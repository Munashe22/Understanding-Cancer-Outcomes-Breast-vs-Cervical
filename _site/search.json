[
  {
    "objectID": "technical-details/unsupervised-learning/main.html",
    "href": "technical-details/unsupervised-learning/main.html",
    "title": "Unsupervised Learning",
    "section": "",
    "text": "Note: You should remove these instructions once you have read and understood them. They should not be included in your final submission.\nRemember: Exactly what do you put on this page will be specific you your project and data. Some things might “make more sense” on one page rather than another, depending on your workflow. Organize your project in a logical way that makes the most sense to you.\n\n\nHere’s one suggested structure for organizing your technical pages. You can adjust this as needed:\nAudience:Remember that these are written for a technical audience. Assume they have completed the DSAN program, but would appreciate refreshers of the important concepts.\n\nIntroduction and Motivation: Briefly outline your plan. What are you doing on this page, and why? Provide context and explain the goals of your analysis.\nOverview of Methods: Give a concise explanation of the methods used. For example, if using K-Means clustering, describe what it is, how it works, the inputs and outputs, and key hyperparameters.\nCode: Include the code you used to implement your workflow.\nSummary and Interpretation of Results: Summarize your findings, interpret the results, and discuss their technical implications.\n\n\n\n\nThe following is a list of some of the things you should address on this page. This list is not exhaustive, and you should use your judgment to decide what is most relevant to your project.\nThis page is designed to give you hands-on experience with key unsupervised learning techniques, including clustering methods and dimensionality reduction, applied to real-world datasets. Please apply algorithms such as K-Means, DBSCAN, Hierarchical clustering, PCA, and t-SNE to your data. Through this process, you’ll deepen your understanding of how unsupervised learning can reveal hidden patterns and structure in data.\n\n\nThe objective of this section is to explore and demonstrate the effectiveness of PCA and t-SNE in reducing the dimensionality of complex data while preserving essential information and improving visualization.\n\nPCA (Principal Component Analysis):\n\nApply PCA to your dataset.\nDetermine the optimal number of principal components.\nVisualize the reduced-dimensional data.\nAnalyze and interpret the results.\n\nt-SNE (t-distributed Stochastic Neighbor Embedding):\n\nImplement t-SNE on the same dataset.\nExperiment with different perplexity values.\nVisualize the t-SNE output to reveal patterns and clusters.\nCompare the results of t-SNE with those from PCA.\n\nEvaluation and Comparison:\n\nEvaluate the effectiveness of PCA and t-SNE in preserving data structure.\nCompare the visualization capabilities of both techniques.\nDiscuss the trade-offs and scenarios where one technique may perform better than the other.\n\n\n\n\n\nApply clustering techniques (K-Means, DBSCAN, and Hierarchical clustering) to a selected dataset. The goal is to understand how each method works, compare their performance, and interpret the results.\n\nClustering Methods:\n\nApply K-Means, DBSCAN, and Hierarchical clustering to your dataset.\nWrite a technical summary for each method (2–4 paragraphs per method) explaining how it works, its purpose, and any model selection methods used (e.g., Elbow, Silhouette).\n\nResults Section:\n\nDiscuss and visualize the results of each clustering analysis.\nCompare the performance of different clustering methods, noting any insights gained from the analysis.\nVisualize cluster patterns and how they relate (if at all) to existing labels in the dataset.\nUse professional, labeled, and clear visualizations that support your discussion.\n\nConclusion:\n\nSummarize the key findings and their real-world implications in a non-technical way. Focus on the most important results and how they could apply to practical situations."
  },
  {
    "objectID": "technical-details/unsupervised-learning/main.html#suggested-page-structure",
    "href": "technical-details/unsupervised-learning/main.html#suggested-page-structure",
    "title": "Unsupervised Learning",
    "section": "",
    "text": "Here’s one suggested structure for organizing your technical pages. You can adjust this as needed:\nAudience:Remember that these are written for a technical audience. Assume they have completed the DSAN program, but would appreciate refreshers of the important concepts.\n\nIntroduction and Motivation: Briefly outline your plan. What are you doing on this page, and why? Provide context and explain the goals of your analysis.\nOverview of Methods: Give a concise explanation of the methods used. For example, if using K-Means clustering, describe what it is, how it works, the inputs and outputs, and key hyperparameters.\nCode: Include the code you used to implement your workflow.\nSummary and Interpretation of Results: Summarize your findings, interpret the results, and discuss their technical implications."
  },
  {
    "objectID": "technical-details/unsupervised-learning/main.html#what-to-address",
    "href": "technical-details/unsupervised-learning/main.html#what-to-address",
    "title": "Unsupervised Learning",
    "section": "",
    "text": "The following is a list of some of the things you should address on this page. This list is not exhaustive, and you should use your judgment to decide what is most relevant to your project.\nThis page is designed to give you hands-on experience with key unsupervised learning techniques, including clustering methods and dimensionality reduction, applied to real-world datasets. Please apply algorithms such as K-Means, DBSCAN, Hierarchical clustering, PCA, and t-SNE to your data. Through this process, you’ll deepen your understanding of how unsupervised learning can reveal hidden patterns and structure in data.\n\n\nThe objective of this section is to explore and demonstrate the effectiveness of PCA and t-SNE in reducing the dimensionality of complex data while preserving essential information and improving visualization.\n\nPCA (Principal Component Analysis):\n\nApply PCA to your dataset.\nDetermine the optimal number of principal components.\nVisualize the reduced-dimensional data.\nAnalyze and interpret the results.\n\nt-SNE (t-distributed Stochastic Neighbor Embedding):\n\nImplement t-SNE on the same dataset.\nExperiment with different perplexity values.\nVisualize the t-SNE output to reveal patterns and clusters.\nCompare the results of t-SNE with those from PCA.\n\nEvaluation and Comparison:\n\nEvaluate the effectiveness of PCA and t-SNE in preserving data structure.\nCompare the visualization capabilities of both techniques.\nDiscuss the trade-offs and scenarios where one technique may perform better than the other.\n\n\n\n\n\nApply clustering techniques (K-Means, DBSCAN, and Hierarchical clustering) to a selected dataset. The goal is to understand how each method works, compare their performance, and interpret the results.\n\nClustering Methods:\n\nApply K-Means, DBSCAN, and Hierarchical clustering to your dataset.\nWrite a technical summary for each method (2–4 paragraphs per method) explaining how it works, its purpose, and any model selection methods used (e.g., Elbow, Silhouette).\n\nResults Section:\n\nDiscuss and visualize the results of each clustering analysis.\nCompare the performance of different clustering methods, noting any insights gained from the analysis.\nVisualize cluster patterns and how they relate (if at all) to existing labels in the dataset.\nUse professional, labeled, and clear visualizations that support your discussion.\n\nConclusion:\n\nSummarize the key findings and their real-world implications in a non-technical way. Focus on the most important results and how they could apply to practical situations."
  },
  {
    "objectID": "technical-details/eda/main.html",
    "href": "technical-details/eda/main.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Exploratory Data Analysis (EDA) serves as the critical foundation for understanding the complex clinical landscape of cancer patient data before building predictive models. Our analysis focuses on two major cancer types affecting women: Breast Invasive Carcinoma (BRCA) and Cervical Squamous Cell Carcinoma (CESC) from The Cancer Genome Atlas (TCGA).\n\n\nCancer datasets present unique analytical challenges that make thorough exploration crucial:\n\nMulti-dimensional Clinical Complexity: Cancer progression involves intricate relationships between patient demographics, tumor characteristics, staging systems (AJCC, FIGO), treatment modalities, and survival outcomes that required systematic investigation.\nData Quality Assessment: EDA was also a process enabling us to assess the effectiveness of our data cleaning stage.\nFeature Engineering Insights: Understanding distributions and relationships helped identify opportunities for creating meaningful derived features (e.g., ordinal encoding of cancer stages, treatments offered).\nModel Selection Guidance: EDA revealed whether relationships are linear or non-linear, helping inform appropriate algorithm choices for subsequent supervised and unsupervised learning tasks.\n\n\n\n\nOur EDA is designed to answer key questions that will inform our modeling strategy:\n\nSurvival Patterns: How do survival times vary between BRCA and CESC patients? What are the distributional characteristics of our regression target?\nStaging Relationships: How do different staging systems (AJCC pathologic staging, FIGO staging for cervical cancer) relate to patient outcomes?\nTreatment Impact: What treatment patterns exist, and how do they correlate with survival outcomes?\nFeature Relationships: Which clinical variables show the strongest associations with survival time and each other?\nData Completeness: Where are the gaps in our data, and how might they impact model performance?\n\n\n\n\nThrough systematic exploration, we aimed to:\n\nIdentify the most informative features for survival prediction\nDetect potential confounding variables or selection biases\nEstablish baseline expectations for model performance\nGenerate hypotheses about cancer survival mechanisms for validation in supervised learning"
  },
  {
    "objectID": "technical-details/eda/main.html#suggested-page-structure",
    "href": "technical-details/eda/main.html#suggested-page-structure",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Here’s one suggested structure for organizing your technical pages. You can adjust this as needed:\nAudience:Remember that these are written for a technical audience. Assume they have completed the DSAN program, but would appreciate refreshers of the important concepts.\n\nIntroduction and Motivation: Briefly outline your plan. What are you doing on this page, and why? Provide context and explain the goals of your analysis.\nOverview of Methods: Give a concise explanation of the methods used. For example, if using K-Means clustering, describe what it is, how it works, the inputs and outputs, and key hyperparameters.\nCode: Include the code you used to implement your workflow.\nSummary and Interpretation of Results: Summarize your findings, interpret the results, and discuss their technical implications."
  },
  {
    "objectID": "technical-details/eda/main.html#what-to-address",
    "href": "technical-details/eda/main.html#what-to-address",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "The following is a list of some of the things you should address on this page. This list is not exhaustive, and you should use your judgment to decide what is most relevant to your project.\nThe EDA (Exploratory Data Analysis) tab in your portfolio serves as a crucial foundation for your project. It provides a thorough overview of the dataset, highlights patterns, identifies potential issues, and prepares the data for further analysis. Follow these instructions to document your EDA effectively:\nThe goal of EDA is to gain a deeper understanding of the dataset and its relevance to your project’s objectives. It involves summarizing key data characteristics, identifying patterns, anomalies, and preparing for future analysis phases.\nHere are suggestions for things to include on this page\nUnivariate Analysis:\n\nNumerical Variables:\n\nProvide summary statistics (mean, median, standard deviation).\nVisualize distributions using histograms or density plots.\n\nCategorical Variables:\n\nPresent frequency counts and visualize distributions using bar charts or pie charts.\n\nKey Insights:\n\nHighlight any notable trends or patterns observed.\n\n\nBivariate and Multivariate Analysis:\n\nCorrelation Analysis:\n\nAnalyze relationships between numerical variables using a correlation matrix.\nVisualize with heatmaps or pair plots and discuss any strong correlations.\n\nCrosstabulations:\n\nFor categorical variables, use crosstabs to explore relationships and visualize them with grouped bar plots.\n\nFeature Pairings:\n\nAnalyze relationships between key variables, particularly those related to your target.\nVisualize with scatter plots, box plots, or violin plots.\n\n\nData Distribution and Normalization:\n\nSkewness and Kurtosis:\nAnalyze and discuss the distribution of variables.\nApply transformations (e.g., log transformation) if needed for skewed data.\nNormalization:\nApply normalization or scaling techniques (e.g., min-max scaling, z-score).\nDocument and visualize the impact of normalization.\n\nStatistical Insights:\n\nConduct basic statistical tests (e.g., T-tests, ANOVA, chi-square) to explore relationships between variables.\nSummarize the statistical results and their implications for your analysis.\n\nData Visualization and Storytelling:\n\nVisual Summary:\nPresent key insights using charts and visualizations (e.g., Matplotlib, Seaborn, Plotly).\nEnsure all visualizations are well-labeled and easy to interpret.\nInteractive Visualizations (Optional):\nInclude interactive elements (e.g., Plotly, Bokeh) to allow users to explore the data further.\n\nConclusions and Next Steps:\n\nSummary of EDA Findings:\nHighlight the main takeaways from the EDA process (key trends, patterns, data quality issues).\nImplications for Modeling:\nDiscuss how your EDA informs the next steps in your project (e.g., feature selection, data transformations).\nOutline any further data cleaning or preparation required before moving into modeling."
  },
  {
    "objectID": "technical-details/data-cleaning/main.html",
    "href": "technical-details/data-cleaning/main.html",
    "title": "Data Cleaning",
    "section": "",
    "text": "Our data cleaning methods were comparable for both the cervical (cesc) and breast (brca) cancer datasets due to the dataset having similar columns due to both diseases being cancer. The clinical breast cancer dataset originally has 5546 rows and 210 columns representing 1098 patients. The clinical cervical cancer dataset originally has 1535 rows and 210 columns representing 307 patients.\nOur data cleaning was focused on three key areas:\n\nManaging missing data\nData type correction and formatting\nData engineering\n\nVisualizations below will be centered on the brca dataset due to the larger number of samples. However, the similar process for cleaning the cesc dataset can be found here along with the data cleaning code for the brca dataset.\n\n\n#| echo: false\n#| warning: false\n#| tbl-cap: Rows showing a unique patient (cases.submitter_id) and their different treatments for breast cancer\n\n# Import relevant libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.io as pio\npio.renderers.default = \"notebook_connected\"\nimport missingno as msno\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom scipy import stats\nfrom scipy.stats import norm, skew\n\n# Import dataset\nbrca_df_original = pd.read_csv(\"../../data/raw-data/brca/brca-clinical.tsv\", sep=\"\\t\")\n\n# Create a copy of the original dataframe to work on\nbrca_df = brca_df_original.copy()\n\n# Display first few rows of the dataset\nbrca_df.head()\nMissing data: From viewing both datasets, the missing data was represented as ’— and required replacing the placeholder string with numpy nontype in order to handle missing values efficiently.\nThe missing values per columns ranged from 0% to 100%, this was a limitation of the datasets especially due to a lot of demographic columns having a large percentage of missing values, as these columns might have been potential social determinants of survival days depending on the type of cancer,\n#| echo: false\n#| warning: false\n#| tbl-cap: Distribution of missing values in key demographic columns\n\ncols_to_check = [\n    'demographic.year_of_birth',\n    'demographic.age_at_index',\n    'demographic.cause_of_death',\n    'demographic.year_of_death',\n    'demographic.vital_status',\n    'demographic.cause_of_death',\n    'demographic.education_level',\n    'demographic.days_to_death'\n]\nfor col in cols_to_check:\n    missing_percentage = brca_df[col].isnull().mean() * 100\n    print(f\"{col}: {missing_percentage:.2f}% missing values\")\nHowever, the demographic.vital_status column has fewer missing values, which still allowed for some analysis regarding survival status. Despite a large number of missing values in demographic.days_to_death, we reasonable assummed it is because the patient is alive since the missing values corresponded to alive in the vital_status column. In addition, days_to_last_follow_up also has fewer missing values (11% in the brca dataset, and 12% in the cesc dataset), which enabled inferring survival time in feature engineering.\nThe datasets had a lot of columns with missing data. The overall original view of missing data in the brca dataset is showed below:\n#| echo: false\n#| warning: false\n#| tbl-cap: Distribution of missing values in breast cancer dataset\n\n# Replace \"'--\" as NA\nbrca_df_original.replace('\\'--', np.nan, inplace=True)\nbrca_df.replace('\\'--', np.nan, inplace=True)\n\nplt.figure(figsize=(15, 8))\nmsno.matrix(brca_df)\nplt.title(\"Missing Data Matrix - Breast Cancer Dataset\", fontsize=14, fontweight='bold')\nplt.show()\nMost of the missing values were initially dropped through the following logic:\n\nDrop of columns with more than 30% data missing (except days_to_death as it is a key column for analysis). This reduced the number of columns by ~75% (e.g., to 46 columns for brca)\nDrop of columns irrelevant to the task of analysing survival time for the two different types of cancers e.g., data consent - not a predictor of how someone will survive a cancer, year of diagnoses - age at diagnoses captures the effect\nDrop of duplicate rows and rows with greater than 30% of the data missing i.e., 30% of information on that patient missing\n\nThe above resulted in a cleaner dataset as shown below:\n\n\n\nDistribution of missing data after dropping missing values as described above\n\n\nAfterwards, missing data was cleaned as follows\n\nFor most of the columns, the missing values were replaced with the mode/most frequent value e.g., diasease_is_primary diasease as True, site_of_involvement as breast, pathologic n (lymph node component of cancer staging) as N0 (no regional lymph node metastasis) due to heavy imbalance towards specific classes\nOverall stage infered from pathologic n, pathologic t (size and extent of primary tumor), and pathologic m (distant metastasis - whether the cancer has spread to distant organs)\nHandling of missing data in days_to_death was handled in the supervised learning section, this was due to the patients still being alive\n\n\n\n\n\nData Types: All columns in the dataset are originally stored as object datatype\nTransformation: Columns were changed to numeric, boolean, and strings as needed in the dataset\n\nNumeric: days_to_death and days_to_last_follow_up were changed to numeric integers. age_at_diagnoses was changed from days to years for easier analysis during exploratory data analysis\nBoolean: Boolean columns were primarily coded as yes/no and these values were changed to True/False respectively\nStrings: Object columns were changed to lowercase strings and leading/trailing whitespace trimmed\n\nImpact of changes: These changes were primarily made with exploratory data analysis in mind and a longer term view towards survival time prediction. Changing age at diagnoses to years enabled better synthesis of multivariate analysis and while preserving days_to_death and days_to_last_follow_up preserved information as the columns are a measure of survival time. Boolean columns enabled efficient filtering and subseeting and the string columns were optimal for wordcloud analysis.\n\n\n\n\nAfter validating the range and distribution of age_at_diagnosis (min of 26 years and max of 89 years), and handling negative values for days_to_last_follow_up by replacing them with the mean, our data engineering process involved extracting more data from columns. Primarily the two columns below were derived:\n\ndiagnosis.behavior: Tumor behavior was derived from the diagnoses.morphology field using the International Classification of Diseases for Oncology, Third Edition (ICD-O-3). Morphology codes follow the format ####/B, where the digit following the slash encodes tumor behavior (e.g., /3 indicates malignant primary disease). For example, morphology code 8500/3 corresponds to infiltrating duct carcinoma with malignant primary behavior. Behavior values were extracted and mapped to ordinal numeric representations following ICD-O-3 guidelines.1\nsurvival_time_days: Survival time was derived using clinical time-to-event variables provided by the Genomic Data Commons (GDC).2 For patients with a recorded death event, survival time was calculated as the difference between demographic.days_to_death and diagnoses.days_to_diagnosis, yielding the number of days survived following cancer diagnosis. For patients without a recorded death event (i.e., alive at last contact), survival time was defined as diagnoses.days_to_last_follow_up, representing the number of days from diagnosis to the most recent clinical follow-up. This approach follows standard survival analysis practice by treating deaths as observed events and living patients as right-censored observations. Missing values in days_to_death were therefore interpreted as censored outcomes rather than zero survival time. No additional adjustments or imputation were applied to survival duration to preserve the temporal integrity of the observed clinical timelines.\n\nFurther data engineering e.g., handling of multiple rows per patient due to multiple treatment types, were handled in feature engineering before machine learning in order to analyse variables in depth e.g., number of treatments. Additional columns are also dropped and some created after exploratory data analysis (EDA) continuing the process of data engineering.\nFor cervical cancer, data cleaning also included extracting the tobacco smoking status and unique ID from the exposure dataset. Unfortunately, the breast cancer exposure file contained only missing values, limiting our analysis. However, examining tobacco exposure in the cervical cancer dataset and not in the breast cancer dataset is epidemiologically justified as cigarette smoking is a recognized co-factor in cervical carcinogenesis while it is not considered a primary risk factor for breast cancer onset or progression, with prior research indicating weak, inconsistent, or indirect associations compared to dominant hormonal, genetic, and reproductive factors3"
  },
  {
    "objectID": "technical-details/data-cleaning/main.html#suggested-page-structure",
    "href": "technical-details/data-cleaning/main.html#suggested-page-structure",
    "title": "Data Cleaning",
    "section": "",
    "text": "Here’s one suggested structure for organizing your technical pages. You can adjust this as needed:\nAudience:Remember that these are written for a technical audience. Assume they have completed the DSAN program, but would appreciate refreshers of the important concepts.\n\nIntroduction and Motivation: Briefly outline your plan. What are you doing on this page, and why? Provide context and explain the goals of your analysis.\nOverview of Methods: Give a concise explanation of the methods used. For example, if using K-Means clustering, describe what it is, how it works, the inputs and outputs, and key hyperparameters.\nCode: Include the code you used to implement your workflow.\nSummary and Interpretation of Results: Summarize your findings, interpret the results, and discuss their technical implications."
  },
  {
    "objectID": "technical-details/data-cleaning/main.html#general-comments",
    "href": "technical-details/data-cleaning/main.html#general-comments",
    "title": "Data Cleaning",
    "section": "",
    "text": "Iterative Process: Data cleaning is often not a one-time process. As your analysis progresses, you may need to revisit the cleaning phase, and re-run the code, to adjust to new insights or requirements.\nClarity and Reproducibility: Ensure your documentation is clear and thorough. Others should be able to follow your steps and achieve the same results.\nVisualizations: Use before-and-after visualizations to illustrate the impact of your cleaning steps, making the process more intuitive and transparent.\n\nBy the end of this phase, your cleaned data should be well-documented and ready for further stages, such as Exploratory Data Analysis (EDA) and Machine Learning."
  },
  {
    "objectID": "technical-details/data-cleaning/main.html#what-to-address",
    "href": "technical-details/data-cleaning/main.html#what-to-address",
    "title": "Data Cleaning",
    "section": "",
    "text": "The following is a list of some of the things you should address on this page. This list is not exhaustive, and you should use your judgment to decide what is most relevant to your project.\nThe Data Cleaning page of your portfolio is where you document the process of transforming your raw data into a usable format. Data cleaning is essential for ensuring the quality of your analysis, and this page should serve as a clear and reproducible guide for anyone reviewing your work. It also provides transparency, allowing others to trace the steps you took to prepare your data.\nThe following is a guide to help you get started with possible thing to address on this page .\n\nDescription of the Data Cleaning Process: Explain the steps you took to clean and preprocess the data.\nCode Documentation: Provide the code used in the data cleaning process (link to GitHub or embed the code directly).\nProvide examples of data before and after cleaning: e.g. with df.head() or df.describe()\nRaw and Cleaned Data Links: Ensure your page links to both the original (raw) dataset and the cleaned dataset. (please keep organized and store the cleaned data in data/processed-data, or similar location which doesn’t get synced to GitHub)\n\nPossible things to include:\nIntroduction to Data Cleaning:\n\nProvide a brief explanation of the data cleaning phase, its importance in preparing the data for further analysis (EDA, modeling), and its iterative nature.\nMention that data cleaning may need to be revisited as the project evolves and analysis goals change.\n\nManaging Missing Data:\n\nIdentify Missing Values: Explain how you identified missing data and where it occurred.\nHandling Missing Data: Describe how missing values were addressed (e.g., imputation, removal of rows/columns).\nVisualize Missing Data: Include visualizations (e.g., heatmaps) showing missing values before and after handling them.\n\nOutlier Detection and Treatment:\n\nIdentify Outliers: Describe the methods you used to detect outliers in the dataset.\nAddressing Outliers: Explain how outliers were treated (e.g., removal, transformation, or retaining them for analysis).\nVisualize Outliers: Use visualizations (e.g., box plots) to show how outliers were managed.\n\nData Type Correction and Formatting:\n\nReview Data Types: Summarize the types of variables (numerical, categorical, date-time, etc.) and ensure they are correctly formatted.\nTransformation: Document any transformations performed, such as converting date formats, handling categorical variables, or encoding labels.\nImpact of Changes: Briefly explain why these changes were necessary for accurate analysis.\n\nNormalization and Scaling:\n\nData Distribution Analysis: Check and discuss the distribution of numerical variables (e.g., skewness).\nNormalization Techniques: Describe any normalization or scaling techniques used (e.g., min-max scaling, z-score normalization).\nBefore-and-After Visualizations: Provide visualizations comparing the data before and after scaling or normalization.\n\nSubsetting the Data:\n\nData Filtering: Explain any subsetting or filtering of the data (e.g., selecting quantitative or qualitative columns).\nRationale: Justify why you chose to work with a particular subset of the data."
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "Visual EDA",
    "section": "",
    "text": "Below are the focus of the EDA,"
  },
  {
    "objectID": "eda.html#breast-brca-dataset-eda",
    "href": "eda.html#breast-brca-dataset-eda",
    "title": "Visual EDA",
    "section": "Breast (BRCA) Dataset EDA",
    "text": "Breast (BRCA) Dataset EDA\n\n\nBRCA Dataset Overview:\nShape: (4920, 38)\n\nColumns: ['project.project_id', 'cases.case_id', 'cases.disease_type', 'cases.index_date', 'cases.primary_site', 'cases.submitter_id', 'demographic.age_is_obfuscated', 'demographic.days_to_death', 'demographic.ethnicity', 'demographic.gender', 'demographic.race', 'demographic.submitter_id', 'demographic.vital_status', 'diagnoses.age_at_diagnosis', 'diagnoses.ajcc_pathologic_m', 'diagnoses.ajcc_pathologic_n', 'diagnoses.ajcc_pathologic_stage', 'diagnoses.ajcc_pathologic_t', 'diagnoses.classification_of_tumor', 'diagnoses.days_to_diagnosis', 'diagnoses.days_to_last_follow_up', 'diagnoses.diagnosis_is_primary_disease', 'diagnoses.laterality', 'diagnoses.method_of_diagnosis', 'diagnoses.morphology', 'diagnoses.primary_diagnosis', 'diagnoses.prior_malignancy', 'diagnoses.prior_treatment', 'diagnoses.site_of_resection_or_biopsy', 'diagnoses.sites_of_involvement', 'diagnoses.submitter_id', 'diagnoses.synchronous_malignancy', 'diagnoses.tissue_or_organ_of_origin', 'treatments.submitter_id', 'treatments.treatment_or_therapy', 'treatments.treatment_type', 'survival_time_days', 'diagnoses.behavior']\n\n\n\nUnivariate Analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnivariate Analysis Findings - Categorical - The breast cancer dataset is heavily imbalanced towards alive in the vital_status column, this makes sense as breast cancer has a high survival rate compared to many other cancers. - The behavior of the tumor is completely dominated by malignant tumors and for most patients, this is their first known malignant cancer diagnosis - Over 70% of the patients are white followed by almost 20% black/African American, this is reflective of the US population where breast cancer is most prevalent - As expected, most patients receive treatment with a majority receiving chemotherapy followed by surgery, and hormone therapy. - Last but not least, the disease type is ductal and lobular neoplasms and there is no difference in laterality (which breast)\n\n\n(4920, 38)\n\n\n\n\n\n\n\n\n\n\n\nUnivariate Analysis Findings - Numerical - The average age at diagnoses is 56 years old with a minimum age of 26 and a maximum age of 89 years old. - The average survival time is 1324 days from diagnoses and ranges from 0 days to 8605 days\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBivariate Analysis Findings - The survival time is slightly higher for dead patients compared to alive patients, this is likely due to many alive patients being recently diagnosed and have not had enough time to accumulate survival days. - Older patients tend to have lower survival times compared to younger patients, this is expected as older patients tend to have more comorbidities and a weaker immune system. - Patients who received immunotherapy tend to have higher survival times compared to other treatment types, this is likely due to immunotherapy being a more aggressive treatment option. The next type of treatment that shows higher survival times is chemotherapy. - Patients who opted for treatment tend to have higher survival times compared to those who did not receive treatment, this is expected as treatment is designed to improve patient outcomes. - There is lower survical times for patients with stage iiib as it is one of the more severe stages of breast cancer before metastasis (stage iv). Stage i and ib have the highest survival times as they are the least severe stages.\n\n\n\n\n\n\n\n\n\nMultivariate Analysis Findings - Generally, older patients tend to have lower survival times across all stages of breast cancer, with latter stages (stage iiib, iiic, iv)showing more pronounced decreases in survival time.\n- Younger patients generally have higher survival times, especially if the diagnoses is at an early stage (stage i, ib, ii). - Stage x is when the tumor could not be assessed, the patients tend to have a higher survival time - Overall, getting diagnoses at an earlier stage is associated with better survival outcomes, regardless of age. - Treatment or no treatment, there is no difference in survival times for older patients (&gt;70 years old). However, for younger patients (&lt; 70 years old), those who received treatment tend to have higher survival times compared to those who did not receive treatment.\n\n\n\n\n\n\n\n\n\nText Analysis Findings - Text Analysis Findings reveal not difference in breast side and a slightly higher frequency for the upper outer region.\n\n\nCorrelation between Age at Diagnosis and Survival Time: -0.1989\n\n\n\nThere is a negative correlation between age at diagnoses and survival time days, indicating that as age at diagnoses increases, survival time days tends to decrease. This suggests that older patients may have poorer survival outcomes compared to younger patients.\n\n\ncesc_df.head(1)\n\n\n\n\n\n\n\n\nproject.project_id\ncases.case_id\ncases.disease_type\ncases.index_date\ncases.lost_to_followup\ncases.primary_site\ncases.submitter_id\ndemographic.days_to_death\ndemographic.ethnicity\ndemographic.gender\ndemographic.race\ndemographic.submitter_id\ndemographic.vital_status\ndiagnoses.age_at_diagnosis\ndiagnoses.ajcc_pathologic_m\ndiagnoses.ajcc_pathologic_n\ndiagnoses.ajcc_pathologic_t\ndiagnoses.classification_of_tumor\ndiagnoses.days_to_diagnosis\ndiagnoses.days_to_last_follow_up\ndiagnoses.figo_stage\ndiagnoses.figo_staging_edition_year\ndiagnoses.method_of_diagnosis\ndiagnoses.morphology\ndiagnoses.primary_diagnosis\ndiagnoses.prior_malignancy\ndiagnoses.prior_treatment\ndiagnoses.site_of_resection_or_biopsy\ndiagnoses.submitter_id\ndiagnoses.synchronous_malignancy\ndiagnoses.tissue_or_organ_of_origin\ndiagnoses.tumor_grade\ntreatments.submitter_id\ntreatments.treatment_or_therapy\ntreatments.treatment_type\nsurvival_time_days\ndiagnoses.behavior\nexposures.tobacco_smoking_status\n\n\n\n\n0\ntcga-cesc\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nsquamous cell neoplasms\ndiagnosis\nyes\ncervix uteri\ntcga-c5-a2lv\nNaN\nnot hispanic or latino\nfemale\nblack or african american\ntcga-c5-a2lv_demographic\nalive\n36.0\nmx\nn1\nt1b\nprimary\n0\n2234.0\nstage ib\n1995\nbiopsy\n8070/3\nsquamous cell carcinoma, nos\nFalse\nFalse\ncervix uteri\ntcga-c5-a2lv_diagnosis\nFalse\ncervix uteri\ng3\ntcga-c5-a2lv_treatment3\nyes\nhysterectomy, nos\n2234.0\nmalignant\ncurrent smoker"
  },
  {
    "objectID": "eda.html#cervical-cancer-cesc-dataset-eda",
    "href": "eda.html#cervical-cancer-cesc-dataset-eda",
    "title": "Visual EDA",
    "section": "Cervical Cancer (CESC) Dataset EDA",
    "text": "Cervical Cancer (CESC) Dataset EDA\nBelow are the focus of the EDA,\n\nUnivariate Analysis (Single Feature)\n\nFrequency Counts: For categorical features (e.g., vital_status, figo_stage, tumor_grade, treatment_type, diagnoses.behavior), visualize frequency distribution (bar charts).\nAge Distribution: Analyze the range and spread of age at diagnoses data (histograms, box plots).\nSurvival time distribution See the spread of survival_time_days (histograms, box plots).\nRace distribution\n\n\n\nBivariate Analysis (Two Features)\n\nvital_status vs. survival_time_days: Explore how survival time varies by vital_status, infer average survival_time_days (box plot or scatter plot).\nage_at_diagnoses vs. average survival_time_days: Analyze differences in average survival time by age_at_diagnoses .\ntreatment_type vs. survival_time_days: Check how treatment_type and survival_time_days are related.\ntreatment_type vs. vital_status: Check treatment_type s offered by vital_status.\nfigo_stage vs. survival_time_days: Explore how survival time varies by ajcc_pathological_stage.\nSurvival_time_days vs. race: Analyze survival time across different races.\nTumor_grade vs. survival_time_days: Explore how survival time varies by tumor_grade.\nDiagnoses behavior vs survival_time_days: Explore how survival time varies by diagnoses behavior.\n\n\n\nMultivariate Analysis (Multiple Features)\n\nTumor_stage vs. age_at_diagnoses vs. survival_time_days : Analyze how survival time varies across different stages and age groups (3D scatter plot or heatmap).\ntreatment_type vs. age_at_diagnoses vs. survival_time_days: Explore trends across treatment types, age groups, and survival times (grouped bar plots).\nfigo_stage vs. age_at_diagnoses vs. survival_time_days: Check if stage impacts survival time at different age groups.\ndiagnoses.behavior vs. age_at_diagnoses vs. survival_time_days: Compare survival times across diagnoses behavior and age groups.\n\n\n\nCorrelations and Associations\n\nCorrelation Matrix: Compute correlations between numerical features (e.g., age_at_diagnoses and survival_time_Days) to find relationships."
  },
  {
    "objectID": "eda.html#cervical-cesc-dataset-eda",
    "href": "eda.html#cervical-cesc-dataset-eda",
    "title": "Visual EDA",
    "section": "Cervical (CESC) Dataset EDA",
    "text": "Cervical (CESC) Dataset EDA\nDue to slightly different columns in the CESC dataset, the EDA will be adjusted accordingly.\n\n\nCESC Dataset Overview:\nShape: (872, 38)\n\nColumns: ['project.project_id', 'cases.case_id', 'cases.disease_type', 'cases.index_date', 'cases.lost_to_followup', 'cases.primary_site', 'cases.submitter_id', 'demographic.days_to_death', 'demographic.ethnicity', 'demographic.gender', 'demographic.race', 'demographic.submitter_id', 'demographic.vital_status', 'diagnoses.age_at_diagnosis', 'diagnoses.ajcc_pathologic_m', 'diagnoses.ajcc_pathologic_n', 'diagnoses.ajcc_pathologic_t', 'diagnoses.classification_of_tumor', 'diagnoses.days_to_diagnosis', 'diagnoses.days_to_last_follow_up', 'diagnoses.figo_stage', 'diagnoses.figo_staging_edition_year', 'diagnoses.method_of_diagnosis', 'diagnoses.morphology', 'diagnoses.primary_diagnosis', 'diagnoses.prior_malignancy', 'diagnoses.prior_treatment', 'diagnoses.site_of_resection_or_biopsy', 'diagnoses.submitter_id', 'diagnoses.synchronous_malignancy', 'diagnoses.tissue_or_organ_of_origin', 'diagnoses.tumor_grade', 'treatments.submitter_id', 'treatments.treatment_or_therapy', 'treatments.treatment_type', 'survival_time_days', 'diagnoses.behavior', 'exposures.tobacco_smoking_status']\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnivariate Analysis Findings - Categorical - The cervical cancer dataset is heavily imbalanced towards alive in the vital_status column, this makes sense as cervical cancer also has a high survival rate compared to many other cancers. - The tumor grade is mostly dominated by grade ii and grade iii tumors, with very few patients having grade i tumors. - The stage is domniated by ib1 followed by iib and ib2, which are some of the less severe stages of cervical cancer. - Almost 70% of the patients are white followed by an approximately equal distribution of the rest of the other races, which is not reflective of the US population - As expected, most patients receive treatment with a majority receiving pharmaceutical therapy followed by radiation therapy. - Last but not least, the disease type is squamous cell neoplasm. All of the patients have malignant tumors and no prior malignant cancer diagnoses.\n\n\n\n\n\n\n\n\n\nUnivariate Analysis Findings - Numerical - The average age at diagnoses is 48 years old with a minimum age of 25 and a maximum age of 80 years old. - The average survival time is 1036 days from diagnoses and ranges from 2 days to 6408 days\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBivariate Analysis Findings - The survival time is slightly higher for alive patients which is expected as alive patients have had more time to accumulate survival days, unlike breast cancer where many alive patients are recently diagnosed. - Older patients tend to have higher survival times compared to younger patients, this is unexpected as older patients tend to have more comorbidities and a weaker immune system. - Patients who received radiation combination therapy tend to have higher survival times compared to other treatment types, this is likely due to combination therapy being a more aggressive treatment option. The next type of treatment that shows higher survival times is pharmaceutical therapy. - There is no difference in survival times for patients who opted for treatment compared to those who did not receive treatment, which is unexpected as treatment is designed to improve patient outcomes. - There is lower survical times for patients with stage iiib, which is one of the more severe stages of cervical cancer before metastasis (stage iv). Stage ib has the highest survival times as it is one of the least severe stages. - Stage ia2, ia1 have small sample size which might indicate need for earlier testing to catch cancer at these stages. There is no data for stage iii which might also suggest a need to shift in diagnoses to earlier stages.\n\n\n\n\n\n\n\n\n\nMultivariate Analysis Findings - Generally, earlier stages show higher survival times across all age groups. - The heatmap plot interpretation is obfuscated by missing data at stages but also younger patients will have lower survival times due to less time to accumulate survival days.\n\n\nCorrelation between Age at Diagnosis and Survival Time: 0.1390\n\n\nThere is a positive correlation between age at diagnoses and survival time days, indicating that as age at diagnoses increases, survival time days tends to increase. This suggests that older patients may have better survival outcomes compared to younger patients but this is unexpected, potentially due to less survival days accumulated by younger patients.\n\ncesc_df.head(1)\n\n\n\n\n\n\n\n\nproject.project_id\ncases.case_id\ncases.disease_type\ncases.index_date\ncases.lost_to_followup\ncases.primary_site\ncases.submitter_id\ndemographic.days_to_death\ndemographic.ethnicity\ndemographic.gender\ndemographic.race\ndemographic.submitter_id\ndemographic.vital_status\ndiagnoses.age_at_diagnosis\ndiagnoses.ajcc_pathologic_m\ndiagnoses.ajcc_pathologic_n\ndiagnoses.ajcc_pathologic_t\ndiagnoses.classification_of_tumor\ndiagnoses.days_to_diagnosis\ndiagnoses.days_to_last_follow_up\ndiagnoses.figo_stage\ndiagnoses.figo_staging_edition_year\ndiagnoses.method_of_diagnosis\ndiagnoses.morphology\ndiagnoses.primary_diagnosis\ndiagnoses.prior_malignancy\ndiagnoses.prior_treatment\ndiagnoses.site_of_resection_or_biopsy\ndiagnoses.submitter_id\ndiagnoses.synchronous_malignancy\ndiagnoses.tissue_or_organ_of_origin\ndiagnoses.tumor_grade\ntreatments.submitter_id\ntreatments.treatment_or_therapy\ntreatments.treatment_type\nsurvival_time_days\ndiagnoses.behavior\nexposures.tobacco_smoking_status\nage_group\n\n\n\n\n0\ntcga-cesc\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nsquamous cell neoplasms\ndiagnosis\nyes\ncervix uteri\ntcga-c5-a2lv\nNaN\nnot hispanic or latino\nfemale\nblack or african american\ntcga-c5-a2lv_demographic\nalive\n36.0\nmx\nn1\nt1b\nprimary\n0\n2234.0\nstage ib\n1995\nbiopsy\n8070/3\nsquamous cell carcinoma, nos\nFalse\nFalse\ncervix uteri\ntcga-c5-a2lv_diagnosis\nFalse\ncervix uteri\ng3\ntcga-c5-a2lv_treatment3\nyes\nhysterectomy, nos\n2234.0\nmalignant\ncurrent smoker\n&lt;40\n\n\n\n\n\n\n\n\n\nSmoking Status Distribution in CESC Dataset:\nexposures.tobacco_smoking_status\nlifelong non-smoker                                553\ncurrent smoker                                     142\ncurrent reformed smoker for &lt; or = 15 yrs           94\nnot reported                                        29\nunknown                                             23\ncurrent reformed smoker for &gt; 15 yrs                20\ncurrent reformed smoker, duration not specified     11\nName: count, dtype: int64\n\nTotal patients with smoking data: 872\n\n\n\n\n\n\n\n\n\n\n============================================================\nSMOKING EXPOSURE SURVIVAL ANALYSIS SUMMARY\n============================================================\n\nInsufficient data for statistical comparison between never smokers and current smokers\n\n============================================================\n\n\nThere is a heavy imbalance towards lifelong non-smoker in the tobacco smoking status column which might indicate underreporting or misclassification of smoking status among cervical cancer patients. This results suggests that smoking status may not be a reliable indicator of cervical cancer risk in this dataset. From survival time by smoking status, lifelong non-smokers and unknowen tend to have higher survival times compared to current smokers and former smokers. However, there is insufficient data to draw definitive conclusions about the impact of smoking status on survival time in cervical cancer patients."
  },
  {
    "objectID": "cesc-cleaning.html",
    "href": "cesc-cleaning.html",
    "title": "EDA for cervical cancer dataset",
    "section": "",
    "text": "# Import relevant libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.io as pio\npio.renderers.default = \"notebook_connected\"\nimport missingno as msno\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom scipy import stats\nfrom scipy.stats import norm, skew\n\n\n# Import dataset\ncesc_df_original = pd.read_csv(\"data/raw-data/cesc/cesc-clinical.tsv\", sep=\"\\t\")\n\n# Create a copy of the original dataframe to work on\ncesc_df = cesc_df_original.copy()\n\n# Display first few rows of the dataset\ncesc_df.head()\n\n\n\n\n\n\n\n\nproject.project_id\ncases.case_id\ncases.consent_type\ncases.days_to_consent\ncases.days_to_lost_to_followup\ncases.disease_type\ncases.index_date\ncases.lost_to_followup\ncases.primary_site\ncases.submitter_id\n...\ntreatments.treatment_duration\ntreatments.treatment_effect\ntreatments.treatment_effect_indicator\ntreatments.treatment_frequency\ntreatments.treatment_id\ntreatments.treatment_intent_type\ntreatments.treatment_or_therapy\ntreatments.treatment_outcome\ntreatments.treatment_outcome_duration\ntreatments.treatment_type\n\n\n\n\n0\nTCGA-CESC\n00ad0ffe-2105-4829-a495-1c2aceb5bb31\nInformed Consent\n0\n'--\nSquamous Cell Neoplasms\nDiagnosis\nYes\nCervix uteri\nTCGA-EK-A2R9\n...\n'--\n'--\n'--\n'--\n672b3cf9-bb40-4f6f-a1c9-69ac3383fbd5\n'--\n'--\n'--\n'--\nHysterectomy, NOS\n\n\n1\nTCGA-CESC\n00ad0ffe-2105-4829-a495-1c2aceb5bb31\nInformed Consent\n0\n'--\nSquamous Cell Neoplasms\nDiagnosis\nYes\nCervix uteri\nTCGA-EK-A2R9\n...\n'--\n'--\n'--\n'--\nd4baa31f-8c1f-5333-afcd-836816fd1a2a\nAdjuvant\nunknown\n'--\n'--\nPharmaceutical Therapy, NOS\n\n\n2\nTCGA-CESC\n00ad0ffe-2105-4829-a495-1c2aceb5bb31\nInformed Consent\n0\n'--\nSquamous Cell Neoplasms\nDiagnosis\nYes\nCervix uteri\nTCGA-EK-A2R9\n...\n'--\n'--\n'--\n'--\ne79370ba-36f0-4639-bc8f-119ba2b2457b\nAdjuvant\nunknown\n'--\n'--\nRadiation Therapy, NOS\n\n\n3\nTCGA-CESC\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nInformed Consent\n2108\n'--\nSquamous Cell Neoplasms\nDiagnosis\nYes\nCervix uteri\nTCGA-C5-A2LV\n...\n'--\n'--\n'--\n'--\n277d525e-9674-4954-b427-3e829d469b8f\n'--\n'--\n'--\n'--\nHysterectomy, NOS\n\n\n4\nTCGA-CESC\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nInformed Consent\n2108\n'--\nSquamous Cell Neoplasms\nDiagnosis\nYes\nCervix uteri\nTCGA-C5-A2LV\n...\n'--\n'--\n'--\n'--\n788ff156-d009-46f7-b832-f39b11ed13ac\nAdjuvant\nno\n'--\n'--\nRadiation Therapy, NOS\n\n\n\n\n5 rows × 210 columns\n\n\n\nFrom the first rows, we can see that there are several columns with missing values, represented as ’– . These values will be turned to NA for easier handling\n\n# Replace \"'--\" as NA\ncesc_df_original.replace('\\'--', np.nan, inplace=True)\ncesc_df.replace('\\'--', np.nan, inplace=True)\n\n\nInspect key columns for survival analysis\n\n# List all cols starting with 'demographic'\ndemographic_cols = [col for col in cesc_df.columns if col.startswith('demographic')]\nprint(\"Columns starting with 'demographic':\")\nfor col in demographic_cols:\n    print(f\"  - {col}\")\nprint(f\"\\nTotal demographic columns: {len(demographic_cols)}\")\n\n\nColumns starting with 'demographic':\n  - demographic.age_at_index\n  - demographic.age_is_obfuscated\n  - demographic.cause_of_death\n  - demographic.cause_of_death_source\n  - demographic.country_of_birth\n  - demographic.country_of_residence_at_enrollment\n  - demographic.days_to_birth\n  - demographic.days_to_death\n  - demographic.demographic_id\n  - demographic.education_level\n  - demographic.ethnicity\n  - demographic.gender\n  - demographic.marital_status\n  - demographic.occupation_duration_years\n  - demographic.population_group\n  - demographic.premature_at_birth\n  - demographic.race\n  - demographic.submitter_id\n  - demographic.vital_status\n  - demographic.weeks_gestation_at_birth\n  - demographic.year_of_birth\n  - demographic.year_of_death\n\nTotal demographic columns: 22\n\n\n\n# Check unique values in 'demographic.days_to_death'\ncesc_df[\"demographic.days_to_death\"].unique()\n\narray([nan, '543', '144', '355', '2052', '2859', '348', '469', '1394',\n       '4086', '253', '14', '506', '570', '951', '1245', '861', '2094',\n       '305', '607', '1186', '636', '642', '275', '879', '284', '370',\n       '523', '1118', '1453', '100', '227', '978', '132', '1011', '52',\n       '442', '252', '2520', '955', '166', '1083', '1372', '555', '1065',\n       '157', '414', '74', '908', '266', '471', '837', '3046', '1210',\n       '104', '350', '2888', '633', '492', '494', '829', '477', '638',\n       '582', '715', '1692', '773', '604', '2032', '659', '3097'],\n      dtype=object)\n\n\n\n# Check for percentage of missing values in 'demographic.days_to_death'\nmissing_percentage = cesc_df[\"demographic.days_to_death\"].isnull().mean()\nprint(f\"'Percentage of missing values in 'demographic.days_to_death' {missing_percentage:.2f}\")\n\n'Percentage of missing values in 'demographic.days_to_death' 0.72\n\n\n\n# Check to see if status is 'alive' where days_to_death is missing\nmissing_death_status = cesc_df[cesc_df[\"demographic.days_to_death\"].isnull()][\"demographic.vital_status\"].value_counts()\nmissing_death_status\n\ndemographic.vital_status\nAlive    1103\nName: count, dtype: int64\n\n\nWe can assume that the demographic.days_to_death column is crucial for survival analysis, as it indicates the time until death for each patient. Despite a significant number of missing values in this column, these are for patients who are still alive, as indicated by the demographic.vital_status column. Therefore, we can retain this column for analysis, treating missing values as censored data.\n\n# Drop rows where days_to_death is missing and vital_status is 'Dead'\ncesc_df = cesc_df[~((cesc_df[\"demographic.days_to_death\"].isnull()) & (cesc_df[\"demographic.vital_status\"] == 'Dead'))]\n\n\n# Check for percentage of missing values in diagnoses.days_to_last_follow_up\nmissing_percentage = cesc_df[\"diagnoses.days_to_last_follow_up\"].isnull().mean()\nprint(f\"'Percentage of missing values in 'diagnoses.days_to_last_follow_up' {missing_percentage:.2f}\")\n\n'Percentage of missing values in 'diagnoses.days_to_last_follow_up' 0.12\n\n\n\n# Check the distribution of vital_status when days_to_last_follow_up is missing\nmissing_followup_status = cesc_df[cesc_df[\"diagnoses.days_to_last_follow_up\"].isnull()][\"demographic.vital_status\"].value_counts()\nmissing_followup_status\n\ndemographic.vital_status\nDead     105\nAlive     86\nName: count, dtype: int64\n\n\n\n# Check the percentage of missing values for the following columns:\n# - demographic.year_of_birth\n# - demographic.year_of_death\n# - demographic.vital_status\n# - demographic.cause_of_death\n# - demographic.education_level\ncols_to_check = [\n    'demographic.year_of_birth',\n    'demographic.age_at_index',\n    'demographic.cause_of_death',\n    'demographic.year_of_death',\n    'demographic.vital_status',\n    'demographic.cause_of_death',\n    'demographic.education_level'\n]\nfor col in cols_to_check:\n    missing_percentage = cesc_df[col].isnull().mean() * 100\n    print(f\"{col}: {missing_percentage:.2f}% missing values\")\n\ndemographic.year_of_birth: 100.00% missing values\ndemographic.age_at_index: 0.00% missing values\ndemographic.cause_of_death: 71.86% missing values\ndemographic.year_of_death: 100.00% missing values\ndemographic.vital_status: 0.00% missing values\ndemographic.cause_of_death: 71.86% missing values\ndemographic.education_level: 100.00% missing values\n\n\nA lot of missing values in key demographic columns, especially in cause of death become a limiting factor for analysis.\n\n# Distribution of demographic.vital_status\nvital_status_counts = cesc_df['demographic.vital_status'].value_counts(dropna=False)\nprint(\"\\ndemographic.vital_status distribution:\")\nprint(vital_status_counts)\n\n\ndemographic.vital_status distribution:\ndemographic.vital_status\nAlive    1103\nDead      432\nName: count, dtype: int64\n\n\nHowever, the demographic.vital_status column has fewer missing values, which may still allow for some analysis regarding survival status. Despite large number of missing values in demographic.days_to_death, we can assume it is because the patient is alive since the missing values correspond to alive in the vital_status column. In addition, days_to_last_follow_up in the diagnoses table also has fewer missing values, which may be useful for survival time analysis.\n\n\nCheck for missing values\n\n# Missing data visualization\nplt.figure(figsize=(15, 8))\nmsno.matrix(cesc_df)\nplt.title(\"Missing Data Matrix - cervical cancer Dataset\", fontsize=14, fontweight='bold')\nplt.show()\n\n&lt;Figure size 1500x800 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\n# Drop columns with more than 30% missing values except for demographic.days_to_death and diagnoses.days_to_last_follow_up\n\n# Calculate missing percentage for each column\nmissing_percentages = cesc_df.isnull().mean()\n\n# Identify columns to drop (more than 30% missing, excluding the exceptions)\nexceptions = ['demographic.days_to_death', 'diagnoses.days_to_last_follow_up']\ncolumns_to_drop = []\n\nfor col in cesc_df.columns:\n    if col not in exceptions and missing_percentages[col] &gt; 0.3:\n        columns_to_drop.append(col)\n\nprint(f\"Columns to be dropped due to &gt;30% missing values: {columns_to_drop}\")\n\n# Drop the identified columns\ncesc_df = cesc_df.drop(columns=columns_to_drop)\n\n# Display the shape of the cleaned dataset\ncesc_df.shape\n\nColumns to be dropped due to &gt;30% missing values: ['cases.days_to_lost_to_followup', 'demographic.cause_of_death', 'demographic.cause_of_death_source', 'demographic.country_of_birth', 'demographic.education_level', 'demographic.marital_status', 'demographic.occupation_duration_years', 'demographic.population_group', 'demographic.premature_at_birth', 'demographic.weeks_gestation_at_birth', 'demographic.year_of_birth', 'demographic.year_of_death', 'diagnoses.adrenal_hormone', 'diagnoses.ajcc_clinical_m', 'diagnoses.ajcc_clinical_n', 'diagnoses.ajcc_clinical_stage', 'diagnoses.ajcc_clinical_t', 'diagnoses.ajcc_pathologic_stage', 'diagnoses.ajcc_serum_tumor_markers', 'diagnoses.ajcc_staging_system_edition', 'diagnoses.ann_arbor_b_symptoms', 'diagnoses.ann_arbor_b_symptoms_described', 'diagnoses.ann_arbor_clinical_stage', 'diagnoses.ann_arbor_extranodal_involvement', 'diagnoses.ann_arbor_pathologic_stage', 'diagnoses.best_overall_response', 'diagnoses.burkitt_lymphoma_clinical_variant', 'diagnoses.calgb_risk_group', 'diagnoses.cancer_detection_method', 'diagnoses.child_pugh_classification', 'diagnoses.clark_level', 'diagnoses.cog_liver_stage', 'diagnoses.cog_neuroblastoma_risk_group', 'diagnoses.cog_renal_stage', 'diagnoses.cog_rhabdomyosarcoma_risk_group', 'diagnoses.contiguous_organ_invaded', 'diagnoses.days_to_best_overall_response', 'diagnoses.days_to_last_known_disease_status', 'diagnoses.days_to_recurrence', 'diagnoses.double_expressor_lymphoma', 'diagnoses.double_hit_lymphoma', 'diagnoses.eln_risk_classification', 'diagnoses.enneking_msts_grade', 'diagnoses.enneking_msts_metastasis', 'diagnoses.enneking_msts_stage', 'diagnoses.enneking_msts_tumor_site', 'diagnoses.ensat_clinical_m', 'diagnoses.ensat_pathologic_n', 'diagnoses.ensat_pathologic_stage', 'diagnoses.ensat_pathologic_t', 'diagnoses.esophageal_columnar_dysplasia_degree', 'diagnoses.esophageal_columnar_metaplasia_present', 'diagnoses.fab_morphology_code', 'diagnoses.first_symptom_longest_duration', 'diagnoses.first_symptom_prior_to_diagnosis', 'diagnoses.gastric_esophageal_junction_involvement', 'diagnoses.gleason_grade_group', 'diagnoses.gleason_grade_tertiary', 'diagnoses.gleason_patterns_percent', 'diagnoses.gleason_score', 'diagnoses.goblet_cells_columnar_mucosa_present', 'diagnoses.igcccg_stage', 'diagnoses.inpc_grade', 'diagnoses.inpc_histologic_group', 'diagnoses.inrg_stage', 'diagnoses.inss_stage', 'diagnoses.international_prognostic_index', 'diagnoses.irs_group', 'diagnoses.irs_stage', 'diagnoses.ishak_fibrosis_score', 'diagnoses.iss_stage', 'diagnoses.last_known_disease_status', 'diagnoses.laterality', 'diagnoses.margin_distance', 'diagnoses.margins_involved_site', 'diagnoses.masaoka_stage', 'diagnoses.max_tumor_bulk_site', 'diagnoses.medulloblastoma_molecular_classification', 'diagnoses.melanoma_known_primary', 'diagnoses.metastasis_at_diagnosis', 'diagnoses.metastasis_at_diagnosis_site', 'diagnoses.micropapillary_features', 'diagnoses.mitosis_karyorrhexis_index', 'diagnoses.mitotic_count', 'diagnoses.ovarian_specimen_status', 'diagnoses.ovarian_surface_involvement', 'diagnoses.papillary_renal_cell_type', 'diagnoses.pediatric_kidney_staging', 'diagnoses.peritoneal_fluid_cytological_status', 'diagnoses.pregnant_at_diagnosis', 'diagnoses.primary_disease', 'diagnoses.primary_gleason_grade', 'diagnoses.progression_or_recurrence', 'diagnoses.residual_disease', 'diagnoses.satellite_nodule_present', 'diagnoses.secondary_gleason_grade', 'diagnoses.sites_of_involvement', 'diagnoses.sites_of_involvement_count', 'diagnoses.supratentorial_localization', 'diagnoses.tumor_burden', 'diagnoses.tumor_confined_to_organ_of_origin', 'diagnoses.tumor_depth', 'diagnoses.tumor_focality', 'diagnoses.tumor_grade_category', 'diagnoses.tumor_of_origin', 'diagnoses.tumor_regression_grade', 'diagnoses.uicc_clinical_m', 'diagnoses.uicc_clinical_n', 'diagnoses.uicc_clinical_stage', 'diagnoses.uicc_clinical_t', 'diagnoses.uicc_pathologic_m', 'diagnoses.uicc_pathologic_n', 'diagnoses.uicc_pathologic_stage', 'diagnoses.uicc_pathologic_t', 'diagnoses.uicc_staging_system_edition', 'diagnoses.ulceration_indicator', 'diagnoses.weiss_assessment_findings', 'diagnoses.weiss_assessment_score', 'diagnoses.who_cns_grade', 'diagnoses.who_nte_grade', 'diagnoses.wilms_tumor_histologic_subtype', 'treatments.chemo_concurrent_to_radiation', 'treatments.clinical_trial_indicator', 'treatments.course_number', 'treatments.days_to_treatment_end', 'treatments.days_to_treatment_start', 'treatments.drug_category', 'treatments.embolic_agent', 'treatments.initial_disease_status', 'treatments.lesions_treated_number', 'treatments.margin_distance', 'treatments.margin_status', 'treatments.margins_involved_site', 'treatments.number_of_cycles', 'treatments.number_of_fractions', 'treatments.prescribed_dose', 'treatments.prescribed_dose_units', 'treatments.pretreatment', 'treatments.protocol_identifier', 'treatments.radiosensitizing_agent', 'treatments.reason_treatment_ended', 'treatments.reason_treatment_not_given', 'treatments.regimen_or_line_of_therapy', 'treatments.residual_disease', 'treatments.route_of_administration', 'treatments.therapeutic_agents', 'treatments.therapeutic_level_achieved', 'treatments.therapeutic_levels_achieved', 'treatments.therapeutic_target_level', 'treatments.timepoint_category', 'treatments.treatment_anatomic_site', 'treatments.treatment_anatomic_sites', 'treatments.treatment_arm', 'treatments.treatment_dose', 'treatments.treatment_dose_max', 'treatments.treatment_dose_units', 'treatments.treatment_duration', 'treatments.treatment_effect', 'treatments.treatment_effect_indicator', 'treatments.treatment_frequency', 'treatments.treatment_intent_type', 'treatments.treatment_outcome', 'treatments.treatment_outcome_duration']\n\n\n(1535, 47)\n\n\n\n# Check distribution na values after dropping columns\nplt.figure(figsize=(15, 8))\nmsno.matrix(cesc_df)\nplt.title(\"Missing Data Matrix After Dropping Columns - cesc Clinical Dataset\", fontsize=14, fontweight='bold')\nplt.show()\n\n&lt;Figure size 1500x800 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\n\nCheck for duplicate IDs\n\n# Count unique IDs (cases.submitter_id)\n\nunique_ids = cesc_df['cases.submitter_id'].nunique()\nprint(f\"Number of unique IDs: {unique_ids}\")\n\nNumber of unique IDs: 307\n\n\nThe TGCA cesc dataset contains 1,082 unique patient IDs (cases.submitter_id) but 3554 rows in total. This is because the TCGA Schema is designed to have multiple samples per patient, capturing different aspects of the tumor biology. Each patient may have multiple entries corresponding to different sample types, such as primary tumor, metastatic tumor, or normal tissue adjacent to the tumor. This allows for a more comprehensive analysis of the cancer’s characteristics and progression within the same individual.\nThe tcga schema is hierarchical as follows:\nCase (cesc) -&gt; Diagnosis -&gt; Follow-up -&gt; Treatment -&gt; Biospecimens\nMost cesc patients have: - 1 diagnosis - 1 - 5 follow-up entries - 1 - 3 treatments - 2 - 4 tissue samples (tumor and normal)\n\n\nFilter columns based on task\nColumns that are not relevant to the predictive modeling task will be dropped. These include identifiers, dates, and other metadata that do not contribute to the prediction of breast cancer outcomes such as the following:\n\ncases.consent_type\ncases.days_to_consent\ndemographic.days_to_birth\ndemographic.age_at_index (will preserve diagnosis.age_at_diagnosis instead for age at diagnosis)\ndiagnoses.ajcc_staging_system_edition\ndiagnoses.diagnosis_id (captured in disease_type)\ndiagnoses.icd_10_code (captured in disease_type)\ndiagnoses.year_of_diagnosis (interested in age at diagnosis instead)\ntreatments.treatment_id\n\n\n# Drop irrelevant columns\ncolumns_to_drop = [\n    'cases.consent_type',\n    'cases.days_to_consent',\n    'demographic.days_to_birth',\n    'demographic.age_at_index',\n    'demographic.demographic_id',\n    'diagnoses.diagnosis_id',\n    'diagnoses.icd_10_code',\n    'diagnoses.year_of_diagnosis',\n    'treatments.treatment_id',\n    'demographic.country_of_residence_at_enrollment',\n    'diagnoses.diagnosis_is_primary_disease',\n    'demographic.age_is_obfuscated'\n]\n\n# Drop the existing columns\ncesc_df = cesc_df.drop(columns=columns_to_drop)\n\nprint(f\"Dataset shape after dropping columns: {cesc_df.shape}\")\n\nDataset shape after dropping columns: (1535, 35)\n\n\n\n# Check remaining column names\ncesc_df.columns.tolist()\n\n['project.project_id',\n 'cases.case_id',\n 'cases.disease_type',\n 'cases.index_date',\n 'cases.lost_to_followup',\n 'cases.primary_site',\n 'cases.submitter_id',\n 'demographic.days_to_death',\n 'demographic.ethnicity',\n 'demographic.gender',\n 'demographic.race',\n 'demographic.submitter_id',\n 'demographic.vital_status',\n 'diagnoses.age_at_diagnosis',\n 'diagnoses.ajcc_pathologic_m',\n 'diagnoses.ajcc_pathologic_n',\n 'diagnoses.ajcc_pathologic_t',\n 'diagnoses.classification_of_tumor',\n 'diagnoses.days_to_diagnosis',\n 'diagnoses.days_to_last_follow_up',\n 'diagnoses.figo_stage',\n 'diagnoses.figo_staging_edition_year',\n 'diagnoses.method_of_diagnosis',\n 'diagnoses.morphology',\n 'diagnoses.primary_diagnosis',\n 'diagnoses.prior_malignancy',\n 'diagnoses.prior_treatment',\n 'diagnoses.site_of_resection_or_biopsy',\n 'diagnoses.submitter_id',\n 'diagnoses.synchronous_malignancy',\n 'diagnoses.tissue_or_organ_of_origin',\n 'diagnoses.tumor_grade',\n 'treatments.submitter_id',\n 'treatments.treatment_or_therapy',\n 'treatments.treatment_type']\n\n\n\n# Using msno to visualize missing data in remaining columns\nplt.figure(figsize=(15, 8))\nmsno.matrix(cesc_df)\nplt.title(\"Missing Data Matrix After Dropping irrelevant columns - cesc Clinical Dataset\", fontsize=14, fontweight='bold')\nplt.show()\n\n&lt;Figure size 1500x800 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\n# Check missing value percentages again\n\nfor col in cesc_df.columns:\n    missing_percentage = cesc_df[col].isnull().mean() * 100\n    print(f\"{col}: {missing_percentage:.2f}% missing values\")\n\nproject.project_id: 0.00% missing values\ncases.case_id: 0.00% missing values\ncases.disease_type: 0.00% missing values\ncases.index_date: 0.00% missing values\ncases.lost_to_followup: 27.23% missing values\ncases.primary_site: 0.00% missing values\ncases.submitter_id: 0.00% missing values\ndemographic.days_to_death: 71.86% missing values\ndemographic.ethnicity: 0.00% missing values\ndemographic.gender: 0.00% missing values\ndemographic.race: 0.00% missing values\ndemographic.submitter_id: 0.00% missing values\ndemographic.vital_status: 0.00% missing values\ndiagnoses.age_at_diagnosis: 1.76% missing values\ndiagnoses.ajcc_pathologic_m: 23.52% missing values\ndiagnoses.ajcc_pathologic_n: 22.61% missing values\ndiagnoses.ajcc_pathologic_t: 22.28% missing values\ndiagnoses.classification_of_tumor: 0.00% missing values\ndiagnoses.days_to_diagnosis: 1.04% missing values\ndiagnoses.days_to_last_follow_up: 12.44% missing values\ndiagnoses.figo_stage: 16.22% missing values\ndiagnoses.figo_staging_edition_year: 16.09% missing values\ndiagnoses.method_of_diagnosis: 12.64% missing values\ndiagnoses.morphology: 0.00% missing values\ndiagnoses.primary_diagnosis: 0.00% missing values\ndiagnoses.prior_malignancy: 12.44% missing values\ndiagnoses.prior_treatment: 1.56% missing values\ndiagnoses.site_of_resection_or_biopsy: 0.00% missing values\ndiagnoses.submitter_id: 0.00% missing values\ndiagnoses.synchronous_malignancy: 12.44% missing values\ndiagnoses.tissue_or_organ_of_origin: 0.00% missing values\ndiagnoses.tumor_grade: 13.81% missing values\ntreatments.submitter_id: 0.39% missing values\ntreatments.treatment_or_therapy: 11.40% missing values\ntreatments.treatment_type: 0.39% missing values\n\n\n\n# Drop rows with missing cases.lost_to_followup\ncesc_df = cesc_df.dropna(subset=['cases.lost_to_followup'])\ncesc_df.shape\n\n(1117, 35)\n\n\n\n# Check distribution of rows that have a lot of missing values\ncesc_df[\"na_count\"] = cesc_df.isna().sum(axis=1)\nna_count_distribution = cesc_df['na_count'].value_counts().sort_index()\nprint(\"\\nDistribution of rows by number of missing values:\")\nprint(na_count_distribution)\n\n\nDistribution of rows by number of missing values:\nna_count\n0      52\n1     675\n2     115\n3      51\n4      83\n5      19\n6       6\n8       3\n9       3\n10     31\n11     67\n12      3\n13      3\n14      5\n16      1\nName: count, dtype: int64\n\n\n\n# Delete rows that have 10 or more missing values (representing over 25% of that entity info missing)\ncesc_df = cesc_df[cesc_df['na_count'] &lt; 9].drop(columns=['na_count'])\n\n\n# Delete rows that have missing age_at_diagnosis info since this is a critical variable for our analysis\ncesc_df = cesc_df[cesc_df['diagnoses.age_at_diagnosis'].notna()]\n\n\n# Check missing value percentages again\n\nfor col in cesc_df.columns:\n    missing_percentage = cesc_df[col].isnull().mean() * 100\n    print(f\"{col}: {missing_percentage:.2f}% missing values\")\n\nproject.project_id: 0.00% missing values\ncases.case_id: 0.00% missing values\ncases.disease_type: 0.00% missing values\ncases.index_date: 0.00% missing values\ncases.lost_to_followup: 0.00% missing values\ncases.primary_site: 0.00% missing values\ncases.submitter_id: 0.00% missing values\ndemographic.days_to_death: 91.57% missing values\ndemographic.ethnicity: 0.00% missing values\ndemographic.gender: 0.00% missing values\ndemographic.race: 0.00% missing values\ndemographic.submitter_id: 0.00% missing values\ndemographic.vital_status: 0.00% missing values\ndiagnoses.age_at_diagnosis: 0.00% missing values\ndiagnoses.ajcc_pathologic_m: 12.15% missing values\ndiagnoses.ajcc_pathologic_n: 11.24% missing values\ndiagnoses.ajcc_pathologic_t: 11.24% missing values\ndiagnoses.classification_of_tumor: 0.00% missing values\ndiagnoses.days_to_diagnosis: 0.00% missing values\ndiagnoses.days_to_last_follow_up: 0.30% missing values\ndiagnoses.figo_stage: 4.82% missing values\ndiagnoses.figo_staging_edition_year: 4.62% missing values\ndiagnoses.method_of_diagnosis: 0.30% missing values\ndiagnoses.morphology: 0.00% missing values\ndiagnoses.primary_diagnosis: 0.00% missing values\ndiagnoses.prior_malignancy: 0.30% missing values\ndiagnoses.prior_treatment: 0.30% missing values\ndiagnoses.site_of_resection_or_biopsy: 0.00% missing values\ndiagnoses.submitter_id: 0.00% missing values\ndiagnoses.synchronous_malignancy: 0.30% missing values\ndiagnoses.tissue_or_organ_of_origin: 0.00% missing values\ndiagnoses.tumor_grade: 1.00% missing values\ntreatments.submitter_id: 0.00% missing values\ntreatments.treatment_or_therapy: 12.85% missing values\ntreatments.treatment_type: 0.00% missing values\n\n\n\n# Check the distribution of the method_of_diagnosis since it has a significantly higher missing value percentage\nmethod_of_diagnosis_counts = cesc_df['diagnoses.method_of_diagnosis'].value_counts(dropna=False)\nprint(\"\\ndiagnoses.method_of_diagnosis distribution:\")\nprint(method_of_diagnosis_counts)\n\n\ndiagnoses.method_of_diagnosis distribution:\ndiagnoses.method_of_diagnosis\nBiopsy                              852\nSurgical Resection                   61\nCytology                             54\nDilation and Curettage Procedure     26\nNaN                                   3\nName: count, dtype: int64\n\n\nDue to the heavy imbalance leaning towards Biopsy for the diagnoses.method_of_diagnosis column, we can replace missing values with ‘Biopsy’ to retain more rows for analysis.\n\n# Set pandas options to display all columns\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', None)\n\n\n# Check distribution of diagnoses.ajcc_pathologic_n \najcc_pathologic_stage_counts = cesc_df['diagnoses.ajcc_pathologic_n'].value_counts(dropna=False)\nprint(\"\\ndiagnoses.ajcc_pathologic_n distribution:\")\nprint(ajcc_pathologic_stage_counts)\n\n\ndiagnoses.ajcc_pathologic_n distribution:\ndiagnoses.ajcc_pathologic_n\nN0     452\nNX     265\nN1     167\nNaN    112\nName: count, dtype: int64\n\n\n\n# Check distribution of diagnoses.ajcc_pathologic_m \najcc_pathologic_stage_counts = cesc_df['diagnoses.ajcc_pathologic_m'].value_counts(dropna=False)\nprint(\"\\ndiagnoses.ajcc_pathologic_m distribution:\")\nprint(ajcc_pathologic_stage_counts)\n\n\ndiagnoses.ajcc_pathologic_m distribution:\ndiagnoses.ajcc_pathologic_m\nMX     472\nM0     358\nNaN    121\nM1      45\nName: count, dtype: int64\n\n\n\n# Check distribution of diagnoses.ajcc_pathologic_t \najcc_pathologic_stage_counts = cesc_df['diagnoses.ajcc_pathologic_t'].value_counts(dropna=False)\nprint(\"\\ndiagnoses.ajcc_pathologic_t distribution:\")\nprint(ajcc_pathologic_stage_counts)\n\n\ndiagnoses.ajcc_pathologic_t distribution:\ndiagnoses.ajcc_pathologic_t\nT1b1    246\nT2b     132\nT1b2    115\nNaN     112\nT1b      94\nTX       50\nT2a2     49\nT3b      39\nT2a      35\nT2a1     32\nT4       30\nT2       23\nT3a      13\nT3       12\nTis       6\nT1a1      5\nT1        3\nName: count, dtype: int64\n\n\nThe missing values in the diagnoses.ajcc_pathologic_t, diagnoses.ajcc_pathologic_n, and diagnoses.ajcc_pathologic_m columns will be replaced by the mode of each column respectively due to the high imbalance.\n\n# Check distribution of diagnoses.treatment_or_therapy\ntreatment_or_therapy_counts = cesc_df['treatments.treatment_or_therapy'].value_counts(dropna=False)\nprint(\"\\ntreatments.treatment_or_therapy distribution:\")\nprint(treatment_or_therapy_counts)\n\n\ntreatments.treatment_or_therapy distribution:\ntreatments.treatment_or_therapy\nyes        545\nno         224\nNaN        128\nunknown     99\nName: count, dtype: int64\n\n\n\n# Check distribution od diagnoses.figo_stage\nfigo_stage_counts = cesc_df['diagnoses.figo_stage'].value_counts(dropna=False)\nprint(\"\\ndiagnoses.figo_stage distribution:\")\nprint(figo_stage_counts)\n\n\ndiagnoses.figo_stage distribution:\ndiagnoses.figo_stage\nStage IB1     272\nStage IIB     161\nStage IB2     134\nStage IIIB    117\nStage IB       72\nNaN            48\nStage IIA      34\nStage IVB      33\nStage IIA2     31\nStage IIA1     21\nStage IIIA     19\nStage I        16\nStage II       14\nStage IVA      10\nStage III       6\nStage IA1       5\nStage IA2       3\nName: count, dtype: int64\n\n\n\n# Check the distribution of diagnoses.figo_staging_edition_year\nfigo_staging_edition_year_counts = cesc_df['diagnoses.figo_staging_edition_year'].value_counts(dropna=False)\nprint(\"\\ndiagnoses.figo_staging_edition_year distribution:\")\nprint(figo_staging_edition_year_counts)\n\n\ndiagnoses.figo_staging_edition_year distribution:\ndiagnoses.figo_staging_edition_year\n2009    753\n1995    134\n1988     63\nNaN      46\nName: count, dtype: int64\n\n\n\n# Check the distribution of prior_malignancy\nprior_malignancy_counts = cesc_df['diagnoses.prior_malignancy'].value_counts(dropna=False)\nprint(\"\\ndiagnoses.prior_malignancy distribution:\")\nprint(prior_malignancy_counts)\n\n\ndiagnoses.prior_malignancy distribution:\ndiagnoses.prior_malignancy\nno              962\nyes              20\nnot reported     11\nNaN               3\nName: count, dtype: int64\n\n\n\n# Check distribution of diagnoses.tumor_grade\ntumor_grade_counts = cesc_df['diagnoses.tumor_grade'].value_counts(dropna=False)\nprint(\"\\ndiagnoses.tumor_grade distribution:\")\nprint(tumor_grade_counts)\n\n\ndiagnoses.tumor_grade distribution:\ndiagnoses.tumor_grade\nG2     437\nG3     399\nGX      86\nG1      60\nNaN     10\nG4       4\nName: count, dtype: int64\n\n\n\n\nClean NA values\nReplace the missing values in the following columns based on the assigned strategy: - diagnoses.method_of_diagnosis: ‘Core Biopsy’ (most frequent) - diagnoses.diagnosis_is_primary_disease: ‘True’ (most frequent) - diagnoses.prior_malignancy: ‘False’ (most frequent) - diagnoses.prior_treatment: ‘False’ (most frequent) - diagnoses.sites_of_involvement: ‘Breast’ (most frequent) - diagnoses.synchronous_malignancy: ‘False’ (most frequent) - diagnoses.treatment_or_therapy: True (most frequent) - diagnoses.figo_stage: ‘Stage IB1’ (most frequent) - diagnoses.figo_staging_edition_year: ‘2009’ (most frequent)\nDropping rows with missing diagnoses.ajcc_pathologic_m, diagnoses.ajcc_pathologic_n, diagnoses.ajcc_pathologic_t and tumor_grade since they are a small percentage and there is no clear imbalance to guide imputation.\n\n# Drop rows with missing diagnoses.ajcc_pathologic_m, diagnoses.ajcc_pathologic_n, diagnoses.ajcc_pathologic_t and tumor_grade\ncesc_df = cesc_df.dropna(subset=['diagnoses.ajcc_pathologic_m', 'diagnoses.ajcc_pathologic_n', 'diagnoses.ajcc_pathologic_t', 'diagnoses.tumor_grade'])\n\n\n# Replace missing values based on the strategy above:\n\n# Replace with most frequent values\ncesc_df['diagnoses.method_of_diagnosis'] = cesc_df['diagnoses.method_of_diagnosis'].fillna('Biopsy')\ncesc_df['diagnoses.prior_malignancy'] = cesc_df['diagnoses.prior_malignancy'].fillna('no')\ncesc_df['diagnoses.prior_treatment'] = cesc_df['diagnoses.prior_treatment'].fillna('no')\ncesc_df['diagnoses.synchronous_malignancy'] = cesc_df['diagnoses.synchronous_malignancy'].fillna('no')\ncesc_df['treatments.treatment_or_therapy'] = cesc_df['treatments.treatment_or_therapy'].fillna('yes')\ncesc_df['diagnoses.figo_stage'] = cesc_df['diagnoses.figo_stage'].fillna('Stage IB1')\ncesc_df['diagnoses.figo_staging_edition_year'] = cesc_df['diagnoses.figo_staging_edition_year'].fillna(2009)\n\n\n# Check distribution of treatments.treatment_or_therapy after imputation\ntreatment_or_therapy_counts = cesc_df['treatments.treatment_or_therapy'].value_counts(dropna=False)\nprint(\"\\ntreatments.treatment_or_therapy distribution after imputation:\")\nprint(treatment_or_therapy_counts)\n\n\ntreatments.treatment_or_therapy distribution after imputation:\ntreatments.treatment_or_therapy\nyes        583\nno         216\nunknown     73\nName: count, dtype: int64\n\n\n\n# Percentage of missing values in each column\n\nmissing_percentages = cesc_df.isnull().mean() * 100\nprint(\"\\nPercentage of missing values in each column:\")\nprint(missing_percentages)\n\n\nPercentage of missing values in each column:\nproject.project_id                        0.000000\ncases.case_id                             0.000000\ncases.disease_type                        0.000000\ncases.index_date                          0.000000\ncases.lost_to_followup                    0.000000\ncases.primary_site                        0.000000\ncases.submitter_id                        0.000000\ndemographic.days_to_death                92.889908\ndemographic.ethnicity                     0.000000\ndemographic.gender                        0.000000\ndemographic.race                          0.000000\ndemographic.submitter_id                  0.000000\ndemographic.vital_status                  0.000000\ndiagnoses.age_at_diagnosis                0.000000\ndiagnoses.ajcc_pathologic_m               0.000000\ndiagnoses.ajcc_pathologic_n               0.000000\ndiagnoses.ajcc_pathologic_t               0.000000\ndiagnoses.classification_of_tumor         0.000000\ndiagnoses.days_to_diagnosis               0.000000\ndiagnoses.days_to_last_follow_up          0.000000\ndiagnoses.figo_stage                      0.000000\ndiagnoses.figo_staging_edition_year       0.000000\ndiagnoses.method_of_diagnosis             0.000000\ndiagnoses.morphology                      0.000000\ndiagnoses.primary_diagnosis               0.000000\ndiagnoses.prior_malignancy                0.000000\ndiagnoses.prior_treatment                 0.000000\ndiagnoses.site_of_resection_or_biopsy     0.000000\ndiagnoses.submitter_id                    0.000000\ndiagnoses.synchronous_malignancy          0.000000\ndiagnoses.tissue_or_organ_of_origin       0.000000\ndiagnoses.tumor_grade                     0.000000\ntreatments.submitter_id                   0.000000\ntreatments.treatment_or_therapy           0.000000\ntreatments.treatment_type                 0.000000\ndtype: float64\n\n\n\n\nCheck for consistent data types\n\n# Check column data types\n\ncesc_df.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 872 entries, 3 to 1523\nData columns (total 35 columns):\n #   Column                                 Non-Null Count  Dtype \n---  ------                                 --------------  ----- \n 0   project.project_id                     872 non-null    object\n 1   cases.case_id                          872 non-null    object\n 2   cases.disease_type                     872 non-null    object\n 3   cases.index_date                       872 non-null    object\n 4   cases.lost_to_followup                 872 non-null    object\n 5   cases.primary_site                     872 non-null    object\n 6   cases.submitter_id                     872 non-null    object\n 7   demographic.days_to_death              62 non-null     object\n 8   demographic.ethnicity                  872 non-null    object\n 9   demographic.gender                     872 non-null    object\n 10  demographic.race                       872 non-null    object\n 11  demographic.submitter_id               872 non-null    object\n 12  demographic.vital_status               872 non-null    object\n 13  diagnoses.age_at_diagnosis             872 non-null    object\n 14  diagnoses.ajcc_pathologic_m            872 non-null    object\n 15  diagnoses.ajcc_pathologic_n            872 non-null    object\n 16  diagnoses.ajcc_pathologic_t            872 non-null    object\n 17  diagnoses.classification_of_tumor      872 non-null    object\n 18  diagnoses.days_to_diagnosis            872 non-null    object\n 19  diagnoses.days_to_last_follow_up       872 non-null    object\n 20  diagnoses.figo_stage                   872 non-null    object\n 21  diagnoses.figo_staging_edition_year    872 non-null    object\n 22  diagnoses.method_of_diagnosis          872 non-null    object\n 23  diagnoses.morphology                   872 non-null    object\n 24  diagnoses.primary_diagnosis            872 non-null    object\n 25  diagnoses.prior_malignancy             872 non-null    object\n 26  diagnoses.prior_treatment              872 non-null    object\n 27  diagnoses.site_of_resection_or_biopsy  872 non-null    object\n 28  diagnoses.submitter_id                 872 non-null    object\n 29  diagnoses.synchronous_malignancy       872 non-null    object\n 30  diagnoses.tissue_or_organ_of_origin    872 non-null    object\n 31  diagnoses.tumor_grade                  872 non-null    object\n 32  treatments.submitter_id                872 non-null    object\n 33  treatments.treatment_or_therapy        872 non-null    object\n 34  treatments.treatment_type              872 non-null    object\ndtypes: object(35)\nmemory usage: 245.2+ KB\n\n\n\n# Check the statistical summary of diagnoses.age_at_diagnosis\n\n# Convert to numeric \ncesc_df['diagnoses.age_at_diagnosis'] = pd.to_numeric(cesc_df['diagnoses.age_at_diagnosis'], errors='coerce')\n\n# Statistical summary\nprint(\"Statistical Summary of Age at Diagnosis:\")\nprint(cesc_df['diagnoses.age_at_diagnosis'].describe())\n\nprint(f\"\\nMean: {cesc_df['diagnoses.age_at_diagnosis'].mean():.2f}\")\nprint(f\"Median: {cesc_df['diagnoses.age_at_diagnosis'].median():.2f}\")\nprint(f\"Standard Deviation: {cesc_df['diagnoses.age_at_diagnosis'].std():.2f}\")\nprint(f\"Missing values: {cesc_df['diagnoses.age_at_diagnosis'].isna().sum()}\")\n\nStatistical Summary of Age at Diagnosis:\ncount      872.000000\nmean     17612.810780\nstd       4448.299744\nmin       9186.000000\n25%      14162.000000\n50%      16894.000000\n75%      20286.000000\nmax      29526.000000\nName: diagnoses.age_at_diagnosis, dtype: float64\n\nMean: 17612.81\nMedian: 16894.00\nStandard Deviation: 4448.30\nMissing values: 0\n\n\nThe age at diagnosis column has been converted to numeric but the values are in days. For analysis we will convert these to years by dividing by 365.25 (accounting for leap years) and rounding down\n\n# Convert age at diagnosis from days to years (integer)\ncesc_df['diagnoses.age_at_diagnosis'] = (cesc_df['diagnoses.age_at_diagnosis'] / 365.25).apply(np.floor)\n\n\n# Convert to integer\ncesc_df['diagnoses.age_at_diagnosis'] = pd.to_numeric(\n    cesc_df['diagnoses.age_at_diagnosis'], \n    errors='coerce'\n)\ncesc_df['diagnoses.age_at_diagnosis'].dtype\n\ndtype('float64')\n\n\n\n# Change all object type columns to lowercase\nfor col in cesc_df.select_dtypes(include=['object']).columns:\n    cesc_df[col] = cesc_df[col].astype(str).str.lower().replace('nan', np.nan)\n\n\n# Strip whitespace from string columns\nfor col in cesc_df.select_dtypes(include=['object']).columns:\n    cesc_df[col] = cesc_df[col].str.strip()\n\nChange other columns to boolean as appropriate: - diagnoses.diagnosis_is_primary_disease (from true/false strings) - diagnoses.prior_malignancy (from no/yes strings) - diagnoses.prior_treatment (from No/Yes strings) - diagnoses.synchronous_malignancy (from no/yes strings)\n\n# Convert diagnosis-related columns to boolean\n\n# Convert diagnoses.prior_malignancy (yes/no to boolean)\ncesc_df['diagnoses.prior_malignancy'] = cesc_df['diagnoses.prior_malignancy'].map({'yes': True, 'no': False})\n\n# Convert diagnoses.prior_treatment (yes/no to boolean)\ncesc_df['diagnoses.prior_treatment'] = cesc_df['diagnoses.prior_treatment'].map({'yes': True, 'no': False})\n\n# Convert diagnoses.synchronous_malignancy (yes/no to boolean)\ncesc_df['diagnoses.synchronous_malignancy'] = cesc_df['diagnoses.synchronous_malignancy'].map({'yes': True, 'no': False})\n\n# Check the conversions\nprint(\"Conversion results:\")\nprint(f\"diagnoses.prior_malignancy dtype: {cesc_df['diagnoses.prior_malignancy'].dtype}\")\nprint(f\"diagnoses.prior_treatment dtype: {cesc_df['diagnoses.prior_treatment'].dtype}\")\nprint(f\"diagnoses.synchronous_malignancy dtype: {cesc_df['diagnoses.synchronous_malignancy'].dtype}\")\n\nprint(\"\\nValue counts for each column:\")\nfor col in ['diagnoses.prior_malignancy', \n           'diagnoses.prior_treatment', 'diagnoses.synchronous_malignancy']:\n    print(f\"\\n{col}:\")\n    print(cesc_df[col].value_counts())\n\nConversion results:\ndiagnoses.prior_malignancy dtype: object\ndiagnoses.prior_treatment dtype: bool\ndiagnoses.synchronous_malignancy dtype: object\n\nValue counts for each column:\n\ndiagnoses.prior_malignancy:\ndiagnoses.prior_malignancy\nFalse    854\nTrue      15\nName: count, dtype: int64\n\ndiagnoses.prior_treatment:\ndiagnoses.prior_treatment\nFalse    872\nName: count, dtype: int64\n\ndiagnoses.synchronous_malignancy:\ndiagnoses.synchronous_malignancy\nFalse    869\nName: count, dtype: int64\n\n\n\n\nData Engineering\n\n# Percentage of missing values in each column\nmissing_percentages = cesc_df.isnull().mean() * 100\nprint(\"\\nPercentage of missing values in each column:\")\nprint(missing_percentages)\n\n\nPercentage of missing values in each column:\nproject.project_id                        0.000000\ncases.case_id                             0.000000\ncases.disease_type                        0.000000\ncases.index_date                          0.000000\ncases.lost_to_followup                    0.000000\ncases.primary_site                        0.000000\ncases.submitter_id                        0.000000\ndemographic.days_to_death                92.889908\ndemographic.ethnicity                     0.000000\ndemographic.gender                        0.000000\ndemographic.race                          0.000000\ndemographic.submitter_id                  0.000000\ndemographic.vital_status                  0.000000\ndiagnoses.age_at_diagnosis                0.000000\ndiagnoses.ajcc_pathologic_m               0.000000\ndiagnoses.ajcc_pathologic_n               0.000000\ndiagnoses.ajcc_pathologic_t               0.000000\ndiagnoses.classification_of_tumor         0.000000\ndiagnoses.days_to_diagnosis               0.000000\ndiagnoses.days_to_last_follow_up          0.000000\ndiagnoses.figo_stage                      0.000000\ndiagnoses.figo_staging_edition_year       0.000000\ndiagnoses.method_of_diagnosis             0.000000\ndiagnoses.morphology                      0.000000\ndiagnoses.primary_diagnosis               0.000000\ndiagnoses.prior_malignancy                0.344037\ndiagnoses.prior_treatment                 0.000000\ndiagnoses.site_of_resection_or_biopsy     0.000000\ndiagnoses.submitter_id                    0.000000\ndiagnoses.synchronous_malignancy          0.344037\ndiagnoses.tissue_or_organ_of_origin       0.000000\ndiagnoses.tumor_grade                     0.000000\ntreatments.submitter_id                   0.000000\ntreatments.treatment_or_therapy           0.000000\ntreatments.treatment_type                 0.000000\ndtype: float64\n\n\n\n# Check percentage of missing values in days_to_death when vital_status is 'dead'\nmissing_death_percentage = cesc_df[cesc_df['demographic.vital_status'] == 'dead']['demographic.days_to_death'].isnull().mean()\nprint(f\"Percentage of missing values in 'demographic.days_to_death' when vital_status is 'dead': {missing_death_percentage:.2%}\")    \n\nPercentage of missing values in 'demographic.days_to_death' when vital_status is 'dead': 0.00%\n\n\n\n# Percentage of missing values in days_to_last_follow_up when vital_status is 'alive'\nmissing_followup_percentage = cesc_df[cesc_df['demographic.vital_status'] == 'alive']['diagnoses.days_to_last_follow_up'].isnull().mean()\nprint(f\"Percentage of missing values in 'diagnoses.days_to_last_follow_up' when vital_status is 'alive': {missing_followup_percentage:.2%}\")\n\nPercentage of missing values in 'diagnoses.days_to_last_follow_up' when vital_status is 'alive': 0.00%\n\n\n\n# Create survival time column based on vital status\ndef calculate_survival_time(row):\n    if row['demographic.vital_status'] == 'dead':\n        return row['demographic.days_to_death']\n    elif row['demographic.vital_status'] == 'alive':\n        return row['diagnoses.days_to_last_follow_up']\n    else:\n        return np.nan\n    \ncesc_df['survival_time_days'] = cesc_df.apply(calculate_survival_time, axis=1)\n\n\n# Check percentage of missing values in survival_time_days\nmissing_percentage = cesc_df['survival_time_days'].isnull().mean() * 100\nprint(f\"Percentage of missing values in 'survival_time_days': {missing_percentage:.2f}%\")\n\nPercentage of missing values in 'survival_time_days': 0.00%\n\n\n\n# Drop rows with missing survival_time_days\ncesc_df = cesc_df[cesc_df['survival_time_days'].notna()]\ncesc_df.shape\n\n(872, 36)\n\n\n\n# Drop duplicate rows before feature engineering\ncesc_df = cesc_df.drop_duplicates()\ncesc_df.shape\n\n(872, 36)\n\n\n\n# Extract diagnoses.behavior from diagnoses.morphology column (e.g., 8500/3 -&gt; 3 where 3 is the behavior code)\n\n# Mappings for behavior codes\nbehavior_mapping = {\n    '0': 'benign',\n    '2': 'in situ',\n    '3': 'malignant'\n}\n# Extract behavior code and map to descriptive labels\ncesc_df['diagnoses.behavior'] = cesc_df['diagnoses.morphology'].str.split('/').str[1].map(behavior_mapping)\n# Check the new column\nprint(\"Value counts for diagnoses.behavior:\")\nprint(cesc_df['diagnoses.behavior'].value_counts())\n\nValue counts for diagnoses.behavior:\ndiagnoses.behavior\nmalignant    872\nName: count, dtype: int64\n\n\nNote: There is a heavy class imbalance for diagnoses.behavior as over 95% of the entries are malignant.\n\ncesc_df.head()\n\n\n\n\n\n\n\n\nproject.project_id\ncases.case_id\ncases.disease_type\ncases.index_date\ncases.lost_to_followup\ncases.primary_site\ncases.submitter_id\ndemographic.days_to_death\ndemographic.ethnicity\ndemographic.gender\ndemographic.race\ndemographic.submitter_id\ndemographic.vital_status\ndiagnoses.age_at_diagnosis\ndiagnoses.ajcc_pathologic_m\ndiagnoses.ajcc_pathologic_n\ndiagnoses.ajcc_pathologic_t\ndiagnoses.classification_of_tumor\ndiagnoses.days_to_diagnosis\ndiagnoses.days_to_last_follow_up\ndiagnoses.figo_stage\ndiagnoses.figo_staging_edition_year\ndiagnoses.method_of_diagnosis\ndiagnoses.morphology\ndiagnoses.primary_diagnosis\ndiagnoses.prior_malignancy\ndiagnoses.prior_treatment\ndiagnoses.site_of_resection_or_biopsy\ndiagnoses.submitter_id\ndiagnoses.synchronous_malignancy\ndiagnoses.tissue_or_organ_of_origin\ndiagnoses.tumor_grade\ntreatments.submitter_id\ntreatments.treatment_or_therapy\ntreatments.treatment_type\nsurvival_time_days\ndiagnoses.behavior\n\n\n\n\n3\ntcga-cesc\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nsquamous cell neoplasms\ndiagnosis\nyes\ncervix uteri\ntcga-c5-a2lv\nNaN\nnot hispanic or latino\nfemale\nblack or african american\ntcga-c5-a2lv_demographic\nalive\n36.0\nmx\nn1\nt1b\nprimary\n0\n2234.0\nstage ib\n1995\nbiopsy\n8070/3\nsquamous cell carcinoma, nos\nFalse\nFalse\ncervix uteri\ntcga-c5-a2lv_diagnosis\nFalse\ncervix uteri\ng3\ntcga-c5-a2lv_treatment3\nyes\nhysterectomy, nos\n2234.0\nmalignant\n\n\n4\ntcga-cesc\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nsquamous cell neoplasms\ndiagnosis\nyes\ncervix uteri\ntcga-c5-a2lv\nNaN\nnot hispanic or latino\nfemale\nblack or african american\ntcga-c5-a2lv_demographic\nalive\n36.0\nmx\nn1\nt1b\nprimary\n0\n2234.0\nstage ib\n1995\nbiopsy\n8070/3\nsquamous cell carcinoma, nos\nFalse\nFalse\ncervix uteri\ntcga-c5-a2lv_diagnosis\nFalse\ncervix uteri\ng3\ntcga-c5-a2lv_treatment2\nno\nradiation therapy, nos\n2234.0\nmalignant\n\n\n5\ntcga-cesc\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nsquamous cell neoplasms\ndiagnosis\nyes\ncervix uteri\ntcga-c5-a2lv\nNaN\nnot hispanic or latino\nfemale\nblack or african american\ntcga-c5-a2lv_demographic\nalive\n36.0\nmx\nn1\nt1b\nprimary\n0\n2234.0\nstage ib\n1995\nbiopsy\n8070/3\nsquamous cell carcinoma, nos\nFalse\nFalse\ncervix uteri\ntcga-c5-a2lv_diagnosis\nFalse\ncervix uteri\ng3\ntcga-c5-a2lv_treatment\nno\npharmaceutical therapy, nos\n2234.0\nmalignant\n\n\n11\ntcga-cesc\n03804f9b-df7c-462c-8984-8eb3a5ed4999\nsquamous cell neoplasms\ndiagnosis\nno\ncervix uteri\ntcga-vs-a9v2\nNaN\nnot reported\nfemale\nwhite\ntcga-vs-a9v2_demographic\nalive\n29.0\nmx\nn0\nt1b\nprimary\n0\n555.0\nstage ib1\n2009\nbiopsy\n8070/3\nsquamous cell carcinoma, nos\nFalse\nFalse\ncervix uteri\ntcga-vs-a9v2_diagnosis\nFalse\ncervix uteri\ng2\ntcga-vs-a9v2_treatment3\nyes\nradiation, 3d conformal\n555.0\nmalignant\n\n\n12\ntcga-cesc\n03804f9b-df7c-462c-8984-8eb3a5ed4999\nsquamous cell neoplasms\ndiagnosis\nno\ncervix uteri\ntcga-vs-a9v2\nNaN\nnot reported\nfemale\nwhite\ntcga-vs-a9v2_demographic\nalive\n29.0\nmx\nn0\nt1b\nprimary\n0\n555.0\nstage ib1\n2009\nbiopsy\n8070/3\nsquamous cell carcinoma, nos\nFalse\nFalse\ncervix uteri\ntcga-vs-a9v2_diagnosis\nFalse\ncervix uteri\ng2\ntcga-vs-a9v2_treatment2\nno\npharmaceutical therapy, nos\n555.0\nmalignant\n\n\n\n\n\n\n\n\n# Check distribution of missing values in columns after cleaning and data engineering\nmissing_percentages = cesc_df.isnull().mean() * 100\nprint(\"\\nPercentage of missing values in each column:\")\nprint(missing_percentages)\n\n\nPercentage of missing values in each column:\nproject.project_id                        0.000000\ncases.case_id                             0.000000\ncases.disease_type                        0.000000\ncases.index_date                          0.000000\ncases.lost_to_followup                    0.000000\ncases.primary_site                        0.000000\ncases.submitter_id                        0.000000\ndemographic.days_to_death                92.889908\ndemographic.ethnicity                     0.000000\ndemographic.gender                        0.000000\ndemographic.race                          0.000000\ndemographic.submitter_id                  0.000000\ndemographic.vital_status                  0.000000\ndiagnoses.age_at_diagnosis                0.000000\ndiagnoses.ajcc_pathologic_m               0.000000\ndiagnoses.ajcc_pathologic_n               0.000000\ndiagnoses.ajcc_pathologic_t               0.000000\ndiagnoses.classification_of_tumor         0.000000\ndiagnoses.days_to_diagnosis               0.000000\ndiagnoses.days_to_last_follow_up          0.000000\ndiagnoses.figo_stage                      0.000000\ndiagnoses.figo_staging_edition_year       0.000000\ndiagnoses.method_of_diagnosis             0.000000\ndiagnoses.morphology                      0.000000\ndiagnoses.primary_diagnosis               0.000000\ndiagnoses.prior_malignancy                0.344037\ndiagnoses.prior_treatment                 0.000000\ndiagnoses.site_of_resection_or_biopsy     0.000000\ndiagnoses.submitter_id                    0.000000\ndiagnoses.synchronous_malignancy          0.344037\ndiagnoses.tissue_or_organ_of_origin       0.000000\ndiagnoses.tumor_grade                     0.000000\ntreatments.submitter_id                   0.000000\ntreatments.treatment_or_therapy           0.000000\ntreatments.treatment_type                 0.000000\nsurvival_time_days                        0.000000\ndiagnoses.behavior                        0.000000\ndtype: float64\n\n\n\n# Replace missing prior_malignancy and synchronous_malignancy with False\ncesc_df['diagnoses.prior_malignancy'] = cesc_df['diagnoses.prior_malignancy'].fillna(False)\ncesc_df['diagnoses.synchronous_malignancy'] = cesc_df['diagnoses.synchronous_malignancy'].fillna(False)\n\n\ncesc_df.head(1)\n\n\n\n\n\n\n\n\nproject.project_id\ncases.case_id\ncases.disease_type\ncases.index_date\ncases.lost_to_followup\ncases.primary_site\ncases.submitter_id\ndemographic.days_to_death\ndemographic.ethnicity\ndemographic.gender\ndemographic.race\ndemographic.submitter_id\ndemographic.vital_status\ndiagnoses.age_at_diagnosis\ndiagnoses.ajcc_pathologic_m\ndiagnoses.ajcc_pathologic_n\ndiagnoses.ajcc_pathologic_t\ndiagnoses.classification_of_tumor\ndiagnoses.days_to_diagnosis\ndiagnoses.days_to_last_follow_up\ndiagnoses.figo_stage\ndiagnoses.figo_staging_edition_year\ndiagnoses.method_of_diagnosis\ndiagnoses.morphology\ndiagnoses.primary_diagnosis\ndiagnoses.prior_malignancy\ndiagnoses.prior_treatment\ndiagnoses.site_of_resection_or_biopsy\ndiagnoses.submitter_id\ndiagnoses.synchronous_malignancy\ndiagnoses.tissue_or_organ_of_origin\ndiagnoses.tumor_grade\ntreatments.submitter_id\ntreatments.treatment_or_therapy\ntreatments.treatment_type\nsurvival_time_days\ndiagnoses.behavior\n\n\n\n\n3\ntcga-cesc\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nsquamous cell neoplasms\ndiagnosis\nyes\ncervix uteri\ntcga-c5-a2lv\nNaN\nnot hispanic or latino\nfemale\nblack or african american\ntcga-c5-a2lv_demographic\nalive\n36.0\nmx\nn1\nt1b\nprimary\n0\n2234.0\nstage ib\n1995\nbiopsy\n8070/3\nsquamous cell carcinoma, nos\nFalse\nFalse\ncervix uteri\ntcga-c5-a2lv_diagnosis\nFalse\ncervix uteri\ng3\ntcga-c5-a2lv_treatment3\nyes\nhysterectomy, nos\n2234.0\nmalignant\n\n\n\n\n\n\n\n\n\nCervical cancer exposure data cleaning\n\n# Open cesc exposure tsv data\n\ncesc_exposure_df = pd.read_csv('data/raw-data/cesc/exposure.tsv', sep='\\t')\ncesc_exposure_df.head(3)\n\n\n\n\n\n\n\n\nproject.project_id\ncases.case_id\ncases.submitter_id\nexposures.age_at_last_exposure\nexposures.age_at_onset\nexposures.alcohol_days_per_week\nexposures.alcohol_drinks_per_day\nexposures.alcohol_frequency\nexposures.alcohol_history\nexposures.alcohol_intensity\nexposures.alcohol_type\nexposures.asbestos_exposure\nexposures.asbestos_exposure_type\nexposures.chemical_exposure_type\nexposures.cigarettes_per_day\nexposures.coal_dust_exposure\nexposures.environmental_tobacco_smoke_exposure\nexposures.exposure_duration\nexposures.exposure_duration_hrs_per_day\nexposures.exposure_duration_years\nexposures.exposure_id\nexposures.exposure_source\nexposures.exposure_type\nexposures.occupation_duration_years\nexposures.occupation_type\nexposures.pack_years_smoked\nexposures.parent_with_radiation_exposure\nexposures.radon_exposure\nexposures.respirable_crystalline_silica_exposure\nexposures.secondhand_smoke_as_child\nexposures.smoking_frequency\nexposures.submitter_id\nexposures.time_between_waking_and_first_smoke\nexposures.tobacco_smoking_onset_year\nexposures.tobacco_smoking_quit_year\nexposures.tobacco_smoking_status\nexposures.type_of_smoke_exposure\nexposures.type_of_tobacco_used\nexposures.use_per_day\nexposures.years_smoked\n\n\n\n\n0\nTCGA-CESC\n00ad0ffe-2105-4829-a495-1c2aceb5bb31\nTCGA-EK-A2R9\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\nTobacco\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\nNot Reported\n'--\n'--\n'--\n'--\n\n\n1\nTCGA-CESC\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nTCGA-C5-A2LV\n'--\n20\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\nTobacco\n'--\n'--\n16.0\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\nCurrent Smoker\n'--\n'--\n'--\n'--\n\n\n2\nTCGA-CESC\n010a807f-9dc0-4e14-9533-dcf478f3d947\nTCGA-C5-A902\n'--\n14\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\nTobacco\n'--\n'--\n21.0\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\nCurrent Smoker\n'--\n'--\n'--\n'--\n\n\n\n\n\n\n\n\n# Change every column to lowercase\nfor col in cesc_exposure_df.select_dtypes(include=['object']).columns:\n    cesc_exposure_df[col] = cesc_exposure_df[col].astype(str).str.lower().replace('nan', np.nan)\n\n\n# Strip whitespace from string columns\nfor col in cesc_exposure_df.select_dtypes(include=['object']).columns:\n    cesc_exposure_df[col] = cesc_exposure_df[col].str.strip()\n\n\n# Double check for common cases.submitter_id between clinical and exposure datasets\ncommon_ids = set(cesc_df['cases.submitter_id']).intersection(set(cesc_exposure_df['cases.submitter_id']))\nprint(f\"Number of common cases.submitter_id between clinical and exposure datasets: {len(common_ids)}\")\n\nNumber of common cases.submitter_id between clinical and exposure datasets: 184\n\n\n\n# Replace \"'--\" as NA\ncesc_exposure_df.replace('\\'--', np.nan, inplace=True)\ncesc_exposure_df.replace('\\'--', np.nan, inplace=True)\n\n\n# Check distribution of null values in exposure dataset\nmissing_percentages = cesc_exposure_df.isnull().mean() * 100\nprint(\"\\nPercentage of missing values in each column of exposure dataset:\")\nprint(missing_percentages)\n\n\nPercentage of missing values in each column of exposure dataset:\nproject.project_id                                    0.000000\ncases.case_id                                         0.000000\ncases.submitter_id                                    0.000000\nexposures.age_at_last_exposure                      100.000000\nexposures.age_at_onset                               72.312704\nexposures.alcohol_days_per_week                     100.000000\nexposures.alcohol_drinks_per_day                    100.000000\nexposures.alcohol_frequency                         100.000000\nexposures.alcohol_history                           100.000000\nexposures.alcohol_intensity                         100.000000\nexposures.alcohol_type                              100.000000\nexposures.asbestos_exposure                         100.000000\nexposures.asbestos_exposure_type                    100.000000\nexposures.chemical_exposure_type                    100.000000\nexposures.cigarettes_per_day                        100.000000\nexposures.coal_dust_exposure                        100.000000\nexposures.environmental_tobacco_smoke_exposure      100.000000\nexposures.exposure_duration                         100.000000\nexposures.exposure_duration_hrs_per_day             100.000000\nexposures.exposure_duration_years                   100.000000\nexposures.exposure_id                               100.000000\nexposures.exposure_source                           100.000000\nexposures.exposure_type                               0.000000\nexposures.occupation_duration_years                 100.000000\nexposures.occupation_type                           100.000000\nexposures.pack_years_smoked                          69.706840\nexposures.parent_with_radiation_exposure            100.000000\nexposures.radon_exposure                            100.000000\nexposures.respirable_crystalline_silica_exposure    100.000000\nexposures.secondhand_smoke_as_child                 100.000000\nexposures.smoking_frequency                         100.000000\nexposures.submitter_id                              100.000000\nexposures.time_between_waking_and_first_smoke       100.000000\nexposures.tobacco_smoking_onset_year                100.000000\nexposures.tobacco_smoking_quit_year                  85.993485\nexposures.tobacco_smoking_status                      0.000000\nexposures.type_of_smoke_exposure                    100.000000\nexposures.type_of_tobacco_used                      100.000000\nexposures.use_per_day                               100.000000\nexposures.years_smoked                              100.000000\ndtype: float64\n\n\n\n# Check exposures.tobacco_smoking_status column since they are the only ones with low missing values\nsmoking_status_counts = cesc_exposure_df['exposures.tobacco_smoking_status'].value_counts(dropna=False)\nprint(\"\\nexposures.tobacco_smoking_status distribution:\")\nprint(smoking_status_counts)\n\n\nexposures.tobacco_smoking_status distribution:\nexposures.tobacco_smoking_status\nlifelong non-smoker                                146\ncurrent smoker                                      64\ncurrent reformed smoker for &lt; or = 15 yrs           40\nnot reported                                        32\nunknown                                             12\ncurrent reformed smoker for &gt; 15 yrs                 9\ncurrent reformed smoker, duration not specified      4\nName: count, dtype: int64\n\n\n\n# Join clinical and exposure datasets on cases.submitter_id preserving only exposures.tobacco_smoking_status from exposure dataset\ncesc_merged_df = pd.merge(\n    cesc_df,\n    cesc_exposure_df[['cases.submitter_id', 'exposures.tobacco_smoking_status']],\n    on='cases.submitter_id',\n    how='left'\n)\n\n\ncesc_exposure_df[\"exposures.tobacco_smoking_status\"].head(5)\n\n0                                 not reported\n1                               current smoker\n2                               current smoker\n3                          lifelong non-smoker\n4    current reformed smoker for &lt; or = 15 yrs\nName: exposures.tobacco_smoking_status, dtype: object\n\n\n\ncesc_merged_df.head(1)\n\n\n\n\n\n\n\n\nproject.project_id\ncases.case_id\ncases.disease_type\ncases.index_date\ncases.lost_to_followup\ncases.primary_site\ncases.submitter_id\ndemographic.days_to_death\ndemographic.ethnicity\ndemographic.gender\ndemographic.race\ndemographic.submitter_id\ndemographic.vital_status\ndiagnoses.age_at_diagnosis\ndiagnoses.ajcc_pathologic_m\ndiagnoses.ajcc_pathologic_n\ndiagnoses.ajcc_pathologic_t\ndiagnoses.classification_of_tumor\ndiagnoses.days_to_diagnosis\ndiagnoses.days_to_last_follow_up\ndiagnoses.figo_stage\ndiagnoses.figo_staging_edition_year\ndiagnoses.method_of_diagnosis\ndiagnoses.morphology\ndiagnoses.primary_diagnosis\ndiagnoses.prior_malignancy\ndiagnoses.prior_treatment\ndiagnoses.site_of_resection_or_biopsy\ndiagnoses.submitter_id\ndiagnoses.synchronous_malignancy\ndiagnoses.tissue_or_organ_of_origin\ndiagnoses.tumor_grade\ntreatments.submitter_id\ntreatments.treatment_or_therapy\ntreatments.treatment_type\nsurvival_time_days\ndiagnoses.behavior\nexposures.tobacco_smoking_status\n\n\n\n\n0\ntcga-cesc\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nsquamous cell neoplasms\ndiagnosis\nyes\ncervix uteri\ntcga-c5-a2lv\nNaN\nnot hispanic or latino\nfemale\nblack or african american\ntcga-c5-a2lv_demographic\nalive\n36.0\nmx\nn1\nt1b\nprimary\n0\n2234.0\nstage ib\n1995\nbiopsy\n8070/3\nsquamous cell carcinoma, nos\nFalse\nFalse\ncervix uteri\ntcga-c5-a2lv_diagnosis\nFalse\ncervix uteri\ng3\ntcga-c5-a2lv_treatment3\nyes\nhysterectomy, nos\n2234.0\nmalignant\ncurrent smoker\n\n\n\n\n\n\n\n\n# View percentage of missing values in columns after merging\nmissing_percentages = cesc_merged_df.isnull().mean() * 100\nprint(\"\\nPercentage of missing values in each column after merging:\")\nprint(missing_percentages)\n\n\nPercentage of missing values in each column after merging:\nproject.project_id                        0.000000\ncases.case_id                             0.000000\ncases.disease_type                        0.000000\ncases.index_date                          0.000000\ncases.lost_to_followup                    0.000000\ncases.primary_site                        0.000000\ncases.submitter_id                        0.000000\ndemographic.days_to_death                92.889908\ndemographic.ethnicity                     0.000000\ndemographic.gender                        0.000000\ndemographic.race                          0.000000\ndemographic.submitter_id                  0.000000\ndemographic.vital_status                  0.000000\ndiagnoses.age_at_diagnosis                0.000000\ndiagnoses.ajcc_pathologic_m               0.000000\ndiagnoses.ajcc_pathologic_n               0.000000\ndiagnoses.ajcc_pathologic_t               0.000000\ndiagnoses.classification_of_tumor         0.000000\ndiagnoses.days_to_diagnosis               0.000000\ndiagnoses.days_to_last_follow_up          0.000000\ndiagnoses.figo_stage                      0.000000\ndiagnoses.figo_staging_edition_year       0.000000\ndiagnoses.method_of_diagnosis             0.000000\ndiagnoses.morphology                      0.000000\ndiagnoses.primary_diagnosis               0.000000\ndiagnoses.prior_malignancy                0.000000\ndiagnoses.prior_treatment                 0.000000\ndiagnoses.site_of_resection_or_biopsy     0.000000\ndiagnoses.submitter_id                    0.000000\ndiagnoses.synchronous_malignancy          0.000000\ndiagnoses.tissue_or_organ_of_origin       0.000000\ndiagnoses.tumor_grade                     0.000000\ntreatments.submitter_id                   0.000000\ntreatments.treatment_or_therapy           0.000000\ntreatments.treatment_type                 0.000000\nsurvival_time_days                        0.000000\ndiagnoses.behavior                        0.000000\nexposures.tobacco_smoking_status          0.000000\ndtype: float64\n\n\n\n\nSave processed dataset\n\n# Save cleaned dataset to a new TSV file\ncesc_merged_df.to_csv(\"data/processed-data/cesc/cesc-clinical-processed.tsv\", sep=\"\\t\", index=False)"
  },
  {
    "objectID": "technical-details/unsupervised-learning/instructions.html",
    "href": "technical-details/unsupervised-learning/instructions.html",
    "title": "Instructions",
    "section": "",
    "text": "Note: You should remove these instructions once you have read and understood them. They should not be included in your final submission.\nRemember: Exactly what do you put on this page will be specific you your project and data. Some things might “make more sense” on one page rather than another, depending on your workflow. Organize your project in a logical way that makes the most sense to you.\n\n\nHere’s one suggested structure for organizing your technical pages. You can adjust this as needed:\nAudience:Remember that these are written for a technical audience. Assume they have completed the DSAN program, but would appreciate refreshers of the important concepts.\n\nIntroduction and Motivation: Briefly outline your plan. What are you doing on this page, and why? Provide context and explain the goals of your analysis.\nOverview of Methods: Give a concise explanation of the methods used. For example, if using K-Means clustering, describe what it is, how it works, the inputs and outputs, and key hyperparameters.\nCode: Include the code you used to implement your workflow.\nSummary and Interpretation of Results: Summarize your findings, interpret the results, and discuss their technical implications.\n\n\n\n\nThe following is a list of some of the things you should address on this page. This list is not exhaustive, and you should use your judgment to decide what is most relevant to your project.\nThis page is designed to give you hands-on experience with key unsupervised learning techniques, including clustering methods and dimensionality reduction, applied to real-world datasets. Please apply algorithms such as K-Means, DBSCAN, Hierarchical clustering, PCA, and t-SNE to your data. Through this process, you’ll deepen your understanding of how unsupervised learning can reveal hidden patterns and structure in data.\n\n\nThe objective of this section is to explore and demonstrate the effectiveness of PCA and t-SNE in reducing the dimensionality of complex data while preserving essential information and improving visualization.\n\nPCA (Principal Component Analysis):\n\nApply PCA to your dataset.\nDetermine the optimal number of principal components.\nVisualize the reduced-dimensional data.\nAnalyze and interpret the results.\n\nt-SNE (t-distributed Stochastic Neighbor Embedding):\n\nImplement t-SNE on the same dataset.\nExperiment with different perplexity values.\nVisualize the t-SNE output to reveal patterns and clusters.\nCompare the results of t-SNE with those from PCA.\n\nEvaluation and Comparison:\n\nEvaluate the effectiveness of PCA and t-SNE in preserving data structure.\nCompare the visualization capabilities of both techniques.\nDiscuss the trade-offs and scenarios where one technique may perform better than the other.\n\n\n\n\n\nApply clustering techniques (K-Means, DBSCAN, and Hierarchical clustering) to a selected dataset. The goal is to understand how each method works, compare their performance, and interpret the results.\n\nClustering Methods:\n\nApply K-Means, DBSCAN, and Hierarchical clustering to your dataset.\nWrite a technical summary for each method (2–4 paragraphs per method) explaining how it works, its purpose, and any model selection methods used (e.g., Elbow, Silhouette).\n\nResults Section:\n\nDiscuss and visualize the results of each clustering analysis.\nCompare the performance of different clustering methods, noting any insights gained from the analysis.\nVisualize cluster patterns and how they relate (if at all) to existing labels in the dataset.\nUse professional, labeled, and clear visualizations that support your discussion.\n\nConclusion:\n\nSummarize the key findings and their real-world implications in a non-technical way. Focus on the most important results and how they could apply to practical situations."
  },
  {
    "objectID": "technical-details/unsupervised-learning/instructions.html#suggested-page-structure",
    "href": "technical-details/unsupervised-learning/instructions.html#suggested-page-structure",
    "title": "Instructions",
    "section": "",
    "text": "Here’s one suggested structure for organizing your technical pages. You can adjust this as needed:\nAudience:Remember that these are written for a technical audience. Assume they have completed the DSAN program, but would appreciate refreshers of the important concepts.\n\nIntroduction and Motivation: Briefly outline your plan. What are you doing on this page, and why? Provide context and explain the goals of your analysis.\nOverview of Methods: Give a concise explanation of the methods used. For example, if using K-Means clustering, describe what it is, how it works, the inputs and outputs, and key hyperparameters.\nCode: Include the code you used to implement your workflow.\nSummary and Interpretation of Results: Summarize your findings, interpret the results, and discuss their technical implications."
  },
  {
    "objectID": "technical-details/unsupervised-learning/instructions.html#what-to-address",
    "href": "technical-details/unsupervised-learning/instructions.html#what-to-address",
    "title": "Instructions",
    "section": "",
    "text": "The following is a list of some of the things you should address on this page. This list is not exhaustive, and you should use your judgment to decide what is most relevant to your project.\nThis page is designed to give you hands-on experience with key unsupervised learning techniques, including clustering methods and dimensionality reduction, applied to real-world datasets. Please apply algorithms such as K-Means, DBSCAN, Hierarchical clustering, PCA, and t-SNE to your data. Through this process, you’ll deepen your understanding of how unsupervised learning can reveal hidden patterns and structure in data.\n\n\nThe objective of this section is to explore and demonstrate the effectiveness of PCA and t-SNE in reducing the dimensionality of complex data while preserving essential information and improving visualization.\n\nPCA (Principal Component Analysis):\n\nApply PCA to your dataset.\nDetermine the optimal number of principal components.\nVisualize the reduced-dimensional data.\nAnalyze and interpret the results.\n\nt-SNE (t-distributed Stochastic Neighbor Embedding):\n\nImplement t-SNE on the same dataset.\nExperiment with different perplexity values.\nVisualize the t-SNE output to reveal patterns and clusters.\nCompare the results of t-SNE with those from PCA.\n\nEvaluation and Comparison:\n\nEvaluate the effectiveness of PCA and t-SNE in preserving data structure.\nCompare the visualization capabilities of both techniques.\nDiscuss the trade-offs and scenarios where one technique may perform better than the other.\n\n\n\n\n\nApply clustering techniques (K-Means, DBSCAN, and Hierarchical clustering) to a selected dataset. The goal is to understand how each method works, compare their performance, and interpret the results.\n\nClustering Methods:\n\nApply K-Means, DBSCAN, and Hierarchical clustering to your dataset.\nWrite a technical summary for each method (2–4 paragraphs per method) explaining how it works, its purpose, and any model selection methods used (e.g., Elbow, Silhouette).\n\nResults Section:\n\nDiscuss and visualize the results of each clustering analysis.\nCompare the performance of different clustering methods, noting any insights gained from the analysis.\nVisualize cluster patterns and how they relate (if at all) to existing labels in the dataset.\nUse professional, labeled, and clear visualizations that support your discussion.\n\nConclusion:\n\nSummarize the key findings and their real-world implications in a non-technical way. Focus on the most important results and how they could apply to practical situations."
  },
  {
    "objectID": "technical-details/progress-log.html",
    "href": "technical-details/progress-log.html",
    "title": "Progress log",
    "section": "",
    "text": "Use this page to track your progress and keep a log of your contributions to the project, please update this each time you work on your project, it is generally a good habit to adopt.\nIf you are working as a team, at the end, you can duplicate the project and add it to your individual portfolio websites. If you do, you MUST retain attribution to your teammates. Removing attribution would constitute plagiarism."
  },
  {
    "objectID": "technical-details/progress-log.html#to-do",
    "href": "technical-details/progress-log.html#to-do",
    "title": "Progress log",
    "section": "To-do",
    "text": "To-do\n\nExplore possible topics by brainstorming with GPT\nwrite a technical methods sections for K-means\nwrite a technical methods sections for PCA\n\n… etc"
  },
  {
    "objectID": "technical-details/progress-log.html#member-1",
    "href": "technical-details/progress-log.html#member-1",
    "title": "Progress log",
    "section": "Member-1:",
    "text": "Member-1:\nProvide their name, a link to their “About Me” page.\nAlso, describe a log of their project roles.\nWeekly project contribution log:\nT: 10-15-2024\n\nCoordinate with team member to set up weekly meeting time\n\nM: 10-14-2024\n\nDo a first draft of the project landing page"
  },
  {
    "objectID": "technical-details/progress-log.html#member-2",
    "href": "technical-details/progress-log.html#member-2",
    "title": "Progress log",
    "section": "Member-2",
    "text": "Member-2\nProvide their name, a link to their “About Me” page.\nAlso, describe a log of their project roles.\nWeekly project contribution log:\nW: 10-16-2024\n\nAttend first group meeting"
  },
  {
    "objectID": "technical-details/eda/instructions.html",
    "href": "technical-details/eda/instructions.html",
    "title": "Instructions",
    "section": "",
    "text": "Note: You should remove these instructions once you have read and understood them. They should not be included in your final submission.\nRemember: Exactly what do you put on this page will be specific you your project and data. Some things might “make more sense” on one page rather than another, depending on your workflow. Organize your project in a logical way that makes the most sense to you.\n\n\nHere’s one suggested structure for organizing your technical pages. You can adjust this as needed:\nAudience:Remember that these are written for a technical audience. Assume they have completed the DSAN program, but would appreciate refreshers of the important concepts.\n\nIntroduction and Motivation: Briefly outline your plan. What are you doing on this page, and why? Provide context and explain the goals of your analysis.\nOverview of Methods: Give a concise explanation of the methods used. For example, if using K-Means clustering, describe what it is, how it works, the inputs and outputs, and key hyperparameters.\nCode: Include the code you used to implement your workflow.\nSummary and Interpretation of Results: Summarize your findings, interpret the results, and discuss their technical implications.\n\n\n\n\nThe following is a list of some of the things you should address on this page. This list is not exhaustive, and you should use your judgment to decide what is most relevant to your project.\nThe EDA (Exploratory Data Analysis) tab in your portfolio serves as a crucial foundation for your project. It provides a thorough overview of the dataset, highlights patterns, identifies potential issues, and prepares the data for further analysis. Follow these instructions to document your EDA effectively:\nThe goal of EDA is to gain a deeper understanding of the dataset and its relevance to your project’s objectives. It involves summarizing key data characteristics, identifying patterns, anomalies, and preparing for future analysis phases.\nHere are suggestions for things to include on this page\nUnivariate Analysis:\n\nNumerical Variables:\n\nProvide summary statistics (mean, median, standard deviation).\nVisualize distributions using histograms or density plots.\n\nCategorical Variables:\n\nPresent frequency counts and visualize distributions using bar charts or pie charts.\n\nKey Insights:\n\nHighlight any notable trends or patterns observed.\n\n\nBivariate and Multivariate Analysis:\n\nCorrelation Analysis:\n\nAnalyze relationships between numerical variables using a correlation matrix.\nVisualize with heatmaps or pair plots and discuss any strong correlations.\n\nCrosstabulations:\n\nFor categorical variables, use crosstabs to explore relationships and visualize them with grouped bar plots.\n\nFeature Pairings:\n\nAnalyze relationships between key variables, particularly those related to your target.\nVisualize with scatter plots, box plots, or violin plots.\n\n\nData Distribution and Normalization:\n\nSkewness and Kurtosis:\nAnalyze and discuss the distribution of variables.\nApply transformations (e.g., log transformation) if needed for skewed data.\nNormalization:\nApply normalization or scaling techniques (e.g., min-max scaling, z-score).\nDocument and visualize the impact of normalization.\n\nStatistical Insights:\n\nConduct basic statistical tests (e.g., T-tests, ANOVA, chi-square) to explore relationships between variables.\nSummarize the statistical results and their implications for your analysis.\n\nData Visualization and Storytelling:\n\nVisual Summary:\nPresent key insights using charts and visualizations (e.g., Matplotlib, Seaborn, Plotly).\nEnsure all visualizations are well-labeled and easy to interpret.\nInteractive Visualizations (Optional):\nInclude interactive elements (e.g., Plotly, Bokeh) to allow users to explore the data further.\n\nConclusions and Next Steps:\n\nSummary of EDA Findings:\nHighlight the main takeaways from the EDA process (key trends, patterns, data quality issues).\nImplications for Modeling:\nDiscuss how your EDA informs the next steps in your project (e.g., feature selection, data transformations).\nOutline any further data cleaning or preparation required before moving into modeling."
  },
  {
    "objectID": "technical-details/eda/instructions.html#suggested-page-structure",
    "href": "technical-details/eda/instructions.html#suggested-page-structure",
    "title": "Instructions",
    "section": "",
    "text": "Here’s one suggested structure for organizing your technical pages. You can adjust this as needed:\nAudience:Remember that these are written for a technical audience. Assume they have completed the DSAN program, but would appreciate refreshers of the important concepts.\n\nIntroduction and Motivation: Briefly outline your plan. What are you doing on this page, and why? Provide context and explain the goals of your analysis.\nOverview of Methods: Give a concise explanation of the methods used. For example, if using K-Means clustering, describe what it is, how it works, the inputs and outputs, and key hyperparameters.\nCode: Include the code you used to implement your workflow.\nSummary and Interpretation of Results: Summarize your findings, interpret the results, and discuss their technical implications."
  },
  {
    "objectID": "technical-details/eda/instructions.html#what-to-address",
    "href": "technical-details/eda/instructions.html#what-to-address",
    "title": "Instructions",
    "section": "",
    "text": "The following is a list of some of the things you should address on this page. This list is not exhaustive, and you should use your judgment to decide what is most relevant to your project.\nThe EDA (Exploratory Data Analysis) tab in your portfolio serves as a crucial foundation for your project. It provides a thorough overview of the dataset, highlights patterns, identifies potential issues, and prepares the data for further analysis. Follow these instructions to document your EDA effectively:\nThe goal of EDA is to gain a deeper understanding of the dataset and its relevance to your project’s objectives. It involves summarizing key data characteristics, identifying patterns, anomalies, and preparing for future analysis phases.\nHere are suggestions for things to include on this page\nUnivariate Analysis:\n\nNumerical Variables:\n\nProvide summary statistics (mean, median, standard deviation).\nVisualize distributions using histograms or density plots.\n\nCategorical Variables:\n\nPresent frequency counts and visualize distributions using bar charts or pie charts.\n\nKey Insights:\n\nHighlight any notable trends or patterns observed.\n\n\nBivariate and Multivariate Analysis:\n\nCorrelation Analysis:\n\nAnalyze relationships between numerical variables using a correlation matrix.\nVisualize with heatmaps or pair plots and discuss any strong correlations.\n\nCrosstabulations:\n\nFor categorical variables, use crosstabs to explore relationships and visualize them with grouped bar plots.\n\nFeature Pairings:\n\nAnalyze relationships between key variables, particularly those related to your target.\nVisualize with scatter plots, box plots, or violin plots.\n\n\nData Distribution and Normalization:\n\nSkewness and Kurtosis:\nAnalyze and discuss the distribution of variables.\nApply transformations (e.g., log transformation) if needed for skewed data.\nNormalization:\nApply normalization or scaling techniques (e.g., min-max scaling, z-score).\nDocument and visualize the impact of normalization.\n\nStatistical Insights:\n\nConduct basic statistical tests (e.g., T-tests, ANOVA, chi-square) to explore relationships between variables.\nSummarize the statistical results and their implications for your analysis.\n\nData Visualization and Storytelling:\n\nVisual Summary:\nPresent key insights using charts and visualizations (e.g., Matplotlib, Seaborn, Plotly).\nEnsure all visualizations are well-labeled and easy to interpret.\nInteractive Visualizations (Optional):\nInclude interactive elements (e.g., Plotly, Bokeh) to allow users to explore the data further.\n\nConclusions and Next Steps:\n\nSummary of EDA Findings:\nHighlight the main takeaways from the EDA process (key trends, patterns, data quality issues).\nImplications for Modeling:\nDiscuss how your EDA informs the next steps in your project (e.g., feature selection, data transformations).\nOutline any further data cleaning or preparation required before moving into modeling."
  },
  {
    "objectID": "technical-details/data-collection/methods.html",
    "href": "technical-details/data-collection/methods.html",
    "title": "Methods",
    "section": "",
    "text": "Methods\nIn this section, provide an overview summary of the methods used on this page. This should include a brief description of the key techniques, algorithms, tools, or processes employed in your work. Make sure to outline the approach taken for data collection, processing, analysis, or any specific technical steps relevant to the project.\nIf you are developing a package, include a reference to the relevant documentation and provide a link here for easy access. Ensure that the package details are properly documented in its dedicated section, but mentioned and connected here for a complete understanding of the methods used in this project."
  },
  {
    "objectID": "technical-details/data-collection/closing.html",
    "href": "technical-details/data-collection/closing.html",
    "title": "Summary",
    "section": "",
    "text": "This section should be written for a technical audience, focusing on detailed analysis, factual reporting, and clear presentation of data. The following serves as a guide, but feel free to adjust as needed.\n\n\n\nDiscuss any technical challenges faced during the project, such as data limitations, computational issues, or obstacles encountered during analysis.\nExplain unexpected results and their technical implications.\nIdentify areas for future work, including potential optimizations, further analysis, or scaling solutions.\n\n\n\n\n\nCompare your findings to relevant research, industry benchmarks, or intuitive expectations, if applicable.\n\n\n\n\n\nSummarize the key technical points and outcomes of the project.\nSuggest potential improvements or refinements to this part of the project.\nBased on the results, provide actionable recommendations for further research or optimization efforts."
  },
  {
    "objectID": "technical-details/data-collection/closing.html#challenges",
    "href": "technical-details/data-collection/closing.html#challenges",
    "title": "Summary",
    "section": "",
    "text": "Discuss any technical challenges faced during the project, such as data limitations, computational issues, or obstacles encountered during analysis.\nExplain unexpected results and their technical implications.\nIdentify areas for future work, including potential optimizations, further analysis, or scaling solutions."
  },
  {
    "objectID": "technical-details/data-collection/closing.html#benchmarks",
    "href": "technical-details/data-collection/closing.html#benchmarks",
    "title": "Summary",
    "section": "",
    "text": "Compare your findings to relevant research, industry benchmarks, or intuitive expectations, if applicable."
  },
  {
    "objectID": "technical-details/data-collection/closing.html#conclusion-and-future-steps",
    "href": "technical-details/data-collection/closing.html#conclusion-and-future-steps",
    "title": "Summary",
    "section": "",
    "text": "Summarize the key technical points and outcomes of the project.\nSuggest potential improvements or refinements to this part of the project.\nBased on the results, provide actionable recommendations for further research or optimization efforts."
  },
  {
    "objectID": "report/report.html",
    "href": "report/report.html",
    "title": "Final Report",
    "section": "",
    "text": "Audio instructions:\nIf you want, you can listen to the instructions:\n\n\n\n Source: Text-to-speech conversion done with Amazon Polly on AWS \nNote: These audio instructions should not be included in your final submission or repository, once you are done wiht them, please delete the files and remove them from the website.\nThis report is designed for a non-technical audience (e.g., the general public, executives, marketing teams, or clients), focusing on high-level insights, actionable results, and visualizations to convey the impact without requiring technical knowledge. The goal is to highlight how a model affects business strategy or revenue without diving into complex methods.\n\n\n\nClear Purpose: Define the core message or objective early on.\nKnow Your Audience: Adjust language, tone, and detail based on the audience’s understanding.\nStrong Opening: Start with a hook that sets context and stakes.\nLogical Flow: Structure with a clear beginning, middle, and end.\nKey Insights: Highlight the most important points; avoid unnecessary details or jargon.\nData Support: Use data to enhance the narrative without overwhelming.\nVisuals: Incorporate charts to simplify ideas and engage the audience.\nActionable Takeaways: Conclude with recommendations or next steps.\nAuthenticity: Use storytelling to make the content engaging and relatable.\nRevise: Edit for clarity and impact, removing unnecessary content.\n\n\n\n\nThese are just examples, you can use any structure that is suitable for your project.\n\n\n\nIntroduction: Provide an accessible overview and explain the motivation and importance of the research. Example: “This study explores how climate change affects local ecosystems, vital for wildlife conservation.”\nObjective: Clearly define the research goal and relate it to real-world challenges. Example: “We aim to analyze the effects of air pollution on public health in urban areas.”\nKey Findings: Present insights without technical terms, focusing on the impact. Example: “Air pollution increases the risk of respiratory diseases by 20%.”\nMethodology Overview: Briefly explain relevant methods. Example: “We analyzed air quality data from 50 cities and surveyed 10,000 residents.”\nVisualizations: Use simple graphs and infographics to convey findings. Example: A map showing pollution levels and a bar chart of health risks.\nSocietal Implications: Highlight the broader impact. Example: “This study highlights the need for better air quality policies.”\nCall to Action: Offer recommendations based on findings. Example: “We recommend city planners invest in green spaces.”\nConclusion: Recap the main findings and societal impact. Example: “Understanding pollution’s health impacts will help create healthier cities.”\n\n\n\n\n\nExecutive Summary: Summarize key findings and their relevance to business goals. Example: “This report predicts customer churn and offers strategies to reduce churn by 15%.”\nObjective: Define the problem or question addressed. Example: “This project aims to identify the drivers of customer churn.”\nKey Insights: Present the most important, actionable insights. Example: “Customers who interact with support twice within 30 days are 25% less likely to churn.”\nVisualizations: Use clear graphs to convey key insights. Example: A bar chart showing churn likelihood based on engagement.\nBusiness Implications: Explain how findings impact business outcomes and offer specific recommendations. Example: “Focus retention efforts on low-engagement customers.”\nRecommendations: Provide clear, actionable steps with projections. Example: “Implement an automated retention campaign, reducing churn by 10%.”\nConclusion: Summarize findings and suggest next steps. Example: “Addressing churn drivers can reduce loss and improve profitability.”\nAppendix (Optional): Additional charts or explanations for further insights.\n\n\n\n\n\n\nSimplicity: Avoid jargon; focus on business-relevant insights.\nVisual Focus: Prioritize charts and graphs over dense text.\nEmphasize Impact: Always link data insights to business outcomes."
  },
  {
    "objectID": "report/report.html#guidelines-for-creating-a-good-narrative",
    "href": "report/report.html#guidelines-for-creating-a-good-narrative",
    "title": "Final Report",
    "section": "",
    "text": "Clear Purpose: Define the core message or objective early on.\nKnow Your Audience: Adjust language, tone, and detail based on the audience’s understanding.\nStrong Opening: Start with a hook that sets context and stakes.\nLogical Flow: Structure with a clear beginning, middle, and end.\nKey Insights: Highlight the most important points; avoid unnecessary details or jargon.\nData Support: Use data to enhance the narrative without overwhelming.\nVisuals: Incorporate charts to simplify ideas and engage the audience.\nActionable Takeaways: Conclude with recommendations or next steps.\nAuthenticity: Use storytelling to make the content engaging and relatable.\nRevise: Edit for clarity and impact, removing unnecessary content."
  },
  {
    "objectID": "report/report.html#report-content",
    "href": "report/report.html#report-content",
    "title": "Final Report",
    "section": "",
    "text": "These are just examples, you can use any structure that is suitable for your project.\n\n\n\nIntroduction: Provide an accessible overview and explain the motivation and importance of the research. Example: “This study explores how climate change affects local ecosystems, vital for wildlife conservation.”\nObjective: Clearly define the research goal and relate it to real-world challenges. Example: “We aim to analyze the effects of air pollution on public health in urban areas.”\nKey Findings: Present insights without technical terms, focusing on the impact. Example: “Air pollution increases the risk of respiratory diseases by 20%.”\nMethodology Overview: Briefly explain relevant methods. Example: “We analyzed air quality data from 50 cities and surveyed 10,000 residents.”\nVisualizations: Use simple graphs and infographics to convey findings. Example: A map showing pollution levels and a bar chart of health risks.\nSocietal Implications: Highlight the broader impact. Example: “This study highlights the need for better air quality policies.”\nCall to Action: Offer recommendations based on findings. Example: “We recommend city planners invest in green spaces.”\nConclusion: Recap the main findings and societal impact. Example: “Understanding pollution’s health impacts will help create healthier cities.”\n\n\n\n\n\nExecutive Summary: Summarize key findings and their relevance to business goals. Example: “This report predicts customer churn and offers strategies to reduce churn by 15%.”\nObjective: Define the problem or question addressed. Example: “This project aims to identify the drivers of customer churn.”\nKey Insights: Present the most important, actionable insights. Example: “Customers who interact with support twice within 30 days are 25% less likely to churn.”\nVisualizations: Use clear graphs to convey key insights. Example: A bar chart showing churn likelihood based on engagement.\nBusiness Implications: Explain how findings impact business outcomes and offer specific recommendations. Example: “Focus retention efforts on low-engagement customers.”\nRecommendations: Provide clear, actionable steps with projections. Example: “Implement an automated retention campaign, reducing churn by 10%.”\nConclusion: Summarize findings and suggest next steps. Example: “Addressing churn drivers can reduce loss and improve profitability.”\nAppendix (Optional): Additional charts or explanations for further insights."
  },
  {
    "objectID": "report/report.html#final-tips",
    "href": "report/report.html#final-tips",
    "title": "Final Report",
    "section": "",
    "text": "Simplicity: Avoid jargon; focus on business-relevant insights.\nVisual Focus: Prioritize charts and graphs over dense text.\nEmphasize Impact: Always link data insights to business outcomes."
  },
  {
    "objectID": "instructions/topic-selection.html",
    "href": "instructions/topic-selection.html",
    "title": "Topic selection",
    "section": "",
    "text": "Start by selecting a broad topic area.\nHere are some examples:\n\nBio and Health\n\nClimate\n\nFinance and Economics\n\nPublic Policy\n\nMaterials Discovery\n\nTransportation\n\nEducation\n\nCrime and Punishment\n\nPolitics and Government\n\nZoology and Botany\n\nSocial Phenomena\n\n\n\n\n\nNarrow your focus to a topic that can realistically be addressed in a data driven way.\n\ne.g. Study the effect of climate change on extreme weather\nAvoid commonly used topics from Kaggle.\n\nClaim your topic in the “project topic page in the shared documeent”\n\nclick here to claim your topic\n\n\nEven if multiple students choose similar topics, each portfolio must be original. Portfolios that are too similar will be reviewed for plagiarism and may result in Honor Council violation.\n\n\n\nThe data science life cycle starts with well-posed questions, similar to the scientific method. A data science question is a broad idea that can be broken down into 5 to 10 smaller questions, guiding your investigation.\n\n“What effect is climate change having on frequency of extreme weather events? e.g hurricane, drought, forest fires, etc”\n\nHere are some additional example questions:\n\nHealth & Medicine\n\nWhat factors predict heart disease across different age groups?\n\nHow does cancer treatment effectiveness vary by demographics?\n\nCan wearables predict the onset of diabetes?\n\nClimate & Environment\n\nWhat is the impact of deforestation on regional climates?\n\nEducation\n\nHow do socioeconomic factors affect student performance?\n\nWhat is the impact of remote learning post-pandemic?\n\nSocial Science & Public Policy\n\nHow does income inequality correlate with crime rates?\n\nWhat factors influence voter turnout?\n\nFinance & Economics\n\nWhat indicators predict stock market crashes?\n\nHow does inflation impact consumer spending?\n\nTransportation\n\nHow has ride-sharing impacted taxi services?\n\nWhat are the busiest transportation hubs, and how can congestion be reduced?\n\nCrime & Law Enforcement\n\nWhat factors predict recidivism in former inmates?\n\nHow do different policing strategies impact crime rates?\n\nSports & Entertainment\n\nWhat factors predict an athlete’s long-term performance?\n\nCan machine learning predict sports match outcomes?\n\nTechnology & Social Media\n\nHow do online reviews impact product sales?\n\nWhat strategies drive viral social media campaigns?\n\n\nChoose a topic you’re passionate about, and develop creative, “outside-the-box” questions to guide your project throughout the course."
  },
  {
    "objectID": "instructions/topic-selection.html#select-a-broad-topic-area",
    "href": "instructions/topic-selection.html#select-a-broad-topic-area",
    "title": "Topic selection",
    "section": "",
    "text": "Start by selecting a broad topic area.\nHere are some examples:\n\nBio and Health\n\nClimate\n\nFinance and Economics\n\nPublic Policy\n\nMaterials Discovery\n\nTransportation\n\nEducation\n\nCrime and Punishment\n\nPolitics and Government\n\nZoology and Botany\n\nSocial Phenomena"
  },
  {
    "objectID": "instructions/topic-selection.html#narrow-your-focus",
    "href": "instructions/topic-selection.html#narrow-your-focus",
    "title": "Topic selection",
    "section": "",
    "text": "Narrow your focus to a topic that can realistically be addressed in a data driven way.\n\ne.g. Study the effect of climate change on extreme weather\nAvoid commonly used topics from Kaggle.\n\nClaim your topic in the “project topic page in the shared documeent”\n\nclick here to claim your topic\n\n\nEven if multiple students choose similar topics, each portfolio must be original. Portfolios that are too similar will be reviewed for plagiarism and may result in Honor Council violation."
  },
  {
    "objectID": "instructions/topic-selection.html#data-science-questions",
    "href": "instructions/topic-selection.html#data-science-questions",
    "title": "Topic selection",
    "section": "",
    "text": "The data science life cycle starts with well-posed questions, similar to the scientific method. A data science question is a broad idea that can be broken down into 5 to 10 smaller questions, guiding your investigation.\n\n“What effect is climate change having on frequency of extreme weather events? e.g hurricane, drought, forest fires, etc”\n\nHere are some additional example questions:\n\nHealth & Medicine\n\nWhat factors predict heart disease across different age groups?\n\nHow does cancer treatment effectiveness vary by demographics?\n\nCan wearables predict the onset of diabetes?\n\nClimate & Environment\n\nWhat is the impact of deforestation on regional climates?\n\nEducation\n\nHow do socioeconomic factors affect student performance?\n\nWhat is the impact of remote learning post-pandemic?\n\nSocial Science & Public Policy\n\nHow does income inequality correlate with crime rates?\n\nWhat factors influence voter turnout?\n\nFinance & Economics\n\nWhat indicators predict stock market crashes?\n\nHow does inflation impact consumer spending?\n\nTransportation\n\nHow has ride-sharing impacted taxi services?\n\nWhat are the busiest transportation hubs, and how can congestion be reduced?\n\nCrime & Law Enforcement\n\nWhat factors predict recidivism in former inmates?\n\nHow do different policing strategies impact crime rates?\n\nSports & Entertainment\n\nWhat factors predict an athlete’s long-term performance?\n\nCan machine learning predict sports match outcomes?\n\nTechnology & Social Media\n\nHow do online reviews impact product sales?\n\nWhat strategies drive viral social media campaigns?\n\n\nChoose a topic you’re passionate about, and develop creative, “outside-the-box” questions to guide your project throughout the course."
  },
  {
    "objectID": "instructions/overview.html",
    "href": "instructions/overview.html",
    "title": "Project instruction:",
    "section": "",
    "text": "Author(s): Dr. H and Gerard Pendleton Thurston the 4th\nNote: You can delete this folder and remove it from the project website once you have read and understood the instructions. It shouldn’t be part of your final submission.\nAudio instructions:\nIf you want, you can listen to the instructions:\n\n\n\n Source: Text-to-speech conversion done with Amazon Polly on AWS \nNote: These audio instructions should not be included in your final submission or repository, once you are done wiht them, please delete the files and remove them from the website."
  },
  {
    "objectID": "instructions/overview.html#python-package-optional",
    "href": "instructions/overview.html#python-package-optional",
    "title": "Project instruction:",
    "section": "Python package (optional)",
    "text": "Python package (optional)\nThis is an optional component of the project, if you’d like, you can create a dedicated Python package for your project. The source folder for this package should be included in the root of your repository, and it can be imported into your processing scripts used in the various technical-details sections. If you create a package, it should be well-documented, with an additional tab on the navigation bar for the package documentation.\nWhile a package would typically have its own GitHub repository, for this project, please include it within the same repository.\nThe skeleton for the package is not provided in the repo, but you can recycle what you created in past assignments."
  },
  {
    "objectID": "instructions/overview.html#select-a-broad-topic-area",
    "href": "instructions/overview.html#select-a-broad-topic-area",
    "title": "Project instruction:",
    "section": "Select a broad topic area",
    "text": "Select a broad topic area\nStart by selecting a broad topic area.\nHere are some examples:\n\nBio and Health\n\nClimate\n\nFinance and Economics\n\nPublic Policy\n\nMaterials Discovery\n\nTransportation\n\nEducation\n\nCrime and Punishment\n\nPolitics and Government\n\nZoology and Botany\n\nSocial Phenomena"
  },
  {
    "objectID": "instructions/overview.html#narrow-your-focus",
    "href": "instructions/overview.html#narrow-your-focus",
    "title": "Project instruction:",
    "section": "Narrow your focus",
    "text": "Narrow your focus\n\nNarrow your focus to a topic that can realistically be addressed in a data driven way.\n\ne.g. Study the effect of climate change on extreme weather\nAvoid commonly used topics from Kaggle.\n\nClaim your topic in the “project topic page in the shared documeent”\n\nclick here to claim your topic\n\n\nEven if multiple students choose similar topics, each portfolio must be original. Portfolios that are too similar will be reviewed for plagiarism and may result in Honor Council violation."
  },
  {
    "objectID": "instructions/overview.html#data-science-questions",
    "href": "instructions/overview.html#data-science-questions",
    "title": "Project instruction:",
    "section": "Data Science Questions",
    "text": "Data Science Questions\nThe data science life cycle starts with well-posed questions, similar to the scientific method. A data science question is a broad idea that can be broken down into 5 to 10 smaller questions, guiding your investigation.\n\n“What effect is climate change having on frequency of extreme weather events? e.g hurricane, drought, forest fires, etc”\n\nHere are some additional example questions:\n\nHealth & Medicine\n\nWhat factors predict heart disease across different age groups?\n\nHow does cancer treatment effectiveness vary by demographics?\n\nCan wearables predict the onset of diabetes?\n\nClimate & Environment\n\nWhat is the impact of deforestation on regional climates?\n\nEducation\n\nHow do socioeconomic factors affect student performance?\n\nWhat is the impact of remote learning post-pandemic?\n\nSocial Science & Public Policy\n\nHow does income inequality correlate with crime rates?\n\nWhat factors influence voter turnout?\n\nFinance & Economics\n\nWhat indicators predict stock market crashes?\n\nHow does inflation impact consumer spending?\n\nTransportation\n\nHow has ride-sharing impacted taxi services?\n\nWhat are the busiest transportation hubs, and how can congestion be reduced?\n\nCrime & Law Enforcement\n\nWhat factors predict recidivism in former inmates?\n\nHow do different policing strategies impact crime rates?\n\nSports & Entertainment\n\nWhat factors predict an athlete’s long-term performance?\n\nCan machine learning predict sports match outcomes?\n\nTechnology & Social Media\n\nHow do online reviews impact product sales?\n\nWhat strategies drive viral social media campaigns?\n\n\nChoose a topic you’re passionate about, and develop creative, “outside-the-box” questions to guide your project throughout the course."
  },
  {
    "objectID": "instructions/overview.html#repository-setup",
    "href": "instructions/overview.html#repository-setup",
    "title": "Project instruction:",
    "section": "Repository Setup",
    "text": "Repository Setup\n\nYou MUST use GitHub Classroom to create your project repository. This ensures TAs can access your code and track your progress.\nClone the repository to your local machine, which will provide a basic directory structure."
  },
  {
    "objectID": "instructions/overview.html#expectations-for-github-usage",
    "href": "instructions/overview.html#expectations-for-github-usage",
    "title": "Project instruction:",
    "section": "Expectations for GitHub Usage",
    "text": "Expectations for GitHub Usage\nYour grade will reflect how effectively you use Git, including:\n\nIncremental progress on the project\nThe frequency and quality of commits\nRepository structure and organization\nAdherence to GitHub guidelines outlined below\n\nEnsure regular commits to GitHub (e.g., git add, git commit, git push) to sync your work and maintain a smooth development process.\n\n1. Use a Logical Repository Structure\n\nInclude a comprehensive README file that explains the purpose of the project.\nOrganize files logically to make navigation easier for collaborators and TAs.\nEnsure all files are well-documented and the code is easy to follow.\n\n\n\n2. Commit Regularly\n\nCommit frequently with clear, meaningful commit messages that reflect the changes made.\n\nGood commit message example: Added data cleaning script for tabular data\nPoor commit message example: Fix\n\n\n\n\n3. Data Storage\n\nDo not store large data files in your repository.\n\nStore raw data in the raw-data folder and processed data in the processed-data folder; these folders should be added to .gitignore.\nTip: Use external storage like Google Drive or GU Domains for large datasets and provide access links within the repository.\n\n\n\n\n4. Syncing with GU Domains\n\nSync your GitHub repository with your GU Domains website before submission deadlines to keep everything up to date. (this should be fully automated)\nEnsure your code repository and website are always in sync, particularly before the final submission, to avoid losing points.\n\n\n\n5. Code Documentation\n\nProvide clear and thorough documentation for each file and function in your project.\nInclude a README.md that outlines the project purpose, how to run the code, and any necessary dependencies."
  },
  {
    "objectID": "instructions/overview.html#collaboration-in-groups-if-applicable",
    "href": "instructions/overview.html#collaboration-in-groups-if-applicable",
    "title": "Project instruction:",
    "section": "Collaboration in Groups (If Applicable)",
    "text": "Collaboration in Groups (If Applicable)\nIf you are working in a group, make full use of GitHub’s collaboration features:\n\nTask Assignment:\n\nAssign tasks using GitHub Issues or Project Boards to keep track of progress.\n\nBranching and Pull Requests:\n\nUse branches for feature development and pull requests for code reviews before merging into the main branch.\n\nCommunication:\n\nMaintain regular communication and conduct code reviews with your teammates to prevent conflicts.\n\nEqual Contribution:\n\nEnsure equal contribution from all team members. Unequal contributions will negatively affect individual grades.\nNote: Team members not contributing equally may be flagged by the group and penalized after review.\n\nContribution Documentation:\n\nDocument each member’s contributions clearly in the collaborators.qmd file, detailing who worked on specific aspects of the project.\n\nCode Reviews:\n\nConduct peer code reviews before merging changes into the main branch to maintain quality and consistency."
  },
  {
    "objectID": "instructions/overview.html#website-development",
    "href": "instructions/overview.html#website-development",
    "title": "Project instruction:",
    "section": "Website Development",
    "text": "Website Development\nIt is required that you build your website with Quarto."
  },
  {
    "objectID": "instructions/overview.html#website-hosting",
    "href": "instructions/overview.html#website-hosting",
    "title": "Project instruction:",
    "section": "Website Hosting",
    "text": "Website Hosting\nYou MUST host your website on the Georgetown Domains web space.\nNo exceptions. You may NOT use anything other than Georgetown Domains to host your website. For example, no RPubs, WordPress, Squarespace, or any other website development toolset. Failure to comply with this rule will result in a ZERO."
  },
  {
    "objectID": "instructions/overview.html#the-two-audiences",
    "href": "instructions/overview.html#the-two-audiences",
    "title": "Project instruction:",
    "section": "The two audiences",
    "text": "The two audiences\nKnowing your audience in data science writing is crucial because it shapes how you present information. Technical stakeholders may require detailed explanations of methodologies, while non-technical audiences need clear, simplified insights and data-driven conclusions. Tailoring your message ensures your analysis is both understandable and impactful, driving informed decision-making.\n\nExamples of technical audiences include data scientists, software engineers, and IT professionals. These individuals expect detailed explanations of models, algorithms, methodologies, or system architectures, and they’re comfortable with technical jargon, such as discussing hyperparameters, programming frameworks, or machine learning techniques.\nNon-technical audiences include executives, marketing teams, and clients. They prioritize high-level insights, actionable results, and visualizations that convey the impact of data without requiring an understanding of complex methods. For instance, a CEO may want to know how a model affects business strategy or revenue, without diving into the underlying technical details.\n\nIn this project you will cater to both audiences. This is done by having regions of your website for both audiences (see website struture)"
  },
  {
    "objectID": "instructions/overview.html#get-started-early",
    "href": "instructions/overview.html#get-started-early",
    "title": "Project instruction:",
    "section": "Get started early",
    "text": "Get started early\nRemember, slow and steady wins the race\nMaking steady, incremental progress on a large project generally makes it more manageable. Rushing to throw something together under a tight deadline often turns the process into a nightmare."
  },
  {
    "objectID": "instructions/overview.html#graduate-level-work",
    "href": "instructions/overview.html#graduate-level-work",
    "title": "Project instruction:",
    "section": "Graduate level work",
    "text": "Graduate level work\nThis is a graduate-level class, so each project should be viewed as specifications, not simple step-by-step requirements. Graduate-level work must be creative, individualized, and of high quality. To achieve an A-level grade, you are expected to exceed the specifications and create unique, novel solutions.\nFor example: If you’re asked to build visualizations to support your data science story, you won’t be told how many or what type of visualizations to create. This is up to you, based on your data and the creativity and quality you want to demonstrate.\nWe want you to move away from expecting someone else to tell you what to do, how to do it, and how much to do. Instead, you’ll adopt a professional approach—reviewing specifications provided in the assignments, determining what’s needed to exceed expectations, and demonstrating professional excellence.\nThere are countless ways to approach the project requirements, so be creative and thoughtful. Instructions outline the minimum requirements, but exceeding them will elevate the quality of your work.\nAutonomy and Critical Thinking:\n\nIn the workplace, step-by-step instructions are rare. You’ll need to interpret broad requirements and deliver professional results. Producing high-quality, accurate work with limited guidance is a key professional skill.\nAt this stage, move away from asking, “Do I have to do XYZ?” Instead, critically analyze challenges. If something is unclear, investigate and break it down fundamentally.\n\nDeveloping problem-solving skills is crucial. While it’s important to work independently for at least 10–20 minutes, if you’re still stuck after 30 minutes, seek help. Being resourceful is important, but knowing when to ask for assistance is equally valuable."
  },
  {
    "objectID": "instructions/overview.html#the-intersection-of-skills-and-domain-knowledge",
    "href": "instructions/overview.html#the-intersection-of-skills-and-domain-knowledge",
    "title": "Project instruction:",
    "section": "The intersection of skills and domain knowledge",
    "text": "The intersection of skills and domain knowledge\n“Data science” is essentially a collection of useful computational and mathematical skills (statistics, cloud computing, machine learning, coding, etc). However, to maximize your effectiveness, these skills should be applied to a domain of interest (e.g., materials science, finance, healthcare, etc). Focusing and learning about a particular domain will help you specialize and make you more marketable.\nThat beind said, don’t worry about choosing the “perfect” domain—it’s always possible to pivot later, as many of the skills learned, such as problem-solving, critical thinking, and self-education, are transferable across all fields."
  },
  {
    "objectID": "instructions/overview.html#what-is-impact",
    "href": "instructions/overview.html#what-is-impact",
    "title": "Project instruction:",
    "section": "What is “impact”?",
    "text": "What is “impact”?\nImpact in science refers to the significance and influence of research, often measured by metrics like citations, impact factor of journals, and indices like h-index. These metrics reflect how widely recognized and valuable the work is within the scientific community. Such quanities are used to compare researchers and journals, and are used to determine grant funding and career opportunities.\n\nImpact Factor (IF):\n\nA measure of a journal’s influence, calculated by averaging the number of citations to articles published in the journal over the past two years.\nHigher impact factors indicate a more influential journal.\n\nNumber of Citations:\n\nThe total count of how often a researcher’s work is cited by others, reflecting its influence within the scientific community.\nMore citations generally signal broader recognition or relevance of the research.\n\nh-index:\n\nA metric that measures both productivity and citation impact. An h-index of 10 means a researcher has 10 papers each cited at least 10 times.\nHigher h-index indicates more influential and widely recognized work.\n\ni10-index:\n\nCounts the number of a researcher’s publications with at least 10 citations.\nA straightforward measure of citation impact, commonly used by Google Scholar.\n\nImportance of Citations:\n\nCitations indicate that other researchers find the work valuable for their own research, increasing its perceived credibility and impact in the field."
  },
  {
    "objectID": "instructions/overview.html#what-makes-a-good-research-project",
    "href": "instructions/overview.html#what-makes-a-good-research-project",
    "title": "Project instruction:",
    "section": "What makes a good research project?",
    "text": "What makes a good research project?\nProfessional academic or industrial research is all about discovery, improvement, and novelty. You don’t necessarily need to have a project that acheive the following, but here are some guidelines for what makes “high impact” projects:\nIn no particular order:\n\nNovel computational tools: For example, development of a new Python package to tackle a class of problem which doesn’t have an existing suitable tool.\nCreating more user-friendly tools: For example, there might be a great C++ code, but with no python analogue. Python is easier to use, so if you make a pythonic version of an existing tool, it may get higher adoption, provided it is more or less as efficient to the competitors.\nMore efficient tools or methods: Achieving something 1.25x, 2x, 10x or 10000x faster than existing methods, or creating a new code package that is more efficient than a previous one.\nNovel methods: A completely new way of doing something (e.g. new classification algorithm)\nExisting methods applied to new domains: Using established methods to solve problems in a novel domain, e.g. applying a particular classification methodology to a problem or dataset that no one has applied it to before. Extent of impact obviously depends on the importance of the domain or use-case.\nCreation of novel Data Sets: Provides well-curated, clean datasets that can be used to address important scientific questions or problems.(often more useful if there is an accompanying API)\nNew insights or phenomena: Using data analysis techniques to uncover new insights or patterns that address key questions or problems. For example, discovering overarching governing rules (e.g., differential equations) that describe some observed phenomena.\n\nSolves a Major Problem: Addresses a critical or unresolved issue in the field, offering a breakthrough or significant advancement.\n\nRobust Data and Methodology: Employs sound, validated methodologies and high-quality data to ensure credibility and reliability (i.e. doing something rigorously, correctly, and generally better than the competition).\nInterdisciplinary Impact: Influences multiple fields or areas of study, increasing the breadth of its significance.\nHigh Citation Potential: Likely to be widely cited due to its significance, relevance, and applicability across different areas.\n\nYou can, of course, have multiple of these components in a single project, which will increase its prestige.\nThis is especially true when conducting academic research. Publications need to be novel and make a unique contribution to the body of human knowledge; otherwise, they will not be highly cited or considered particularly important."
  },
  {
    "objectID": "instructions/overview.html#time-management",
    "href": "instructions/overview.html#time-management",
    "title": "Project instruction:",
    "section": "Time management",
    "text": "Time management\n80-20 Rule: This rule of thumb suggests that 80% of results come from 20% of causes. In other words, a small number of key factors drive the majority of outcomes. This principle applies to project management, where a few critical steps or decisions often determine the success of a project.\nFor example, it might take one week of steady work (30-40 hours) to complete 80% of a project, while the final 20% could take an additional four weeks.\n\nProjects tend to expand to fill the time available. No creative project—whether a book, song, poem, or paper—is ever truly 100% complete. There is an asymptotic limit as \\(t \\rightarrow \\infty\\), and true perfection is unattainable. The key is knowing when to “call it done.” This might happen at 95% or 99% completion, but eventually, we all have to stop. Strive to take this project as far as possible, but remember to stop and “call it done” at some point."
  },
  {
    "objectID": "instructions/overview.html#visualization-guidelines",
    "href": "instructions/overview.html#visualization-guidelines",
    "title": "Project instruction:",
    "section": "Visualization guidelines",
    "text": "Visualization guidelines\nVisualizations are a critical component of your portfolio. Use them strategically to support your narrative. The more visual representations of your data, the better—higher-quality visualizations will result in a higher grade. Ensure that all graphics follow best practices:\n\nChoose the right chart type: Match the chart to the data (e.g., bar for categories, line for trends).\nMaintain simplicity: Avoid clutter and focus on the essential message.\nUse appropriate scales: Ensure axes have correct and intuitive scaling to avoid misinterpretation.\nLabel axes clearly: Include meaningful axis labels with units (e.g., “Temperature (°C)” or “Revenue (USD)”).\nInclude descriptive titles: Provide a concise, informative title that explains the visualization’s main takeaway.\nEnsure consistency: Use uniform color schemes, fonts, and styles across all charts in a presentation.\nHighlight key data: Use contrasting colors or annotations to draw attention to important points or trends.\nKeep proportions accurate: Maintain correct data-to-visual size relationships to avoid distortion.\nConsider the audience: Tailor the level of detail and style to the audience’s technical proficiency.\nTest readability: Ensure fonts, colors, and elements are clear and legible in various formats and sizes.\nUse interactivity carefully: Interactive features should add clarity, not complexity, to the visual."
  },
  {
    "objectID": "instructions/overview.html#coding",
    "href": "instructions/overview.html#coding",
    "title": "Project instruction:",
    "section": "Coding",
    "text": "Coding\n\nPractice First\nWhile not required, practice is highly beneficial. It’s also a good habit to write your code from scratch, as this will build your problem-solving skills. You can use the code provided by professors as a reference, but always strive to write your own. Starting with a blank page is a valuable practice.\nTo get comfortable with the methods, review and modify the R and Python codes provided in class. Try applying these to your project data and experiment with creating small toy datasets, such as a CSV file or a text corpus. This helps you understand the structure of the data and what the algorithms are doing.\n\n\nPrototype and develop on a small data set\nIf you have big data, ALWAYS prototype on a small subset of the data, so that your code runs fast so that you can develop quickly, without waiting several minutes for each code cell to run. Do this by including a downsampling hyper-parameter at the beginning of your code, e.g. 0.1. When the code is robust and finalized, you can set the downsampling factor to 1, run it on the complete data set, and let your computer run overnight.\nIt is not a crazy idea to do a “trial run” of the project first from start to finish with a very basic dataset, e.g. penguins,diabetes, or iris. Make sure the “toy” data set is similar to your planned real world data set, for example, if you are planning an NLP project, don’t use a image dataset for your development process.\nThis will have the following benefits:\n\nClarifies Workflow: Understand the complete process from start to finish.\nIdentifies Challenges: Spot potential issues early on.\nValidates Assumptions: Ensure methods and approaches are suitable.\nEnhances Skills: Improve technical skills through practice.\nBuilds Confidence: Familiarity with tools and techniques.\nRefines Methods: Test and optimize analytical strategies.\nEstimates Resources: Better planning for time and resource allocation.\nFacilitates Communication: Clearly convey project goals and outcomes.\nDocuments Process: Create a reference for reproducibility.\nGathers Early Feedback: Obtain input for adjustments before full implementation.\n\nhttps://scikit-learn.org/1.5/datasets/toy_dataset.html\nOnce that is working as a starter code-base you can swap it out for your full data later and start developing further for a more realistic real world project ."
  },
  {
    "objectID": "instructions/overview.html#debugging",
    "href": "instructions/overview.html#debugging",
    "title": "Project instruction:",
    "section": "Debugging",
    "text": "Debugging\n\nAlways remember the following Debugging Steps:\n\nStep A: Copy the error message and search it online (Google or similar).\nStep B: Look through forums or documentation to find a solution.\nStep C: Implement the solution.\nStep D: If you’re still stuck, ask for help from classmates, TAs, or professors.\nStep E: Move on to the next issue and repeat the process.\n\n\n(Note: You can also use ChatGPT for debugging, but be cautious as the solutions may sometimes be inaccurate or incomplete.)"
  },
  {
    "objectID": "instructions/overview.html#file-types",
    "href": "instructions/overview.html#file-types",
    "title": "Project instruction:",
    "section": "File Types",
    "text": "File Types\nYou can decide when to use .qmd vs .ipynb for structuring your code, but I recommend the following guidelines:\n\nIf the file contains any code (either in R or Python), ALWAYS use .ipynb.\nDo not mix R and Python in the same notebook.\nIf the file is purely markdown without code, use .qmd.\nUse Quarto includes to modularize your content (see below for more details). This is also demonstrated in the project skeleton."
  },
  {
    "objectID": "instructions/overview.html#quarto-includes",
    "href": "instructions/overview.html#quarto-includes",
    "title": "Project instruction:",
    "section": "Quarto Includes",
    "text": "Quarto Includes\nQuarto includes (e.g., {{&lt; include _content.qmd &gt;}}) are highly recommended for modularizing and organizing your content. While optional, they offer several advantages.\nNote: You can include a .qmd file in a .ipynb file, but not vice versa.\n\nWhy Use Quarto Includes?\n\nModularization: Breaking your project into smaller, reusable chunks simplifies the management of complex documents. You can work on specific sections without altering the entire project.\nReusability: Includes allow you to reuse content blocks across multiple documents, making them ideal for repetitive sections like headers or footers.\nConsistency: By using includes, you ensure uniformity across your documents. Updating an include file will automatically apply the changes wherever it’s used.\nSimplifies Collaboration: In team settings, includes allow different contributors to work on separate sections simultaneously, reducing merge conflicts and making the project easier to maintain.\nImproved Organization: Includes help keep your main files clean and focused by loading content from separate, well-organized files. This makes your project more manageable and easier to navigate."
  },
  {
    "objectID": "instructions/overview.html#citation",
    "href": "instructions/overview.html#citation",
    "title": "Project instruction:",
    "section": "Citation",
    "text": "Citation\nALWAY CITE CONTENT OR IDEAS TAKEN FROM EXTERNAL SOURCES: e.g. websites, llm tools, papers\nALWAYS BE TRANSPARENT WHEN YOU ARE USING LLM TOOLS:\nPlease follow these guidelines:\n\nGeneral Tasks: Create and regularly update a dedicated LLM Transparency page to document how you are using LLM tools.\n\nThis page can serve as a “catch-all” for use cases that don’t involve content creation, such as reformatting your own ideas, commenting code that you wrote, or proofreading text, PDF summarization.\n\nContent Creation: If non-original content (code or text) is generated by an LLM, you must also cite it on specific pages, just like any external source.\n\nFor non-original content, always provide a citation.\nCite the LLM tool after each chunk of text or code it generates, using a BibTeX. For example1"
  },
  {
    "objectID": "instructions/overview.html#acceptable-use-cases",
    "href": "instructions/overview.html#acceptable-use-cases",
    "title": "Project instruction:",
    "section": "Acceptable use cases",
    "text": "Acceptable use cases\nNote: Various useful non-LLM research tools can be found here at the following link\n\nTraditional research tools\n\nYou can use LLM tools for the following use cases\n\nAI research tools\nThese include\n\nre-formating text with LLM tools.\nCode explaination “describe what this code is doing in prose”\nText summarization\nProofreading\n\nchatGPT for project brainstorming\nUsing LLM tools to comment your code qualifies as an acceptible use case in this project. You can also use or code re-formatters such as black to increase the readability of your code."
  },
  {
    "objectID": "instructions/overview.html#unacceptable-use-cases",
    "href": "instructions/overview.html#unacceptable-use-cases",
    "title": "Project instruction:",
    "section": "Unacceptable use cases",
    "text": "Unacceptable use cases\nDO NOT use ChatGPT or other LLM tools to write large portions of your text or code.\n\nEffect on grade\nIf it is clear that you have used LLM tools to write large portions of your code or text, your grade will reflect this, likely in the range of 0% to 50% of the total points, depending on the quality of the work. LLM outputs still require significant polishing to fit into a well-written, cohesive narrative. If it is evident that you simply inserted large portions of LLM-generated content into your assignment without taking the time to refine it into a high-quality submission, your grade will reflect this, even if the usage does not rise to the level of plagiarism.\n\n\nPlagiarism investigation\nIn extreme cases,the following actions will occur.\n\nOne-on-One Investigation: You will meet with department faculty for a thorough review of your project. You will be asked to explain your work in detail, including what specific chunks of code do, why you made certain decisions, and how you reached your conclusions.\nReferral to the Honor Council: If, during this meeting, it is determined that you do not have sufficient understanding of the content that you claimed to have created, the case will be documented and sent to the honor council. This can result in a permanent mark on your transcript and may even lead to expulsion from the university."
  },
  {
    "objectID": "instructions/github-usage.html",
    "href": "instructions/github-usage.html",
    "title": "GitHub",
    "section": "",
    "text": "Your project will be fully transparent, with all source code hosted on GitHub. This platform will serve as the main repository for your project code, documentation, and website. Proper organization and regular updates are key for effective collaboration and project management.\n\nIMPORTANT: Proficiency in GitHub for collaboration is a valuable addition to your resume. Being able to join a team and immediately contribute by solving problems and adding value is a highly sought-after skill. Now is the time to develop this expertise—embrace Git fully, become proficient, and graduate with a critical skill for your future career.\n\n\n\n\nYou MUST use GitHub Classroom to create your project repository. This ensures TAs can access your code and track your progress.\nClone the repository to your local machine, which will provide a basic directory structure.\n\n\n\n\nYour grade will reflect how effectively you use Git, including:\n\nIncremental progress on the project\nThe frequency and quality of commits\nRepository structure and organization\nAdherence to GitHub guidelines outlined below\n\nEnsure regular commits to GitHub (e.g., git add, git commit, git push) to sync your work and maintain a smooth development process.\n\n\n\nInclude a comprehensive README file that explains the purpose of the project.\nOrganize files logically to make navigation easier for collaborators and TAs.\nEnsure all files are well-documented and the code is easy to follow.\n\n\n\n\n\nCommit frequently with clear, meaningful commit messages that reflect the changes made.\n\nGood commit message example: Added data cleaning script for tabular data\nPoor commit message example: Fix\n\n\n\n\n\n\nDo not store large data files in your repository.\n\nStore raw data in the raw-data folder and processed data in the processed-data folder; these folders should be added to .gitignore.\nTip: Use external storage like Google Drive or GU Domains for large datasets and provide access links within the repository.\n\n\n\n\n\n\nSync your GitHub repository with your GU Domains website before submission deadlines to keep everything up to date. (this should be fully automated)\nEnsure your code repository and website are always in sync, particularly before the final submission, to avoid losing points.\n\n\n\n\n\nProvide clear and thorough documentation for each file and function in your project.\nInclude a README.md that outlines the project purpose, how to run the code, and any necessary dependencies.\n\n\n\n\n\nIf you are working in a group, make full use of GitHub’s collaboration features:\n\nTask Assignment:\n\nAssign tasks using GitHub Issues or Project Boards to keep track of progress.\n\nBranching and Pull Requests:\n\nUse branches for feature development and pull requests for code reviews before merging into the main branch.\n\nCommunication:\n\nMaintain regular communication and conduct code reviews with your teammates to prevent conflicts.\n\nEqual Contribution:\n\nEnsure equal contribution from all team members. Unequal contributions will negatively affect individual grades.\nNote: Team members not contributing equally may be flagged by the group and penalized after review.\n\nContribution Documentation:\n\nDocument each member’s contributions clearly in the collaborators.qmd file, detailing who worked on specific aspects of the project.\n\nCode Reviews:\n\nConduct peer code reviews before merging changes into the main branch to maintain quality and consistency."
  },
  {
    "objectID": "instructions/github-usage.html#repository-setup",
    "href": "instructions/github-usage.html#repository-setup",
    "title": "GitHub",
    "section": "",
    "text": "You MUST use GitHub Classroom to create your project repository. This ensures TAs can access your code and track your progress.\nClone the repository to your local machine, which will provide a basic directory structure."
  },
  {
    "objectID": "instructions/github-usage.html#expectations-for-github-usage",
    "href": "instructions/github-usage.html#expectations-for-github-usage",
    "title": "GitHub",
    "section": "",
    "text": "Your grade will reflect how effectively you use Git, including:\n\nIncremental progress on the project\nThe frequency and quality of commits\nRepository structure and organization\nAdherence to GitHub guidelines outlined below\n\nEnsure regular commits to GitHub (e.g., git add, git commit, git push) to sync your work and maintain a smooth development process.\n\n\n\nInclude a comprehensive README file that explains the purpose of the project.\nOrganize files logically to make navigation easier for collaborators and TAs.\nEnsure all files are well-documented and the code is easy to follow.\n\n\n\n\n\nCommit frequently with clear, meaningful commit messages that reflect the changes made.\n\nGood commit message example: Added data cleaning script for tabular data\nPoor commit message example: Fix\n\n\n\n\n\n\nDo not store large data files in your repository.\n\nStore raw data in the raw-data folder and processed data in the processed-data folder; these folders should be added to .gitignore.\nTip: Use external storage like Google Drive or GU Domains for large datasets and provide access links within the repository.\n\n\n\n\n\n\nSync your GitHub repository with your GU Domains website before submission deadlines to keep everything up to date. (this should be fully automated)\nEnsure your code repository and website are always in sync, particularly before the final submission, to avoid losing points.\n\n\n\n\n\nProvide clear and thorough documentation for each file and function in your project.\nInclude a README.md that outlines the project purpose, how to run the code, and any necessary dependencies."
  },
  {
    "objectID": "instructions/github-usage.html#collaboration-in-groups-if-applicable",
    "href": "instructions/github-usage.html#collaboration-in-groups-if-applicable",
    "title": "GitHub",
    "section": "",
    "text": "If you are working in a group, make full use of GitHub’s collaboration features:\n\nTask Assignment:\n\nAssign tasks using GitHub Issues or Project Boards to keep track of progress.\n\nBranching and Pull Requests:\n\nUse branches for feature development and pull requests for code reviews before merging into the main branch.\n\nCommunication:\n\nMaintain regular communication and conduct code reviews with your teammates to prevent conflicts.\n\nEqual Contribution:\n\nEnsure equal contribution from all team members. Unequal contributions will negatively affect individual grades.\nNote: Team members not contributing equally may be flagged by the group and penalized after review.\n\nContribution Documentation:\n\nDocument each member’s contributions clearly in the collaborators.qmd file, detailing who worked on specific aspects of the project.\n\nCode Reviews:\n\nConduct peer code reviews before merging changes into the main branch to maintain quality and consistency."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Landing page",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "Landing page",
    "section": "Getting Started",
    "text": "Getting Started\nTo begin the project, first read the instruction document (click here). This document is also accessible from the navigation bar.\nOnce you’ve completed that, you can proceed with the instructions found throughout the website."
  },
  {
    "objectID": "index.html#what-to-include-on-this-page",
    "href": "index.html#what-to-include-on-this-page",
    "title": "Landing page",
    "section": "What to Include on This Page",
    "text": "What to Include on This Page\nThis is the landing page for your project. Content from this page can be reused in sections of your final report.\n\nCreate an “About You” Page\n\nDevelop your “About You” page. You can reuse content from previous assignments.\nYou can include the content here or on a separate page.\n\nIt’s recommended to create one “About You” page for all DSAN projects, with links to your various class projects.\n\n\n\n\nCreate a Landing Page for Your Project\n\nSummarize your topic, its significance, related work, and the questions you plan to explore.\nDraft an introduction with at least 5 research questions. These may evolve as your project progresses, since data science is an iterative process.\nInclude your data science questions on this page.\n\n\n\nLiterature review\nOnce you decide on a topic, you should ALWAYS START WITH A LITERATURE REVIEW, this is particularly important for academic projects.\nThe literature review is the most important part of most projects.\nIt allows you to;\n\n\nDetermine what is already known and what has already been tried, so that you don't re-invent the wheel.\n\n\nIt makes you more of a subject matter expert, allowing you to ask the right questions, target impactful projects, and communicate with other professionals.\n\n\n\nDoing a project that you think will change the world, only to find at the end that a very similar version of your project was already done in the 1980’s, isn’t a great use of time.\n\nIn this section, please do a literature review and cite at least 3 academic publications per group member, and include internal academic citations.\nOptional: Consider using LLM tools to 10X your literature review, e.g. instead of focusing on 3 papers, aim for 30 or more\nBy following these steps, you can 10X the efficiency of your literature review process, gaining more insights while minimizing the time spent on manual reading.\n\nExpand Your Literature Search\nAim to gather a larger pool of papers. Use academic databases (Google Scholar, arXiv, etc.) to find relevant studies and ensure a broad scope.\nSkim the Abstracts\nRead the abstracts of each paper to quickly understand their focus and identify those most relevant to your topic. Prioritize these papers for deeper analysis.\nUse LLM Tools for Summarization\nUpload the selected papers to an LLM tool capable of text summarization. Have it condense the main points of each paper into a concise, manageable summary (e.g., condense hundreds of pages into a 10-page summary). Carefully review this summary to absorb the key insights.\nLeverage Interactive LLM Tools\nUse tools like NotebookLM or other AI-based text digesters to ask specific, targeted questions about the papers:\n\nExample questions:\n\n“In the papers uploaded, did any of them explore XYZ?”\n“Which paper is most closely related to the following project idea: [explain idea]?” These tools will help you quickly extract relevant information without re-reading entire papers."
  },
  {
    "objectID": "index.html#additional-ideas-for-things-to-include",
    "href": "index.html#additional-ideas-for-things-to-include",
    "title": "Landing page",
    "section": "Additional Ideas for things to include",
    "text": "Additional Ideas for things to include\n\nAudience: Who is this for? Data professionals, businesses, researchers, or curious readers.\nHeadline: A captivating title introducing the data science theme (e.g., “Unlocking Insights Through Data Stories”).\nIntroduction: A brief, engaging overview of what the website offers (e.g., data-driven stories, insights, or case studies).\nQuestions You Are Addressing: What do you hope to learn?\nMotivation: Explain why this topic matters, highlighting the importance of data in solving real-world problems.\nKey Topics: List the main focus areas (e.g., machine learning, data visualization, predictive modeling).\nUse Cases/Examples: A brief teaser of compelling stories or case studies you’ve worked on.\nCall to Action: Invite visitors to explore the content, follow along, or contact you for more information.\nVisual/Infographic: Add a simple graphic or visual element to make the page more dynamic."
  },
  {
    "objectID": "instructions/expectations.html",
    "href": "instructions/expectations.html",
    "title": "General Tips and Expectations",
    "section": "",
    "text": "Remember, slow and steady wins the race\nMaking steady, incremental progress on a large project generally makes it more manageable. Rushing to throw something together under a tight deadline often turns the process into a nightmare.\n\n\n\nThis is a graduate-level class, so each project should be viewed as specifications, not simple step-by-step requirements. Graduate-level work must be creative, individualized, and of high quality. To achieve an A-level grade, you are expected to exceed the specifications and create unique, novel solutions.\nFor example: If you’re asked to build visualizations to support your data science story, you won’t be told how many or what type of visualizations to create. This is up to you, based on your data and the creativity and quality you want to demonstrate.\nWe want you to move away from expecting someone else to tell you what to do, how to do it, and how much to do. Instead, you’ll adopt a professional approach—reviewing specifications provided in the assignments, determining what’s needed to exceed expectations, and demonstrating professional excellence.\nThere are countless ways to approach the project requirements, so be creative and thoughtful. Instructions outline the minimum requirements, but exceeding them will elevate the quality of your work.\nAutonomy and Critical Thinking:\n\nIn the workplace, step-by-step instructions are rare. You’ll need to interpret broad requirements and deliver professional results. Producing high-quality, accurate work with limited guidance is a key professional skill.\nAt this stage, move away from asking, “Do I have to do XYZ?” Instead, critically analyze challenges. If something is unclear, investigate and break it down fundamentally.\n\nDeveloping problem-solving skills is crucial. While it’s important to work independently for at least 10–20 minutes, if you’re still stuck after 30 minutes, seek help. Being resourceful is important, but knowing when to ask for assistance is equally valuable.\n\n\n\n“Data science” is essentially a collection of useful computational and mathematical skills (statistics, cloud computing, machine learning, coding, etc). However, to maximize your effectiveness, these skills should be applied to a domain of interest (e.g., materials science, finance, healthcare, etc). Focusing and learning about a particular domain will help you specialize and make you more marketable.\nThat beind said, don’t worry about choosing the “perfect” domain—it’s always possible to pivot later, as many of the skills learned, such as problem-solving, critical thinking, and self-education, are transferable across all fields.\n\n\n\nImpact in science refers to the significance and influence of research, often measured by metrics like citations, impact factor of journals, and indices like h-index. These metrics reflect how widely recognized and valuable the work is within the scientific community. Such quanities are used to compare researchers and journals, and are used to determine grant funding and career opportunities.\n\nImpact Factor (IF):\n\nA measure of a journal’s influence, calculated by averaging the number of citations to articles published in the journal over the past two years.\nHigher impact factors indicate a more influential journal.\n\nNumber of Citations:\n\nThe total count of how often a researcher’s work is cited by others, reflecting its influence within the scientific community.\nMore citations generally signal broader recognition or relevance of the research.\n\nh-index:\n\nA metric that measures both productivity and citation impact. An h-index of 10 means a researcher has 10 papers each cited at least 10 times.\nHigher h-index indicates more influential and widely recognized work.\n\ni10-index:\n\nCounts the number of a researcher’s publications with at least 10 citations.\nA straightforward measure of citation impact, commonly used by Google Scholar.\n\nImportance of Citations:\n\nCitations indicate that other researchers find the work valuable for their own research, increasing its perceived credibility and impact in the field.\n\n\n\n\n\nProfessional academic or industrial research is all about discovery, improvement, and novelty. You don’t necessarily need to have a project that acheive the following, but here are some guidelines for what makes “high impact” projects:\nIn no particular order:\n\nNovel computational tools: For example, development of a new Python package to tackle a class of problem which doesn’t have an existing suitable tool.\nCreating more user-friendly tools: For example, there might be a great C++ code, but with no python analogue. Python is easier to use, so if you make a pythonic version of an existing tool, it may get higher adoption, provided it is more or less as efficient to the competitors.\nMore efficient tools or methods: Achieving something 1.25x, 2x, 10x or 10000x faster than existing methods, or creating a new code package that is more efficient than a previous one.\nNovel methods: A completely new way of doing something (e.g. new classification algorithm)\nExisting methods applied to new domains: Using established methods to solve problems in a novel domain, e.g. applying a particular classification methodology to a problem or dataset that no one has applied it to before. Extent of impact obviously depends on the importance of the domain or use-case.\nCreation of novel Data Sets: Provides well-curated, clean datasets that can be used to address important scientific questions or problems.(often more useful if there is an accompanying API)\nNew insights or phenomena: Using data analysis techniques to uncover new insights or patterns that address key questions or problems. For example, discovering overarching governing rules (e.g., differential equations) that describe some observed phenomena.\n\nSolves a Major Problem: Addresses a critical or unresolved issue in the field, offering a breakthrough or significant advancement.\n\nRobust Data and Methodology: Employs sound, validated methodologies and high-quality data to ensure credibility and reliability (i.e. doing something rigorously, correctly, and generally better than the competition).\nInterdisciplinary Impact: Influences multiple fields or areas of study, increasing the breadth of its significance.\nHigh Citation Potential: Likely to be widely cited due to its significance, relevance, and applicability across different areas.\n\nYou can, of course, have multiple of these components in a single project, which will increase its prestige.\nThis is especially true when conducting academic research. Publications need to be novel and make a unique contribution to the body of human knowledge; otherwise, they will not be highly cited or considered particularly important.\n\n\n\n80-20 Rule: This rule of thumb suggests that 80% of results come from 20% of causes. In other words, a small number of key factors drive the majority of outcomes. This principle applies to project management, where a few critical steps or decisions often determine the success of a project.\nFor example, it might take one week of steady work (30-40 hours) to complete 80% of a project, while the final 20% could take an additional four weeks.\n\nProjects tend to expand to fill the time available. No creative project—whether a book, song, poem, or paper—is ever truly 100% complete. There is an asymptotic limit as \\(t \\rightarrow \\infty\\), and true perfection is unattainable. The key is knowing when to “call it done.” This might happen at 95% or 99% completion, but eventually, we all have to stop. Strive to take this project as far as possible, but remember to stop and “call it done” at some point.\n\n\n\n\nVisualizations are a critical component of your portfolio. Use them strategically to support your narrative. The more visual representations of your data, the better—higher-quality visualizations will result in a higher grade. Ensure that all graphics follow best practices:\n\nChoose the right chart type: Match the chart to the data (e.g., bar for categories, line for trends).\nMaintain simplicity: Avoid clutter and focus on the essential message.\nUse appropriate scales: Ensure axes have correct and intuitive scaling to avoid misinterpretation.\nLabel axes clearly: Include meaningful axis labels with units (e.g., “Temperature (°C)” or “Revenue (USD)”).\nInclude descriptive titles: Provide a concise, informative title that explains the visualization’s main takeaway.\nEnsure consistency: Use uniform color schemes, fonts, and styles across all charts in a presentation.\nHighlight key data: Use contrasting colors or annotations to draw attention to important points or trends.\nKeep proportions accurate: Maintain correct data-to-visual size relationships to avoid distortion.\nConsider the audience: Tailor the level of detail and style to the audience’s technical proficiency.\nTest readability: Ensure fonts, colors, and elements are clear and legible in various formats and sizes.\nUse interactivity carefully: Interactive features should add clarity, not complexity, to the visual.\n\n\n\n\n\n\nWhile not required, practice is highly beneficial. It’s also a good habit to write your code from scratch, as this will build your problem-solving skills. You can use the code provided by professors as a reference, but always strive to write your own. Starting with a blank page is a valuable practice.\nTo get comfortable with the methods, review and modify the R and Python codes provided in class. Try applying these to your project data and experiment with creating small toy datasets, such as a CSV file or a text corpus. This helps you understand the structure of the data and what the algorithms are doing.\n\n\n\nIf you have big data, ALWAYS prototype on a small subset of the data, so that your code runs fast so that you can develop quickly, without waiting several minutes for each code cell to run. Do this by including a downsampling hyper-parameter at the beginning of your code, e.g. 0.1. When the code is robust and finalized, you can set the downsampling factor to 1, run it on the complete data set, and let your computer run overnight.\nIt is not a crazy idea to do a “trial run” of the project first from start to finish with a very basic dataset, e.g. penguins,diabetes, or iris. Make sure the “toy” data set is similar to your planned real world data set, for example, if you are planning an NLP project, don’t use a image dataset for your development process.\nThis will have the following benefits:\n\nClarifies Workflow: Understand the complete process from start to finish.\nIdentifies Challenges: Spot potential issues early on.\nValidates Assumptions: Ensure methods and approaches are suitable.\nEnhances Skills: Improve technical skills through practice.\nBuilds Confidence: Familiarity with tools and techniques.\nRefines Methods: Test and optimize analytical strategies.\nEstimates Resources: Better planning for time and resource allocation.\nFacilitates Communication: Clearly convey project goals and outcomes.\nDocuments Process: Create a reference for reproducibility.\nGathers Early Feedback: Obtain input for adjustments before full implementation.\n\nhttps://scikit-learn.org/1.5/datasets/toy_dataset.html\nOnce that is working as a starter code-base you can swap it out for your full data later and start developing further for a more realistic real world project .\n\n\n\n\n\nAlways remember the following Debugging Steps:\n\nStep A: Copy the error message and search it online (Google or similar).\nStep B: Look through forums or documentation to find a solution.\nStep C: Implement the solution.\nStep D: If you’re still stuck, ask for help from classmates, TAs, or professors.\nStep E: Move on to the next issue and repeat the process.\n\n\n(Note: You can also use ChatGPT for debugging, but be cautious as the solutions may sometimes be inaccurate or incomplete.)"
  },
  {
    "objectID": "instructions/expectations.html#get-started-early",
    "href": "instructions/expectations.html#get-started-early",
    "title": "General Tips and Expectations",
    "section": "",
    "text": "Remember, slow and steady wins the race\nMaking steady, incremental progress on a large project generally makes it more manageable. Rushing to throw something together under a tight deadline often turns the process into a nightmare."
  },
  {
    "objectID": "instructions/expectations.html#graduate-level-work",
    "href": "instructions/expectations.html#graduate-level-work",
    "title": "General Tips and Expectations",
    "section": "",
    "text": "This is a graduate-level class, so each project should be viewed as specifications, not simple step-by-step requirements. Graduate-level work must be creative, individualized, and of high quality. To achieve an A-level grade, you are expected to exceed the specifications and create unique, novel solutions.\nFor example: If you’re asked to build visualizations to support your data science story, you won’t be told how many or what type of visualizations to create. This is up to you, based on your data and the creativity and quality you want to demonstrate.\nWe want you to move away from expecting someone else to tell you what to do, how to do it, and how much to do. Instead, you’ll adopt a professional approach—reviewing specifications provided in the assignments, determining what’s needed to exceed expectations, and demonstrating professional excellence.\nThere are countless ways to approach the project requirements, so be creative and thoughtful. Instructions outline the minimum requirements, but exceeding them will elevate the quality of your work.\nAutonomy and Critical Thinking:\n\nIn the workplace, step-by-step instructions are rare. You’ll need to interpret broad requirements and deliver professional results. Producing high-quality, accurate work with limited guidance is a key professional skill.\nAt this stage, move away from asking, “Do I have to do XYZ?” Instead, critically analyze challenges. If something is unclear, investigate and break it down fundamentally.\n\nDeveloping problem-solving skills is crucial. While it’s important to work independently for at least 10–20 minutes, if you’re still stuck after 30 minutes, seek help. Being resourceful is important, but knowing when to ask for assistance is equally valuable."
  },
  {
    "objectID": "instructions/expectations.html#the-intersection-of-skills-and-domain-knowledge",
    "href": "instructions/expectations.html#the-intersection-of-skills-and-domain-knowledge",
    "title": "General Tips and Expectations",
    "section": "",
    "text": "“Data science” is essentially a collection of useful computational and mathematical skills (statistics, cloud computing, machine learning, coding, etc). However, to maximize your effectiveness, these skills should be applied to a domain of interest (e.g., materials science, finance, healthcare, etc). Focusing and learning about a particular domain will help you specialize and make you more marketable.\nThat beind said, don’t worry about choosing the “perfect” domain—it’s always possible to pivot later, as many of the skills learned, such as problem-solving, critical thinking, and self-education, are transferable across all fields."
  },
  {
    "objectID": "instructions/expectations.html#what-is-impact",
    "href": "instructions/expectations.html#what-is-impact",
    "title": "General Tips and Expectations",
    "section": "",
    "text": "Impact in science refers to the significance and influence of research, often measured by metrics like citations, impact factor of journals, and indices like h-index. These metrics reflect how widely recognized and valuable the work is within the scientific community. Such quanities are used to compare researchers and journals, and are used to determine grant funding and career opportunities.\n\nImpact Factor (IF):\n\nA measure of a journal’s influence, calculated by averaging the number of citations to articles published in the journal over the past two years.\nHigher impact factors indicate a more influential journal.\n\nNumber of Citations:\n\nThe total count of how often a researcher’s work is cited by others, reflecting its influence within the scientific community.\nMore citations generally signal broader recognition or relevance of the research.\n\nh-index:\n\nA metric that measures both productivity and citation impact. An h-index of 10 means a researcher has 10 papers each cited at least 10 times.\nHigher h-index indicates more influential and widely recognized work.\n\ni10-index:\n\nCounts the number of a researcher’s publications with at least 10 citations.\nA straightforward measure of citation impact, commonly used by Google Scholar.\n\nImportance of Citations:\n\nCitations indicate that other researchers find the work valuable for their own research, increasing its perceived credibility and impact in the field."
  },
  {
    "objectID": "instructions/expectations.html#what-makes-a-good-research-project",
    "href": "instructions/expectations.html#what-makes-a-good-research-project",
    "title": "General Tips and Expectations",
    "section": "",
    "text": "Professional academic or industrial research is all about discovery, improvement, and novelty. You don’t necessarily need to have a project that acheive the following, but here are some guidelines for what makes “high impact” projects:\nIn no particular order:\n\nNovel computational tools: For example, development of a new Python package to tackle a class of problem which doesn’t have an existing suitable tool.\nCreating more user-friendly tools: For example, there might be a great C++ code, but with no python analogue. Python is easier to use, so if you make a pythonic version of an existing tool, it may get higher adoption, provided it is more or less as efficient to the competitors.\nMore efficient tools or methods: Achieving something 1.25x, 2x, 10x or 10000x faster than existing methods, or creating a new code package that is more efficient than a previous one.\nNovel methods: A completely new way of doing something (e.g. new classification algorithm)\nExisting methods applied to new domains: Using established methods to solve problems in a novel domain, e.g. applying a particular classification methodology to a problem or dataset that no one has applied it to before. Extent of impact obviously depends on the importance of the domain or use-case.\nCreation of novel Data Sets: Provides well-curated, clean datasets that can be used to address important scientific questions or problems.(often more useful if there is an accompanying API)\nNew insights or phenomena: Using data analysis techniques to uncover new insights or patterns that address key questions or problems. For example, discovering overarching governing rules (e.g., differential equations) that describe some observed phenomena.\n\nSolves a Major Problem: Addresses a critical or unresolved issue in the field, offering a breakthrough or significant advancement.\n\nRobust Data and Methodology: Employs sound, validated methodologies and high-quality data to ensure credibility and reliability (i.e. doing something rigorously, correctly, and generally better than the competition).\nInterdisciplinary Impact: Influences multiple fields or areas of study, increasing the breadth of its significance.\nHigh Citation Potential: Likely to be widely cited due to its significance, relevance, and applicability across different areas.\n\nYou can, of course, have multiple of these components in a single project, which will increase its prestige.\nThis is especially true when conducting academic research. Publications need to be novel and make a unique contribution to the body of human knowledge; otherwise, they will not be highly cited or considered particularly important."
  },
  {
    "objectID": "instructions/expectations.html#time-management",
    "href": "instructions/expectations.html#time-management",
    "title": "General Tips and Expectations",
    "section": "",
    "text": "80-20 Rule: This rule of thumb suggests that 80% of results come from 20% of causes. In other words, a small number of key factors drive the majority of outcomes. This principle applies to project management, where a few critical steps or decisions often determine the success of a project.\nFor example, it might take one week of steady work (30-40 hours) to complete 80% of a project, while the final 20% could take an additional four weeks.\n\nProjects tend to expand to fill the time available. No creative project—whether a book, song, poem, or paper—is ever truly 100% complete. There is an asymptotic limit as \\(t \\rightarrow \\infty\\), and true perfection is unattainable. The key is knowing when to “call it done.” This might happen at 95% or 99% completion, but eventually, we all have to stop. Strive to take this project as far as possible, but remember to stop and “call it done” at some point."
  },
  {
    "objectID": "instructions/expectations.html#visualization-guidelines",
    "href": "instructions/expectations.html#visualization-guidelines",
    "title": "General Tips and Expectations",
    "section": "",
    "text": "Visualizations are a critical component of your portfolio. Use them strategically to support your narrative. The more visual representations of your data, the better—higher-quality visualizations will result in a higher grade. Ensure that all graphics follow best practices:\n\nChoose the right chart type: Match the chart to the data (e.g., bar for categories, line for trends).\nMaintain simplicity: Avoid clutter and focus on the essential message.\nUse appropriate scales: Ensure axes have correct and intuitive scaling to avoid misinterpretation.\nLabel axes clearly: Include meaningful axis labels with units (e.g., “Temperature (°C)” or “Revenue (USD)”).\nInclude descriptive titles: Provide a concise, informative title that explains the visualization’s main takeaway.\nEnsure consistency: Use uniform color schemes, fonts, and styles across all charts in a presentation.\nHighlight key data: Use contrasting colors or annotations to draw attention to important points or trends.\nKeep proportions accurate: Maintain correct data-to-visual size relationships to avoid distortion.\nConsider the audience: Tailor the level of detail and style to the audience’s technical proficiency.\nTest readability: Ensure fonts, colors, and elements are clear and legible in various formats and sizes.\nUse interactivity carefully: Interactive features should add clarity, not complexity, to the visual."
  },
  {
    "objectID": "instructions/expectations.html#coding",
    "href": "instructions/expectations.html#coding",
    "title": "General Tips and Expectations",
    "section": "",
    "text": "While not required, practice is highly beneficial. It’s also a good habit to write your code from scratch, as this will build your problem-solving skills. You can use the code provided by professors as a reference, but always strive to write your own. Starting with a blank page is a valuable practice.\nTo get comfortable with the methods, review and modify the R and Python codes provided in class. Try applying these to your project data and experiment with creating small toy datasets, such as a CSV file or a text corpus. This helps you understand the structure of the data and what the algorithms are doing.\n\n\n\nIf you have big data, ALWAYS prototype on a small subset of the data, so that your code runs fast so that you can develop quickly, without waiting several minutes for each code cell to run. Do this by including a downsampling hyper-parameter at the beginning of your code, e.g. 0.1. When the code is robust and finalized, you can set the downsampling factor to 1, run it on the complete data set, and let your computer run overnight.\nIt is not a crazy idea to do a “trial run” of the project first from start to finish with a very basic dataset, e.g. penguins,diabetes, or iris. Make sure the “toy” data set is similar to your planned real world data set, for example, if you are planning an NLP project, don’t use a image dataset for your development process.\nThis will have the following benefits:\n\nClarifies Workflow: Understand the complete process from start to finish.\nIdentifies Challenges: Spot potential issues early on.\nValidates Assumptions: Ensure methods and approaches are suitable.\nEnhances Skills: Improve technical skills through practice.\nBuilds Confidence: Familiarity with tools and techniques.\nRefines Methods: Test and optimize analytical strategies.\nEstimates Resources: Better planning for time and resource allocation.\nFacilitates Communication: Clearly convey project goals and outcomes.\nDocuments Process: Create a reference for reproducibility.\nGathers Early Feedback: Obtain input for adjustments before full implementation.\n\nhttps://scikit-learn.org/1.5/datasets/toy_dataset.html\nOnce that is working as a starter code-base you can swap it out for your full data later and start developing further for a more realistic real world project ."
  },
  {
    "objectID": "instructions/expectations.html#debugging",
    "href": "instructions/expectations.html#debugging",
    "title": "General Tips and Expectations",
    "section": "",
    "text": "Always remember the following Debugging Steps:\n\nStep A: Copy the error message and search it online (Google or similar).\nStep B: Look through forums or documentation to find a solution.\nStep C: Implement the solution.\nStep D: If you’re still stuck, ask for help from classmates, TAs, or professors.\nStep E: Move on to the next issue and repeat the process.\n\n\n(Note: You can also use ChatGPT for debugging, but be cautious as the solutions may sometimes be inaccurate or incomplete.)"
  },
  {
    "objectID": "instructions/llm-usage.html",
    "href": "instructions/llm-usage.html",
    "title": "LLM usage",
    "section": "",
    "text": "We believe that the adoption of LLM tools is inevitable and will be an important skill for success in your future career. Therefore, appropriate and acceptable use of LLM tools is encouraged for this project. Use them to accelerate your workflow and learning, but not as a replacement for critical thinking and understanding. Carefully review and process their output, use them judiciously, and avoid bloating your text with LLM-generated content. Overusing these tools often degrades the quality of your work rather than enhancing it.\nRemember the following guidelines:\n\nUse common sense: If you feel like you’re doing something questionable, you probably are. A good test is to ask yourself, “Would I openly tell the professor or classmates what I’m doing right now?” If the answer is no, you’re probably doing something you shouldn’t.\nCite your LLM use cases: Always cite when and how you’ve used LLM tools. This is a requirement for the project.\nIs your use helping you grow professionally?: If your use of LLM tools is making you a more competent, efficient, and knowledgeable professional, you’re probably using them in an appropriate manner. If you’re using them as a shortcut to avoid work and gain free time, you’re using them incorrectly.\n\n\n\nALWAY CITE CONTENT OR IDEAS TAKEN FROM EXTERNAL SOURCES: e.g. websites, llm tools, papers\nALWAYS BE TRANSPARENT WHEN YOU ARE USING LLM TOOLS:\nPlease follow these guidelines:\n\nGeneral Tasks: Create and regularly update a dedicated LLM Transparency page to document how you are using LLM tools.\n\nThis page can serve as a “catch-all” for use cases that don’t involve content creation, such as reformatting your own ideas, commenting code that you wrote, or proofreading text, PDF summarization.\n\nContent Creation: If non-original content (code or text) is generated by an LLM, you must also cite it on specific pages, just like any external source.\n\nFor non-original content, always provide a citation.\nCite the LLM tool after each chunk of text or code it generates, using a BibTeX. For example1\n\n\n\n\n\nNote: Various useful non-LLM research tools can be found here at the following link\n\nTraditional research tools\n\nYou can use LLM tools for the following use cases\n\nAI research tools\nThese include\n\nre-formating text with LLM tools.\nCode explaination “describe what this code is doing in prose”\nText summarization\nProofreading\n\nchatGPT for project brainstorming\nUsing LLM tools to comment your code qualifies as an acceptible use case in this project. You can also use or code re-formatters such as black to increase the readability of your code.\n\n\n\n\n\nDO NOT use ChatGPT or other LLM tools to write large portions of your text or code.\n\n\nIf it is clear that you have used LLM tools to write large portions of your code or text, your grade will reflect this, likely in the range of 0% to 50% of the total points, depending on the quality of the work. LLM outputs still require significant polishing to fit into a well-written, cohesive narrative. If it is evident that you simply inserted large portions of LLM-generated content into your assignment without taking the time to refine it into a high-quality submission, your grade will reflect this, even if the usage does not rise to the level of plagiarism.\n\n\n\nIn extreme cases,the following actions will occur.\n\nOne-on-One Investigation: You will meet with department faculty for a thorough review of your project. You will be asked to explain your work in detail, including what specific chunks of code do, why you made certain decisions, and how you reached your conclusions.\nReferral to the Honor Council: If, during this meeting, it is determined that you do not have sufficient understanding of the content that you claimed to have created, the case will be documented and sent to the honor council. This can result in a permanent mark on your transcript and may even lead to expulsion from the university."
  },
  {
    "objectID": "instructions/llm-usage.html#citation",
    "href": "instructions/llm-usage.html#citation",
    "title": "LLM usage",
    "section": "",
    "text": "ALWAY CITE CONTENT OR IDEAS TAKEN FROM EXTERNAL SOURCES: e.g. websites, llm tools, papers\nALWAYS BE TRANSPARENT WHEN YOU ARE USING LLM TOOLS:\nPlease follow these guidelines:\n\nGeneral Tasks: Create and regularly update a dedicated LLM Transparency page to document how you are using LLM tools.\n\nThis page can serve as a “catch-all” for use cases that don’t involve content creation, such as reformatting your own ideas, commenting code that you wrote, or proofreading text, PDF summarization.\n\nContent Creation: If non-original content (code or text) is generated by an LLM, you must also cite it on specific pages, just like any external source.\n\nFor non-original content, always provide a citation.\nCite the LLM tool after each chunk of text or code it generates, using a BibTeX. For example1"
  },
  {
    "objectID": "instructions/llm-usage.html#acceptable-use-cases",
    "href": "instructions/llm-usage.html#acceptable-use-cases",
    "title": "LLM usage",
    "section": "",
    "text": "Note: Various useful non-LLM research tools can be found here at the following link\n\nTraditional research tools\n\nYou can use LLM tools for the following use cases\n\nAI research tools\nThese include\n\nre-formating text with LLM tools.\nCode explaination “describe what this code is doing in prose”\nText summarization\nProofreading\n\nchatGPT for project brainstorming\nUsing LLM tools to comment your code qualifies as an acceptible use case in this project. You can also use or code re-formatters such as black to increase the readability of your code."
  },
  {
    "objectID": "instructions/llm-usage.html#unacceptable-use-cases",
    "href": "instructions/llm-usage.html#unacceptable-use-cases",
    "title": "LLM usage",
    "section": "",
    "text": "DO NOT use ChatGPT or other LLM tools to write large portions of your text or code.\n\n\nIf it is clear that you have used LLM tools to write large portions of your code or text, your grade will reflect this, likely in the range of 0% to 50% of the total points, depending on the quality of the work. LLM outputs still require significant polishing to fit into a well-written, cohesive narrative. If it is evident that you simply inserted large portions of LLM-generated content into your assignment without taking the time to refine it into a high-quality submission, your grade will reflect this, even if the usage does not rise to the level of plagiarism.\n\n\n\nIn extreme cases,the following actions will occur.\n\nOne-on-One Investigation: You will meet with department faculty for a thorough review of your project. You will be asked to explain your work in detail, including what specific chunks of code do, why you made certain decisions, and how you reached your conclusions.\nReferral to the Honor Council: If, during this meeting, it is determined that you do not have sufficient understanding of the content that you claimed to have created, the case will be documented and sent to the honor council. This can result in a permanent mark on your transcript and may even lead to expulsion from the university."
  },
  {
    "objectID": "instructions/quarto-tips.html",
    "href": "instructions/quarto-tips.html",
    "title": "Quarto Tips",
    "section": "",
    "text": "You can decide when to use .qmd vs .ipynb for structuring your code, but I recommend the following guidelines:\n\nIf the file contains any code (either in R or Python), ALWAYS use .ipynb.\nDo not mix R and Python in the same notebook.\nIf the file is purely markdown without code, use .qmd.\nUse Quarto includes to modularize your content (see below for more details). This is also demonstrated in the project skeleton.\n\n\n\n\nQuarto includes (e.g., {{&lt; include _content.qmd &gt;}}) are highly recommended for modularizing and organizing your content. While optional, they offer several advantages.\nNote: You can include a .qmd file in a .ipynb file, but not vice versa.\n\n\n\nModularization: Breaking your project into smaller, reusable chunks simplifies the management of complex documents. You can work on specific sections without altering the entire project.\nReusability: Includes allow you to reuse content blocks across multiple documents, making them ideal for repetitive sections like headers or footers.\nConsistency: By using includes, you ensure uniformity across your documents. Updating an include file will automatically apply the changes wherever it’s used.\nSimplifies Collaboration: In team settings, includes allow different contributors to work on separate sections simultaneously, reducing merge conflicts and making the project easier to maintain.\nImproved Organization: Includes help keep your main files clean and focused by loading content from separate, well-organized files. This makes your project more manageable and easier to navigate."
  },
  {
    "objectID": "instructions/quarto-tips.html#file-types",
    "href": "instructions/quarto-tips.html#file-types",
    "title": "Quarto Tips",
    "section": "",
    "text": "You can decide when to use .qmd vs .ipynb for structuring your code, but I recommend the following guidelines:\n\nIf the file contains any code (either in R or Python), ALWAYS use .ipynb.\nDo not mix R and Python in the same notebook.\nIf the file is purely markdown without code, use .qmd.\nUse Quarto includes to modularize your content (see below for more details). This is also demonstrated in the project skeleton."
  },
  {
    "objectID": "instructions/quarto-tips.html#quarto-includes",
    "href": "instructions/quarto-tips.html#quarto-includes",
    "title": "Quarto Tips",
    "section": "",
    "text": "Quarto includes (e.g., {{&lt; include _content.qmd &gt;}}) are highly recommended for modularizing and organizing your content. While optional, they offer several advantages.\nNote: You can include a .qmd file in a .ipynb file, but not vice versa.\n\n\n\nModularization: Breaking your project into smaller, reusable chunks simplifies the management of complex documents. You can work on specific sections without altering the entire project.\nReusability: Includes allow you to reuse content blocks across multiple documents, making them ideal for repetitive sections like headers or footers.\nConsistency: By using includes, you ensure uniformity across your documents. Updating an include file will automatically apply the changes wherever it’s used.\nSimplifies Collaboration: In team settings, includes allow different contributors to work on separate sections simultaneously, reducing merge conflicts and making the project easier to maintain.\nImproved Organization: Includes help keep your main files clean and focused by loading content from separate, well-organized files. This makes your project more manageable and easier to navigate."
  },
  {
    "objectID": "instructions/website-structure.html",
    "href": "instructions/website-structure.html",
    "title": "Website project structure",
    "section": "",
    "text": "Please at miniumum include the following pages in your website:\n\nLanding page\nReport\nTechnical details\n\nData collection\nData cleaning\nEDA\nUnsupervised-learning\nSupervised-learning\nLLM-usage\nProgress-log\n\n\nPlease adhere closely to this structure, for consistency accross projects.\nSub-sections can be handles as markdown headers in the respective pages.\nYou can add more pages,and if you want, you can merge EDA and unsupervised learning into one page, since the are similar. Or make these section headers in the dropdown menu, for further sub-sections creation.\nFor example:\n\nLanding page\nReport\nTechnical details\n\nData collection\nData cleaning\nEDA\nUnsupervised-learning\n\nClustering\nDimensionality Reduction\n\nSupervised-learning\n\nFeature selection\n\nregression\nclassification\n\nClassification\n\nBinary classification\nMulti-class classification\n\nRegression\n\nLLM-usage\nProgress-log\n\n\nImportant: Exactly what you put on these pages will be specific you your project and data. Some things might “make more sense” on one page rather than another, depending on your workflow. Organize your project in a logical way that makes the most sense to you.\nA skeleton of the recommended version of the website is provided in the github classroom repository.\n./\n├── README.md\n├── _quarto.yml\n├── assets\n│   ├── gu-logo.png\n│   ├── nature.csl\n│   └── references.bib\n├── build.sh\n├── data\n│   ├── processed-data\n│   │   └── countries_population.csv\n│   └── raw-data\n│       └── countries_population.csv\n├── index.qmd\n├── instructions\n│   ├── expectations.qmd\n│   ├── github-usage.qmd\n│   ├── llm-usage.qmd\n│   ├── overview.qmd\n│   ├── quarto-tips.qmd\n│   ├── topic-selection.qmd\n│   └── website-structure.qmd\n├── report\n│   └── report.qmd\n└── technical-details\n    ├── data-cleaning\n    │   ├── instructions.qmd\n    │   └── main.ipynb\n    ├── data-collection\n    │   ├── closing.qmd\n    │   ├── instructions.qmd\n    │   ├── main.ipynb\n    │   ├── methods.qmd\n    │   └── overview.qmd\n    ├── eda\n    │   ├── instructions.qmd\n    │   └── main.ipynb\n    ├── llm-usage-log.qmd\n    ├── progress-log.qmd\n    ├── supervised-learning\n    │   ├── instructions.qmd\n    │   └── main.ipynb\n    └── unsupervised-learning\n        ├── instructions.qmd\n        └── main.ipynb\nAlways strive to incorporate the following:\n\nStructure: Use clear headings and subheadings to break down each section of your EDA.\nClarity: Provide concise explanations for all tables and visualizations, ensuring they are easy to interpret.\nCode Links: Link to relevant code (e.g., GitHub) or embed code snippets for transparency and reproducibility.\nReproducibility: Make your EDA reproducible by providing access to the dataset, scripts, and tools you used.\nVisualization: Use visualizations to convey key insights\n\n\n\nIt is required that you build your website with Quarto.\n\n\n\nYou MUST host your website on the Georgetown Domains web space.\nNo exceptions. You may NOT use anything other than Georgetown Domains to host your website. For example, no RPubs, WordPress, Squarespace, or any other website development toolset. Failure to comply with this rule will result in a ZERO.\n\n\n\nKnowing your audience in data science writing is crucial because it shapes how you present information. Technical stakeholders may require detailed explanations of methodologies, while non-technical audiences need clear, simplified insights and data-driven conclusions. Tailoring your message ensures your analysis is both understandable and impactful, driving informed decision-making.\n\nExamples of technical audiences include data scientists, software engineers, and IT professionals. These individuals expect detailed explanations of models, algorithms, methodologies, or system architectures, and they’re comfortable with technical jargon, such as discussing hyperparameters, programming frameworks, or machine learning techniques.\nNon-technical audiences include executives, marketing teams, and clients. They prioritize high-level insights, actionable results, and visualizations that convey the impact of data without requiring an understanding of complex methods. For instance, a CEO may want to know how a model affects business strategy or revenue, without diving into the underlying technical details.\n\nIn this project you will cater to both audiences. This is done by having regions of your website for both audiences (see website struture)"
  },
  {
    "objectID": "instructions/website-structure.html#website-development",
    "href": "instructions/website-structure.html#website-development",
    "title": "Website project structure",
    "section": "",
    "text": "It is required that you build your website with Quarto."
  },
  {
    "objectID": "instructions/website-structure.html#website-hosting",
    "href": "instructions/website-structure.html#website-hosting",
    "title": "Website project structure",
    "section": "",
    "text": "You MUST host your website on the Georgetown Domains web space.\nNo exceptions. You may NOT use anything other than Georgetown Domains to host your website. For example, no RPubs, WordPress, Squarespace, or any other website development toolset. Failure to comply with this rule will result in a ZERO."
  },
  {
    "objectID": "instructions/website-structure.html#the-two-audiences",
    "href": "instructions/website-structure.html#the-two-audiences",
    "title": "Website project structure",
    "section": "",
    "text": "Knowing your audience in data science writing is crucial because it shapes how you present information. Technical stakeholders may require detailed explanations of methodologies, while non-technical audiences need clear, simplified insights and data-driven conclusions. Tailoring your message ensures your analysis is both understandable and impactful, driving informed decision-making.\n\nExamples of technical audiences include data scientists, software engineers, and IT professionals. These individuals expect detailed explanations of models, algorithms, methodologies, or system architectures, and they’re comfortable with technical jargon, such as discussing hyperparameters, programming frameworks, or machine learning techniques.\nNon-technical audiences include executives, marketing teams, and clients. They prioritize high-level insights, actionable results, and visualizations that convey the impact of data without requiring an understanding of complex methods. For instance, a CEO may want to know how a model affects business strategy or revenue, without diving into the underlying technical details.\n\nIn this project you will cater to both audiences. This is done by having regions of your website for both audiences (see website struture)"
  },
  {
    "objectID": "technical-details/data-cleaning/instructions.html",
    "href": "technical-details/data-cleaning/instructions.html",
    "title": "Overview",
    "section": "",
    "text": "Our data cleaning methods were comparable for both the cervical (cesc) and breast (brca) cancer datasets due to the dataset having similar columns due to both diseases being cancer. The clinical breast cancer dataset originally has 5546 rows and 210 columns representing 1098 patients. The clinical cervical cancer dataset originally has 1535 rows and 210 columns representing 307 patients.\nOur data cleaning was focused on three key areas:\nVisualizations below will be centered on the brca dataset due to the larger number of samples. However, the similar process for cleaning the cesc dataset can be found here along with the data cleaning code for the brca dataset."
  },
  {
    "objectID": "technical-details/data-cleaning/instructions.html#suggested-page-structure",
    "href": "technical-details/data-cleaning/instructions.html#suggested-page-structure",
    "title": "Instructions",
    "section": "",
    "text": "Here’s one suggested structure for organizing your technical pages. You can adjust this as needed:\nAudience:Remember that these are written for a technical audience. Assume they have completed the DSAN program, but would appreciate refreshers of the important concepts.\n\nIntroduction and Motivation: Briefly outline your plan. What are you doing on this page, and why? Provide context and explain the goals of your analysis.\nOverview of Methods: Give a concise explanation of the methods used. For example, if using K-Means clustering, describe what it is, how it works, the inputs and outputs, and key hyperparameters.\nCode: Include the code you used to implement your workflow.\nSummary and Interpretation of Results: Summarize your findings, interpret the results, and discuss their technical implications."
  },
  {
    "objectID": "technical-details/data-cleaning/instructions.html#general-comments",
    "href": "technical-details/data-cleaning/instructions.html#general-comments",
    "title": "Instructions",
    "section": "",
    "text": "Iterative Process: Data cleaning is often not a one-time process. As your analysis progresses, you may need to revisit the cleaning phase, and re-run the code, to adjust to new insights or requirements.\nClarity and Reproducibility: Ensure your documentation is clear and thorough. Others should be able to follow your steps and achieve the same results.\nVisualizations: Use before-and-after visualizations to illustrate the impact of your cleaning steps, making the process more intuitive and transparent.\n\nBy the end of this phase, your cleaned data should be well-documented and ready for further stages, such as Exploratory Data Analysis (EDA) and Machine Learning."
  },
  {
    "objectID": "technical-details/data-cleaning/instructions.html#what-to-address",
    "href": "technical-details/data-cleaning/instructions.html#what-to-address",
    "title": "Instructions",
    "section": "",
    "text": "The following is a list of some of the things you should address on this page. This list is not exhaustive, and you should use your judgment to decide what is most relevant to your project.\nThe Data Cleaning page of your portfolio is where you document the process of transforming your raw data into a usable format. Data cleaning is essential for ensuring the quality of your analysis, and this page should serve as a clear and reproducible guide for anyone reviewing your work. It also provides transparency, allowing others to trace the steps you took to prepare your data.\nThe following is a guide to help you get started with possible thing to address on this page .\n\nDescription of the Data Cleaning Process: Explain the steps you took to clean and preprocess the data.\nCode Documentation: Provide the code used in the data cleaning process (link to GitHub or embed the code directly).\nProvide examples of data before and after cleaning: e.g. with df.head() or df.describe()\nRaw and Cleaned Data Links: Ensure your page links to both the original (raw) dataset and the cleaned dataset. (please keep organized and store the cleaned data in data/processed-data, or similar location which doesn’t get synced to GitHub)\n\nPossible things to include:\nIntroduction to Data Cleaning:\n\nProvide a brief explanation of the data cleaning phase, its importance in preparing the data for further analysis (EDA, modeling), and its iterative nature.\nMention that data cleaning may need to be revisited as the project evolves and analysis goals change.\n\nManaging Missing Data:\n\nIdentify Missing Values: Explain how you identified missing data and where it occurred.\nHandling Missing Data: Describe how missing values were addressed (e.g., imputation, removal of rows/columns).\nVisualize Missing Data: Include visualizations (e.g., heatmaps) showing missing values before and after handling them.\n\nOutlier Detection and Treatment:\n\nIdentify Outliers: Describe the methods you used to detect outliers in the dataset.\nAddressing Outliers: Explain how outliers were treated (e.g., removal, transformation, or retaining them for analysis).\nVisualize Outliers: Use visualizations (e.g., box plots) to show how outliers were managed.\n\nData Type Correction and Formatting:\n\nReview Data Types: Summarize the types of variables (numerical, categorical, date-time, etc.) and ensure they are correctly formatted.\nTransformation: Document any transformations performed, such as converting date formats, handling categorical variables, or encoding labels.\nImpact of Changes: Briefly explain why these changes were necessary for accurate analysis.\n\nNormalization and Scaling:\n\nData Distribution Analysis: Check and discuss the distribution of numerical variables (e.g., skewness).\nNormalization Techniques: Describe any normalization or scaling techniques used (e.g., min-max scaling, z-score normalization).\nBefore-and-After Visualizations: Provide visualizations comparing the data before and after scaling or normalization.\n\nSubsetting the Data:\n\nData Filtering: Explain any subsetting or filtering of the data (e.g., selecting quantitative or qualitative columns).\nRationale: Justify why you chose to work with a particular subset of the data."
  },
  {
    "objectID": "technical-details/data-collection/instructions.html",
    "href": "technical-details/data-collection/instructions.html",
    "title": "Data Collection Overview",
    "section": "",
    "text": "The data used in this project were obtained from the National Cancer Institute (NCI) Genomic Data Commons (GDC)1, a centralized repository designed to support cancer research by providing harmonized clinical, genomic, and exposure-related data across multiple cancer types. The GDC integrates data from large-scale initiatives such as The Cancer Genome Atlas (TCGA)2 and applies standardized data models, vocabularies, and quality control procedures to ensure consistency and reproducibility across studies.\n\n\n\nNational Cancer Institute (NCI) Genomic Data Commons (GDC)"
  },
  {
    "objectID": "technical-details/data-collection/instructions.html#suggested-page-structure",
    "href": "technical-details/data-collection/instructions.html#suggested-page-structure",
    "title": "Data Collection Overview",
    "section": "Suggested page structure",
    "text": "Suggested page structure\nHere’s one suggested structure for organizing your technical pages. You can adjust this as needed:\nAudience:Remember that these are written for a technical audience. Assume they have completed the DSAN program, but would appreciate refreshers of the important concepts.\n\nIntroduction and Motivation: Briefly outline your plan. What are you doing on this page, and why? Provide context and explain the goals of your analysis.\nOverview of Methods: Give a concise explanation of the methods used. For example, if using K-Means clustering, describe what it is, how it works, the inputs and outputs, and key hyperparameters.\nCode: Include the code you used to implement your workflow.\nSummary and Interpretation of Results: Summarize your findings, interpret the results, and discuss their technical implications.\n\nIn the provide repo, these subsections have been included in the data-collection file as separate .qmd files that can be embedded using the {{&lt; include &gt;}} tag."
  },
  {
    "objectID": "technical-details/data-collection/instructions.html#what-to-address",
    "href": "technical-details/data-collection/instructions.html#what-to-address",
    "title": "Data Collection Overview",
    "section": "What to address",
    "text": "What to address\nThe following is a list of some of the things you should address on this page. This list is not exhaustive, and you should use your judgment to decide what is most relevant to your project.\nOn this page, you will focus on data collection, which is an essential step for future analysis. You should have already selected a specific data-science question that can be addressed in a data-driven way.\nIt is recommended that you focus on one or two of the following data formats, text, tabular, image, geospatial, or network data.\nTabular (e.g. CSV files) and text formats are highly recommended, as these are covered most thoroughly in the course. Deviating from these formats may require additional work on your end. Please avoid timeseries data formats, as these require special methods not covered in the course. You can include as many additional formats as you want. Your project will revolve around the data you gather and will include data collection, analysis, visualization, and storytelling."
  },
  {
    "objectID": "technical-details/data-collection/instructions.html#start-collecting-data",
    "href": "technical-details/data-collection/instructions.html#start-collecting-data",
    "title": "Data Collection Overview",
    "section": "Start collecting data:",
    "text": "Start collecting data:\nBegin gathering your data and document the methods and sources on the Data Collection page of your project. Include screenshots or example tables to illustrate the data collection process without displaying entire datasets. Ensure transparency so anyone can replicate your work."
  },
  {
    "objectID": "technical-details/data-collection/instructions.html#saving-the-raw-data",
    "href": "technical-details/data-collection/instructions.html#saving-the-raw-data",
    "title": "Data Collection Overview",
    "section": "Saving the raw data",
    "text": "Saving the raw data\n\nDuring the collection phase, save the collected data locally to the data/raw-data folder, in the root of the project, for later processing. (Do not sync this folder to GitHub.)\nRemember, the “raw data” should typically be left “pristine”, to ensure replicability.\nLater when you clean the data, you should save the cleaned data to the data/processed-data folder, in the root of the project.\nYou should also save files you download manually from online to this folder"
  },
  {
    "objectID": "technical-details/data-collection/instructions.html#requirements",
    "href": "technical-details/data-collection/instructions.html#requirements",
    "title": "Data Collection Overview",
    "section": "Requirements:",
    "text": "Requirements:\n\nYour data must be relevant to the project’s overall goals and help solve your research questions.\nYou must use at least one API to collect your data.\nEnsure you have at least one regression target: a continuous quantity that can be used for regression prediction with other features.\nEnsure you have at least one binary classification target: a two-class (A,B) label that can be predicted using other features.\nEnsure you have at least one multiclass-classification target: a multi-class (A,B,C …) label that can be predicted using other features.\nDo not use a Kaggle topic—this project is meant to simulate a real-world project. Kaggle datasets are typically too clean and have already been prepped for analysis, which doesn’t align with the project’s goals.\n\nFocus on data that tells a compelling story and supports the techniques covered in the class (e.g., clustering, classification, regression)."
  },
  {
    "objectID": "technical-details/data-collection/overview.html",
    "href": "technical-details/data-collection/overview.html",
    "title": "Overview",
    "section": "",
    "text": "The data used in this project were obtained from the National Cancer Institute (NCI) Genomic Data Commons (GDC)1, a centralized repository designed to support cancer research by providing harmonized clinical, genomic, and exposure-related data across multiple cancer types. The GDC integrates data from large-scale initiatives such as The Cancer Genome Atlas (TCGA)2 and applies standardized data models, vocabularies, and quality control procedures to ensure consistency and reproducibility across studies.\n{alt = “National Cancer Institute Genomic Data Commons home page”}"
  },
  {
    "objectID": "technical-details/llm-usage-log.html",
    "href": "technical-details/llm-usage-log.html",
    "title": "LLM usage log",
    "section": "",
    "text": "This page can serve as a “catch-all” for LLM use cases that don’t involve content creation, such as reformatting your own ideas, commenting code that you wrote, or proofreading text, PDF summarization.\nLLM tools were used in the following way for the tasks below"
  },
  {
    "objectID": "technical-details/llm-usage-log.html#brainstorming",
    "href": "technical-details/llm-usage-log.html#brainstorming",
    "title": "LLM usage log",
    "section": "Brainstorming",
    "text": "Brainstorming\n\nTo create the initial idea, LLM tools were used to brainstorm ideas and provide feedback and refine the project plan."
  },
  {
    "objectID": "technical-details/llm-usage-log.html#writing",
    "href": "technical-details/llm-usage-log.html#writing",
    "title": "LLM usage log",
    "section": "Writing:",
    "text": "Writing:\n\nReformating text from bulleted lists into proses\nProofreading\nText summarization for literature review"
  },
  {
    "objectID": "technical-details/llm-usage-log.html#code",
    "href": "technical-details/llm-usage-log.html#code",
    "title": "LLM usage log",
    "section": "Code:",
    "text": "Code:\n\nCode commenting and explanatory documentation"
  },
  {
    "objectID": "technical-details/supervised-learning/instructions.html",
    "href": "technical-details/supervised-learning/instructions.html",
    "title": "Instructions",
    "section": "",
    "text": "Note: You should remove these instruction once you have read and understood them. They should not be included in your final submission.\nRemember: Exactly what do you put on this page will be specific you your project and data. Some things might “make more sense” on one page rather than another, depending on your workflow. Organize your project in a logical way that makes the most sense to you.\n\n\nHere’s one suggested structure for organizing your technical pages. You can adjust this as needed:\nAudience:Remember that these are written for a technical audience. Assume they have completed the DSAN program, but would appreciate refreshers of the important concepts.\n\nIntroduction and Motivation: Briefly outline your plan. What are you doing on this page, and why? Provide context and explain the goals of your analysis.\nOverview of Methods: Give a concise explanation of the methods used. For example, if using K-Means clustering, describe what it is, how it works, the inputs and outputs, and key hyperparameters.\nCode: Include the code you used to implement your workflow.\nSummary and Interpretation of Results: Summarize your findings, interpret the results, and discuss their technical implications.\n\n\n\n\nThe following is a list of some of the things you should address on this page. This list is not exhaustive, and you should use your judgment to decide what is most relevant to your project.\nPlease do some form of “Feature selection” in your project and include a section on it. Discuss the process you went through to select the features that you used in your model, this should be done for both classification models and regression models. What did you include and why? What did you exclude? What was the reasoning behind your decisions? This section can be included here, or you can make a new page in the dropdown menu for it.\nPlease break this page into a “regression” section, “binary classification” section, and a “Multi-class classification” section. For each case you should try multiple methods, including those discussed in class, and compare and contrast their preformance and results.\n\n\n\n\nNormalization or Standardization: Apply techniques to scale the data appropriately.\nFeature Selection or Extraction: Identify and select the most relevant features for your analysis.\nEncoding Categorical Variables: Convert categorical variables into a suitable format for modeling.\n\n\n\n\n\nModel Rationale: Explain the reasons for selecting specific models or algorithms.\nOverview of Algorithms: Provide a brief overview of the algorithms used\n\n\n\n\n\nSplit Methods: Detail the splitting methods used (e.g., train-test split, cross-validation).\nDataset Proportions: Specify the proportions used for splitting the dataset.\n\n\n\n\n\nBinary Classification Metrics: Discuss metrics such as accuracy, precision, recall, F1 score, and ROC-AUC.\nMulticlass Classification Metrics: Include metrics such as confusion matrix and macro/micro F1 score.\nRegression Metrics: Explain metrics such as RMSE, MAE, and R-squared, parity plots, etc.\n\n\n\n\n\nModel Performance Summary: Provide a summary of the model’s performance.\nVisualizations: Include visualizations of results (e.g., ROC curves, feature importance plots).\n\n\n\n\n\nResult Interpretation: Interpret the results obtained from the analysis.\nModel Performance Comparison: Compare the performance of different models.\nInsights Gained: Share insights learned from the analysis."
  },
  {
    "objectID": "technical-details/supervised-learning/instructions.html#suggested-page-structure",
    "href": "technical-details/supervised-learning/instructions.html#suggested-page-structure",
    "title": "Instructions",
    "section": "",
    "text": "Here’s one suggested structure for organizing your technical pages. You can adjust this as needed:\nAudience:Remember that these are written for a technical audience. Assume they have completed the DSAN program, but would appreciate refreshers of the important concepts.\n\nIntroduction and Motivation: Briefly outline your plan. What are you doing on this page, and why? Provide context and explain the goals of your analysis.\nOverview of Methods: Give a concise explanation of the methods used. For example, if using K-Means clustering, describe what it is, how it works, the inputs and outputs, and key hyperparameters.\nCode: Include the code you used to implement your workflow.\nSummary and Interpretation of Results: Summarize your findings, interpret the results, and discuss their technical implications."
  },
  {
    "objectID": "technical-details/supervised-learning/instructions.html#what-to-address",
    "href": "technical-details/supervised-learning/instructions.html#what-to-address",
    "title": "Instructions",
    "section": "",
    "text": "The following is a list of some of the things you should address on this page. This list is not exhaustive, and you should use your judgment to decide what is most relevant to your project.\nPlease do some form of “Feature selection” in your project and include a section on it. Discuss the process you went through to select the features that you used in your model, this should be done for both classification models and regression models. What did you include and why? What did you exclude? What was the reasoning behind your decisions? This section can be included here, or you can make a new page in the dropdown menu for it.\nPlease break this page into a “regression” section, “binary classification” section, and a “Multi-class classification” section. For each case you should try multiple methods, including those discussed in class, and compare and contrast their preformance and results."
  },
  {
    "objectID": "technical-details/supervised-learning/instructions.html#data-preprocessing",
    "href": "technical-details/supervised-learning/instructions.html#data-preprocessing",
    "title": "Instructions",
    "section": "",
    "text": "Normalization or Standardization: Apply techniques to scale the data appropriately.\nFeature Selection or Extraction: Identify and select the most relevant features for your analysis.\nEncoding Categorical Variables: Convert categorical variables into a suitable format for modeling."
  },
  {
    "objectID": "technical-details/supervised-learning/instructions.html#model-selection",
    "href": "technical-details/supervised-learning/instructions.html#model-selection",
    "title": "Instructions",
    "section": "",
    "text": "Model Rationale: Explain the reasons for selecting specific models or algorithms.\nOverview of Algorithms: Provide a brief overview of the algorithms used"
  },
  {
    "objectID": "technical-details/supervised-learning/instructions.html#training-and-testing-strategy",
    "href": "technical-details/supervised-learning/instructions.html#training-and-testing-strategy",
    "title": "Instructions",
    "section": "",
    "text": "Split Methods: Detail the splitting methods used (e.g., train-test split, cross-validation).\nDataset Proportions: Specify the proportions used for splitting the dataset."
  },
  {
    "objectID": "technical-details/supervised-learning/instructions.html#model-evaluation-metrics",
    "href": "technical-details/supervised-learning/instructions.html#model-evaluation-metrics",
    "title": "Instructions",
    "section": "",
    "text": "Binary Classification Metrics: Discuss metrics such as accuracy, precision, recall, F1 score, and ROC-AUC.\nMulticlass Classification Metrics: Include metrics such as confusion matrix and macro/micro F1 score.\nRegression Metrics: Explain metrics such as RMSE, MAE, and R-squared, parity plots, etc."
  },
  {
    "objectID": "technical-details/supervised-learning/instructions.html#results",
    "href": "technical-details/supervised-learning/instructions.html#results",
    "title": "Instructions",
    "section": "",
    "text": "Model Performance Summary: Provide a summary of the model’s performance.\nVisualizations: Include visualizations of results (e.g., ROC curves, feature importance plots)."
  },
  {
    "objectID": "technical-details/supervised-learning/instructions.html#discussion",
    "href": "technical-details/supervised-learning/instructions.html#discussion",
    "title": "Instructions",
    "section": "",
    "text": "Result Interpretation: Interpret the results obtained from the analysis.\nModel Performance Comparison: Compare the performance of different models.\nInsights Gained: Share insights learned from the analysis."
  },
  {
    "objectID": "brca-cleaning.html",
    "href": "brca-cleaning.html",
    "title": "EDA for breast cancer dataset",
    "section": "",
    "text": "# Import relevant libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.io as pio\npio.renderers.default = \"notebook_connected\"\nimport missingno as msno\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom scipy import stats\nfrom scipy.stats import norm, skew\n\n\n# Import dataset\nbrca_df_original = pd.read_csv(\"data/raw-data/brca/brca-clinical.tsv\", sep=\"\\t\")\n\n# Create a copy of the original dataframe to work on\nbrca_df = brca_df_original.copy()\n\n# Display first few rows of the dataset\nbrca_df.head()\n\n\n\n\n\n\n\n\nproject.project_id\ncases.case_id\ncases.consent_type\ncases.days_to_consent\ncases.days_to_lost_to_followup\ncases.disease_type\ncases.index_date\ncases.lost_to_followup\ncases.primary_site\ncases.submitter_id\n...\ntreatments.treatment_duration\ntreatments.treatment_effect\ntreatments.treatment_effect_indicator\ntreatments.treatment_frequency\ntreatments.treatment_id\ntreatments.treatment_intent_type\ntreatments.treatment_or_therapy\ntreatments.treatment_outcome\ntreatments.treatment_outcome_duration\ntreatments.treatment_type\n\n\n\n\n0\nTCGA-BRCA\n001cef41-ff86-4d3f-a140-a647ac4b10a1\nInformed Consent\n-34\n'--\nDuctal and Lobular Neoplasms\nDiagnosis\n'--\nBreast\nTCGA-E2-A1IU\n...\n'--\n'--\n'--\n'--\n1b884f21-eb24-467f-aba2-208af17070b9\nAdjuvant\nno\n'--\n'--\nRadiation Therapy, NOS\n\n\n1\nTCGA-BRCA\n001cef41-ff86-4d3f-a140-a647ac4b10a1\nInformed Consent\n-34\n'--\nDuctal and Lobular Neoplasms\nDiagnosis\n'--\nBreast\nTCGA-E2-A1IU\n...\n'--\n'--\n'--\n'--\n27868bc3-23c8-5e85-a0e2-314e6cdf9b2a\nAdjuvant\nyes\nTreatment Ongoing\n'--\nHormone Therapy\n\n\n2\nTCGA-BRCA\n001cef41-ff86-4d3f-a140-a647ac4b10a1\nInformed Consent\n-34\n'--\nDuctal and Lobular Neoplasms\nDiagnosis\n'--\nBreast\nTCGA-E2-A1IU\n...\n'--\n'--\n'--\n'--\naedf144c-6b7b-4d76-a3cb-4271aef10f1d\nFirst-Line Therapy\nyes\n'--\n'--\nSurgery, NOS\n\n\n3\nTCGA-BRCA\n0045349c-69d9-4306-a403-c9c1fa836644\nInformed Consent\n76\n'--\nAdenomas and Adenocarcinomas\nDiagnosis\n'--\nBreast\nTCGA-A1-A0SB\n...\n'--\n'--\n'--\n'--\n0a534cae-de91-5e77-a3e7-b52d46bd3966\nFirst-Line Therapy\nyes\n'--\n'--\nSurgery, NOS\n\n\n4\nTCGA-BRCA\n00807dae-9f4a-4fd1-aac2-82eb11bf2afb\nInformed Consent\n19\n'--\nAdnexal and Skin Appendage Neoplasms\nDiagnosis\nNo\nBreast\nTCGA-A2-A04W\n...\n'--\n'--\n'--\n'--\n024faa94-ec57-4d14-b919-62dcab409958\nAdjuvant\nyes\nTreatment Ongoing\n'--\nBisphosphonate Therapy\n\n\n\n\n5 rows × 210 columns\n\n\n\n\n# Check the shape of the dataset\nbrca_df.shape\n\n(5546, 210)\n\n\nFrom the first rows, we can see that there are several columns with missing values, represented as ’– . These values will be turned to NA for easier handling\n\n# Replace \"'--\" as NA\nbrca_df_original.replace('\\'--', np.nan, inplace=True)\nbrca_df.replace('\\'--', np.nan, inplace=True)\n\n\nInspect key columns for survival analysis\n\n# List all cols starting with 'demographic'\ndemographic_cols = [col for col in brca_df.columns if col.startswith('demographic')]\nprint(\"Columns starting with 'demographic':\")\nfor col in demographic_cols:\n    print(f\"  - {col}\")\nprint(f\"\\nTotal demographic columns: {len(demographic_cols)}\")\n\n\nColumns starting with 'demographic':\n  - demographic.age_at_index\n  - demographic.age_is_obfuscated\n  - demographic.cause_of_death\n  - demographic.cause_of_death_source\n  - demographic.country_of_birth\n  - demographic.country_of_residence_at_enrollment\n  - demographic.days_to_birth\n  - demographic.days_to_death\n  - demographic.demographic_id\n  - demographic.education_level\n  - demographic.ethnicity\n  - demographic.gender\n  - demographic.marital_status\n  - demographic.occupation_duration_years\n  - demographic.population_group\n  - demographic.premature_at_birth\n  - demographic.race\n  - demographic.submitter_id\n  - demographic.vital_status\n  - demographic.weeks_gestation_at_birth\n  - demographic.year_of_birth\n  - demographic.year_of_death\n\nTotal demographic columns: 22\n\n\n\n# Check unique values in 'demographic.days_to_death'\nbrca_df[\"demographic.days_to_death\"].unique()\n\narray([nan, '991', '571', '2534', '1793', '538', '320', '2483', '1812',\n       '255', '3926', '723', '1673', '2373', '3941', '2573', '1034',\n       '7455', '584', '2965', '1649', '266', '3945', '785', '1563', '426',\n       '1275', '2911', '224', '3409', '158', '4456', '239', '616', '302',\n       '322', '1009', '227', '1993', '365', '2009', '362', '116', '2798',\n       '3126', '904', '2273', '1272', '860', '2097', '2763', '3462',\n       '3959', '573', '1439', '2469', '921', '336', '3873', '1781',\n       '2361', '295', '1900', '1920', '786', '468', '1127', '959', '1556',\n       '883', '2192', '749', '943', '879', '2417', '1430', '1508', '0',\n       '1388', '2127', '2520', '30', '614', '1884', '1468', '3063',\n       '1152', '976', '678', '1365', '2551', '1694', '811', '1286', '639',\n       '967', '1032', '385', '1072', '912', '825', '1174', '792', '3472',\n       '1642', '6593', '6456', '1688', '1104', '3262', '4267', '612',\n       '548', '2348', '172', '1411', '160', '2854', '577', '348', '563',\n       '446', '1699', '1692', '1004', '1048', '1759', '2866', '1093',\n       '2712', '1324', '754', '3669', '524', '377', '1', '558', '821',\n       '2296', '3461', '2207', '1927', '1142', '2636', '197'],\n      dtype=object)\n\n\n\n# Check for percentage of missing values in 'demographic.days_to_death'\nmissing_percentage = brca_df[\"demographic.days_to_death\"].isnull().mean()\nprint(f\"'Percentage of missing values in 'demographic.days_to_death' {missing_percentage:.2f}\")\n\n'Percentage of missing values in 'demographic.days_to_death' 0.85\n\n\n\n# Check to see if status is 'alive' where days_to_death is missing\nmissing_death_status = brca_df[brca_df[\"demographic.days_to_death\"].isnull()][\"demographic.vital_status\"].value_counts()\nmissing_death_status\n\ndemographic.vital_status\nAlive    4697\nDead        3\nName: count, dtype: int64\n\n\nWe can assume that the demographic.days_to_death column is crucial for survival analysis, as it indicates the time until death for each patient. Despite a significant number of missing values in this column, these are for patients who are still alive, as indicated by the demographic.vital_status column. Therefore, we can retain this column for analysis, treating missing values as censored data.\n\n# Drop rows where days_to_death is missing and vital_status is 'Dead'\nbrca_df = brca_df[~((brca_df[\"demographic.days_to_death\"].isnull()) & (brca_df[\"demographic.vital_status\"] == 'Dead'))]\n\n\n# Check for percentage of missing values in diagnoses.days_to_last_follow_up\nmissing_percentage = brca_df[\"diagnoses.days_to_last_follow_up\"].isnull().mean()\nprint(f\"'Percentage of missing values in 'diagnoses.days_to_last_follow_up' {missing_percentage:.2f}\")\n\n'Percentage of missing values in 'diagnoses.days_to_last_follow_up' 0.11\n\n\n\n# Check the distribution of vital_status when days_to_last_follow_up is missing\nmissing_followup_status = brca_df[brca_df[\"diagnoses.days_to_last_follow_up\"].isnull()][\"demographic.vital_status\"].value_counts()\nmissing_followup_status\n\ndemographic.vital_status\nAlive    337\nDead     260\nName: count, dtype: int64\n\n\n\n# Check the percentage of missing values for the following columns:\n# - demographic.year_of_birth\n# - demographic.year_of_death\n# - demographic.vital_status\n# - demographic.cause_of_death\n# - demographic.education_level\ncols_to_check = [\n    'demographic.year_of_birth',\n    'demographic.age_at_index',\n    'demographic.cause_of_death',\n    'demographic.year_of_death',\n    'demographic.vital_status',\n    'demographic.cause_of_death',\n    'demographic.education_level',\n    'demographic.days_to_death'\n]\nfor col in cols_to_check:\n    missing_percentage = brca_df[col].isnull().mean() * 100\n    print(f\"{col}: {missing_percentage:.2f}% missing values\")\n\ndemographic.year_of_birth: 99.96% missing values\ndemographic.age_at_index: 0.02% missing values\ndemographic.cause_of_death: 100.00% missing values\ndemographic.year_of_death: 100.00% missing values\ndemographic.vital_status: 0.02% missing values\ndemographic.cause_of_death: 100.00% missing values\ndemographic.education_level: 100.00% missing values\ndemographic.days_to_death: 84.76% missing values\n\n\nA lot of missing values in key demographic columns, especially in cause of death become a limiting factor for analysis.\n\n# Distribution of demographic.vital_status\nvital_status_counts = brca_df['demographic.vital_status'].value_counts(dropna=False)\nprint(\"\\ndemographic.vital_status distribution:\")\nprint(vital_status_counts)\n\n\ndemographic.vital_status distribution:\ndemographic.vital_status\nAlive    4697\nDead      845\nNaN         1\nName: count, dtype: int64\n\n\nHowever, the demographic.vital_status column has fewer missing values, which may still allow for some analysis regarding survival status. Despite large number of missing values in demographic.days_to_death, we can assume it is because the patient is alive since the missing values correspond to alive in the vital_status column. In addition, days_to_last_follow_up in the diagnoses table also has fewer missing values, which may be useful for survival time analysis.\n\n\nCheck for missing values\n\n# Missing data visualization\nplt.figure(figsize=(15, 8))\nmsno.matrix(brca_df)\nplt.title(\"Missing Data Matrix - Breast Cancer Dataset\", fontsize=14, fontweight='bold')\nplt.show()\n\n&lt;Figure size 1500x800 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\n# Drop columns with more than 30% missing values except for demographic.days_to_death and diagnoses.days_to_last_follow_up\n\n# Calculate missing percentage for each column\nmissing_percentages = brca_df.isnull().mean()\n\n# Identify columns to drop (more than 30% missing, excluding the exceptions)\nexceptions = ['demographic.days_to_death', 'diagnoses.days_to_last_follow_up']\ncolumns_to_drop = []\n\nfor col in brca_df.columns:\n    if col not in exceptions and missing_percentages[col] &gt; 0.3:\n        columns_to_drop.append(col)\n\nprint(f\"Columns to be dropped due to &gt;30% missing values: {columns_to_drop}\")\n\n# Drop the identified columns\nbrca_df = brca_df.drop(columns=columns_to_drop)\n\n# Display the shape of the cleaned dataset\nbrca_df.shape\n\nColumns to be dropped due to &gt;30% missing values: ['cases.days_to_lost_to_followup', 'cases.lost_to_followup', 'demographic.cause_of_death', 'demographic.cause_of_death_source', 'demographic.country_of_birth', 'demographic.country_of_residence_at_enrollment', 'demographic.education_level', 'demographic.marital_status', 'demographic.occupation_duration_years', 'demographic.population_group', 'demographic.premature_at_birth', 'demographic.weeks_gestation_at_birth', 'demographic.year_of_birth', 'demographic.year_of_death', 'diagnoses.adrenal_hormone', 'diagnoses.ajcc_clinical_m', 'diagnoses.ajcc_clinical_n', 'diagnoses.ajcc_clinical_stage', 'diagnoses.ajcc_clinical_t', 'diagnoses.ajcc_serum_tumor_markers', 'diagnoses.ann_arbor_b_symptoms', 'diagnoses.ann_arbor_b_symptoms_described', 'diagnoses.ann_arbor_clinical_stage', 'diagnoses.ann_arbor_extranodal_involvement', 'diagnoses.ann_arbor_pathologic_stage', 'diagnoses.best_overall_response', 'diagnoses.burkitt_lymphoma_clinical_variant', 'diagnoses.calgb_risk_group', 'diagnoses.cancer_detection_method', 'diagnoses.child_pugh_classification', 'diagnoses.clark_level', 'diagnoses.cog_liver_stage', 'diagnoses.cog_neuroblastoma_risk_group', 'diagnoses.cog_renal_stage', 'diagnoses.cog_rhabdomyosarcoma_risk_group', 'diagnoses.contiguous_organ_invaded', 'diagnoses.days_to_best_overall_response', 'diagnoses.days_to_last_known_disease_status', 'diagnoses.days_to_recurrence', 'diagnoses.double_expressor_lymphoma', 'diagnoses.double_hit_lymphoma', 'diagnoses.eln_risk_classification', 'diagnoses.enneking_msts_grade', 'diagnoses.enneking_msts_metastasis', 'diagnoses.enneking_msts_stage', 'diagnoses.enneking_msts_tumor_site', 'diagnoses.ensat_clinical_m', 'diagnoses.ensat_pathologic_n', 'diagnoses.ensat_pathologic_stage', 'diagnoses.ensat_pathologic_t', 'diagnoses.esophageal_columnar_dysplasia_degree', 'diagnoses.esophageal_columnar_metaplasia_present', 'diagnoses.fab_morphology_code', 'diagnoses.figo_stage', 'diagnoses.figo_staging_edition_year', 'diagnoses.first_symptom_longest_duration', 'diagnoses.first_symptom_prior_to_diagnosis', 'diagnoses.gastric_esophageal_junction_involvement', 'diagnoses.gleason_grade_group', 'diagnoses.gleason_grade_tertiary', 'diagnoses.gleason_patterns_percent', 'diagnoses.gleason_score', 'diagnoses.goblet_cells_columnar_mucosa_present', 'diagnoses.igcccg_stage', 'diagnoses.inpc_grade', 'diagnoses.inpc_histologic_group', 'diagnoses.inrg_stage', 'diagnoses.inss_stage', 'diagnoses.international_prognostic_index', 'diagnoses.irs_group', 'diagnoses.irs_stage', 'diagnoses.ishak_fibrosis_score', 'diagnoses.iss_stage', 'diagnoses.last_known_disease_status', 'diagnoses.margin_distance', 'diagnoses.margins_involved_site', 'diagnoses.masaoka_stage', 'diagnoses.max_tumor_bulk_site', 'diagnoses.medulloblastoma_molecular_classification', 'diagnoses.melanoma_known_primary', 'diagnoses.metastasis_at_diagnosis', 'diagnoses.metastasis_at_diagnosis_site', 'diagnoses.micropapillary_features', 'diagnoses.mitosis_karyorrhexis_index', 'diagnoses.mitotic_count', 'diagnoses.ovarian_specimen_status', 'diagnoses.ovarian_surface_involvement', 'diagnoses.papillary_renal_cell_type', 'diagnoses.pediatric_kidney_staging', 'diagnoses.peritoneal_fluid_cytological_status', 'diagnoses.pregnant_at_diagnosis', 'diagnoses.primary_disease', 'diagnoses.primary_gleason_grade', 'diagnoses.progression_or_recurrence', 'diagnoses.residual_disease', 'diagnoses.satellite_nodule_present', 'diagnoses.secondary_gleason_grade', 'diagnoses.sites_of_involvement_count', 'diagnoses.supratentorial_localization', 'diagnoses.tumor_burden', 'diagnoses.tumor_confined_to_organ_of_origin', 'diagnoses.tumor_depth', 'diagnoses.tumor_focality', 'diagnoses.tumor_grade', 'diagnoses.tumor_grade_category', 'diagnoses.tumor_of_origin', 'diagnoses.tumor_regression_grade', 'diagnoses.uicc_clinical_m', 'diagnoses.uicc_clinical_n', 'diagnoses.uicc_clinical_stage', 'diagnoses.uicc_clinical_t', 'diagnoses.uicc_pathologic_m', 'diagnoses.uicc_pathologic_n', 'diagnoses.uicc_pathologic_stage', 'diagnoses.uicc_pathologic_t', 'diagnoses.uicc_staging_system_edition', 'diagnoses.ulceration_indicator', 'diagnoses.weiss_assessment_findings', 'diagnoses.weiss_assessment_score', 'diagnoses.who_cns_grade', 'diagnoses.who_nte_grade', 'diagnoses.wilms_tumor_histologic_subtype', 'treatments.chemo_concurrent_to_radiation', 'treatments.clinical_trial_indicator', 'treatments.course_number', 'treatments.days_to_treatment_end', 'treatments.days_to_treatment_start', 'treatments.drug_category', 'treatments.embolic_agent', 'treatments.initial_disease_status', 'treatments.lesions_treated_number', 'treatments.margin_distance', 'treatments.margin_status', 'treatments.margins_involved_site', 'treatments.number_of_cycles', 'treatments.number_of_fractions', 'treatments.prescribed_dose', 'treatments.prescribed_dose_units', 'treatments.pretreatment', 'treatments.protocol_identifier', 'treatments.radiosensitizing_agent', 'treatments.reason_treatment_ended', 'treatments.reason_treatment_not_given', 'treatments.regimen_or_line_of_therapy', 'treatments.residual_disease', 'treatments.route_of_administration', 'treatments.therapeutic_agents', 'treatments.therapeutic_level_achieved', 'treatments.therapeutic_levels_achieved', 'treatments.therapeutic_target_level', 'treatments.timepoint_category', 'treatments.treatment_anatomic_site', 'treatments.treatment_anatomic_sites', 'treatments.treatment_arm', 'treatments.treatment_dose', 'treatments.treatment_dose_max', 'treatments.treatment_dose_units', 'treatments.treatment_duration', 'treatments.treatment_effect', 'treatments.treatment_effect_indicator', 'treatments.treatment_frequency', 'treatments.treatment_intent_type', 'treatments.treatment_outcome', 'treatments.treatment_outcome_duration']\n\n\n(5543, 46)\n\n\n\n# Check distribution na values after dropping columns\nplt.figure(figsize=(15, 8))\nmsno.matrix(brca_df)\nplt.title(\"Missing Data Matrix After Dropping Columns - BRCA Clinical Dataset\", fontsize=14, fontweight='bold')\nplt.show()\n\n&lt;Figure size 1500x800 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\n\nCheck for duplicate IDs\n\n# Count unique IDs (cases.submitter_id)\n\nunique_ids = brca_df['cases.submitter_id'].nunique()\nprint(f\"Number of unique IDs: {unique_ids}\")\n\nNumber of unique IDs: 1097\n\n\nThe TGCA BRCA dataset contains 1,082 unique patient IDs (cases.submitter_id) but 3554 rows in total. This is because the TCGA Schema is designed to have multiple samples per patient, capturing different aspects of the tumor biology. Each patient may have multiple entries corresponding to different sample types, such as primary tumor, metastatic tumor, or normal tissue adjacent to the tumor. This allows for a more comprehensive analysis of the cancer’s characteristics and progression within the same individual.\nThe tcga schema is hierarchical as follows:\nCase (BRCA) -&gt; Diagnosis -&gt; Follow-up -&gt; Treatment -&gt; Biospecimens\nMost BRCA patients have: - 1 diagnosis - 1 - 5 follow-up entries - 1 - 3 treatments - 2 - 4 tissue samples (tumor and normal)\n\n# Drop completely duplicate rows\nbrca_df = brca_df.drop_duplicates()\n\n\n\nFilter columns based on task\nColumns that are not relevant to the predictive modeling task will be dropped. These include identifiers, dates, and other metadata that do not contribute to the prediction of breast cancer outcomes such as the following:\n\ncases.consent_type\ncases.days_to_consent\ndemographic.days_to_birth\ndemographic.age_at_index (will preserve diagnosis.age_at_diagnosis instead for age at diagnosis)\ndiagnoses.ajcc_staging_system_edition\ndiagnoses.diagnosis_id (captured in disease_type)\ndiagnoses.icd_10_code (captured in disease_type)\ndiagnoses.year_of_diagnosis (interested in age at diagnosis instead)\ntreatments.treatment_id\n\n\n# Drop irrelevant columns\ncolumns_to_drop = [\n    'cases.consent_type',\n    'cases.days_to_consent',\n    'demographic.days_to_birth',\n    'demographic.age_at_index',\n    'demographic.demographic_id',\n    'diagnoses.ajcc_staging_system_edition',\n    'diagnoses.diagnosis_id',\n    'diagnoses.icd_10_code',\n    'diagnoses.year_of_diagnosis',\n    'treatments.treatment_id'\n]\n\n# Drop the existing columns\nbrca_df = brca_df.drop(columns=columns_to_drop)\n\nprint(f\"Dataset shape after dropping columns: {brca_df.shape}\")\n\nDataset shape after dropping columns: (5543, 36)\n\n\n\n# Using msno to visualize missing data in remaining columns\nplt.figure(figsize=(15, 8))\nmsno.matrix(brca_df)\nplt.title(\"Missing Data Matrix After Dropping irrelevant columns - BRCA Clinical Dataset\", fontsize=14, fontweight='bold')\nplt.show()\n\n&lt;Figure size 1500x800 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\n# Check missing value percentages again\n\nfor col in brca_df.columns:\n    missing_percentage = brca_df[col].isnull().mean() * 100\n    print(f\"{col}: {missing_percentage:.2f}% missing values\")\n\nproject.project_id: 0.00% missing values\ncases.case_id: 0.00% missing values\ncases.disease_type: 0.00% missing values\ncases.index_date: 0.05% missing values\ncases.primary_site: 0.00% missing values\ncases.submitter_id: 0.00% missing values\ndemographic.age_is_obfuscated: 0.05% missing values\ndemographic.days_to_death: 84.76% missing values\ndemographic.ethnicity: 0.02% missing values\ndemographic.gender: 0.02% missing values\ndemographic.race: 0.02% missing values\ndemographic.submitter_id: 0.02% missing values\ndemographic.vital_status: 0.02% missing values\ndiagnoses.age_at_diagnosis: 3.50% missing values\ndiagnoses.ajcc_pathologic_m: 9.44% missing values\ndiagnoses.ajcc_pathologic_n: 9.44% missing values\ndiagnoses.ajcc_pathologic_stage: 10.25% missing values\ndiagnoses.ajcc_pathologic_t: 9.40% missing values\ndiagnoses.classification_of_tumor: 0.02% missing values\ndiagnoses.days_to_diagnosis: 2.62% missing values\ndiagnoses.days_to_last_follow_up: 10.79% missing values\ndiagnoses.diagnosis_is_primary_disease: 0.05% missing values\ndiagnoses.laterality: 8.44% missing values\ndiagnoses.method_of_diagnosis: 17.54% missing values\ndiagnoses.morphology: 0.02% missing values\ndiagnoses.primary_diagnosis: 0.02% missing values\ndiagnoses.prior_malignancy: 10.79% missing values\ndiagnoses.prior_treatment: 3.63% missing values\ndiagnoses.site_of_resection_or_biopsy: 0.02% missing values\ndiagnoses.sites_of_involvement: 10.82% missing values\ndiagnoses.submitter_id: 0.02% missing values\ndiagnoses.synchronous_malignancy: 10.79% missing values\ndiagnoses.tissue_or_organ_of_origin: 0.02% missing values\ntreatments.submitter_id: 0.67% missing values\ntreatments.treatment_or_therapy: 0.67% missing values\ntreatments.treatment_type: 0.67% missing values\n\n\n\n# Check distribution of rows that have a lot of missing values\nbrca_df[\"na_count\"] = brca_df.isna().sum(axis=1)\nna_count_distribution = brca_df['na_count'].value_counts().sort_index()\nprint(\"\\nDistribution of rows by number of missing values:\")\nprint(na_count_distribution)\n\n\nDistribution of rows by number of missing values:\nna_count\n0      543\n1     3981\n2      415\n3        4\n7       20\n8       15\n9       37\n10     218\n11     172\n12      27\n13      51\n14      56\n15       1\n16       1\n17       1\n31       1\nName: count, dtype: int64\n\n\n\n# Delete rows that have 9 or more missing values (representing over 30% of that entity info missing)\nbrca_df = brca_df[brca_df['na_count'] &lt; 9].drop(columns=['na_count'])\n\n\n# Delete rows that have missing age_at_diagnosis info since this is a critical variable for our analysis\nbrca_df = brca_df[brca_df['diagnoses.age_at_diagnosis'].notna()]\n\n\n# Check missing value percentages again\n\nfor col in brca_df.columns:\n    missing_percentage = brca_df[col].isnull().mean() * 100\n    print(f\"{col}: {missing_percentage:.2f}% missing values\")\n\nproject.project_id: 0.00% missing values\ncases.case_id: 0.00% missing values\ncases.disease_type: 0.00% missing values\ncases.index_date: 0.04% missing values\ncases.primary_site: 0.00% missing values\ncases.submitter_id: 0.00% missing values\ndemographic.age_is_obfuscated: 0.04% missing values\ndemographic.days_to_death: 88.11% missing values\ndemographic.ethnicity: 0.00% missing values\ndemographic.gender: 0.00% missing values\ndemographic.race: 0.00% missing values\ndemographic.submitter_id: 0.00% missing values\ndemographic.vital_status: 0.00% missing values\ndiagnoses.age_at_diagnosis: 0.00% missing values\ndiagnoses.ajcc_pathologic_m: 0.00% missing values\ndiagnoses.ajcc_pathologic_n: 0.00% missing values\ndiagnoses.ajcc_pathologic_stage: 0.89% missing values\ndiagnoses.ajcc_pathologic_t: 0.06% missing values\ndiagnoses.classification_of_tumor: 0.00% missing values\ndiagnoses.days_to_diagnosis: 0.00% missing values\ndiagnoses.days_to_last_follow_up: 0.49% missing values\ndiagnoses.diagnosis_is_primary_disease: 0.04% missing values\ndiagnoses.laterality: 0.10% missing values\ndiagnoses.method_of_diagnosis: 8.09% missing values\ndiagnoses.morphology: 0.00% missing values\ndiagnoses.primary_diagnosis: 0.00% missing values\ndiagnoses.prior_malignancy: 0.49% missing values\ndiagnoses.prior_treatment: 0.49% missing values\ndiagnoses.site_of_resection_or_biopsy: 0.00% missing values\ndiagnoses.sites_of_involvement: 0.53% missing values\ndiagnoses.submitter_id: 0.00% missing values\ndiagnoses.synchronous_malignancy: 0.49% missing values\ndiagnoses.tissue_or_organ_of_origin: 0.00% missing values\ntreatments.submitter_id: 0.00% missing values\ntreatments.treatment_or_therapy: 0.00% missing values\ntreatments.treatment_type: 0.00% missing values\n\n\n\n# Using msno to visualize missing data in remaining columns\nplt.figure(figsize=(15, 8))\nmsno.matrix(brca_df)\nplt.title(\"Missing Data Matrix After Dropping irrelevant columns - BRCA Clinical Dataset\", fontsize=14, fontweight='bold')\nplt.show()\n\n&lt;Figure size 1500x800 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\n# Check the distribution of the method_of_diagnosis since it has a significantly higher missing value percentage\nmethod_of_diagnosis_counts = brca_df['diagnoses.method_of_diagnosis'].value_counts(dropna=False)\nprint(\"\\ndiagnoses.method_of_diagnosis distribution:\")\nprint(method_of_diagnosis_counts)\n\n\ndiagnoses.method_of_diagnosis distribution:\ndiagnoses.method_of_diagnosis\nCore Biopsy                 2932\nSurgical Resection           797\nNaN                          398\nFine Needle Aspiration       380\nExcisional Biopsy            143\nCytology                     124\nBiopsy                        67\nIncisional Biopsy             66\nUltrasound Guided Biopsy       7\nUnknown                        6\nName: count, dtype: int64\n\n\nDue to the heavy imbalance leaning towards Core Biopsy for the diagnoses.method_of_diagnosis column, we can replace missing values with ‘Core Biopsy’ to retain more rows for analysis.\n\n# Distribution of cases.index_date\nindex_date_counts = brca_df['cases.index_date'].value_counts(dropna=False)\nprint(\"\\ncases.index_date distribution:\")\nprint(index_date_counts)\n\n\ncases.index_date distribution:\ncases.index_date\nDiagnosis    4918\nNaN             2\nName: count, dtype: int64\n\n\nDue to the heavy imbalance leaning towards Diagnosis for the cases.index_date column, we can replace missing values with ‘Diagnosis’ to retain more rows for analysis.\n\n# Set pandas options to display all columns\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', None)\n\n\n# Check rows that have missing age_is_obfuscated \nbrca_df[brca_df['demographic.age_is_obfuscated'].isna()].head()\n\n\n\n\n\n\n\n\nproject.project_id\ncases.case_id\ncases.disease_type\ncases.index_date\ncases.primary_site\ncases.submitter_id\ndemographic.age_is_obfuscated\ndemographic.days_to_death\ndemographic.ethnicity\ndemographic.gender\ndemographic.race\ndemographic.submitter_id\ndemographic.vital_status\ndiagnoses.age_at_diagnosis\ndiagnoses.ajcc_pathologic_m\ndiagnoses.ajcc_pathologic_n\ndiagnoses.ajcc_pathologic_stage\ndiagnoses.ajcc_pathologic_t\ndiagnoses.classification_of_tumor\ndiagnoses.days_to_diagnosis\ndiagnoses.days_to_last_follow_up\ndiagnoses.diagnosis_is_primary_disease\ndiagnoses.laterality\ndiagnoses.method_of_diagnosis\ndiagnoses.morphology\ndiagnoses.primary_diagnosis\ndiagnoses.prior_malignancy\ndiagnoses.prior_treatment\ndiagnoses.site_of_resection_or_biopsy\ndiagnoses.sites_of_involvement\ndiagnoses.submitter_id\ndiagnoses.synchronous_malignancy\ndiagnoses.tissue_or_organ_of_origin\ntreatments.submitter_id\ntreatments.treatment_or_therapy\ntreatments.treatment_type\n\n\n\n\n4368\nTCGA-BRCA\ncb9f5e50-f49d-4899-8895-9367afcc1015\nDuctal and Lobular Neoplasms\nNaN\nBreast\nTCGA-A7-A0DC\nNaN\nNaN\nnot hispanic or latino\nfemale\nwhite\nTCGA-A7-A0DC_demographic\nAlive\n23294\nM0\nN0 (i-)\nStage IA\nT1c\nnot reported\n0\n906.0\nNaN\nNaN\nNaN\n8500/3\nInfiltrating duct carcinoma, NOS\nno\nNo\nBreast, NOS\nNaN\nTCGA-A7-A0DC_diagnosis\nNo\nBreast, NOS\nTCGA-A7-A0DC_treatment_1\nyes\nPharmaceutical Therapy, NOS\n\n\n4369\nTCGA-BRCA\ncb9f5e50-f49d-4899-8895-9367afcc1015\nDuctal and Lobular Neoplasms\nNaN\nBreast\nTCGA-A7-A0DC\nNaN\nNaN\nnot hispanic or latino\nfemale\nwhite\nTCGA-A7-A0DC_demographic\nAlive\n23294\nM0\nN0 (i-)\nStage IA\nT1c\nnot reported\n0\n906.0\nNaN\nNaN\nNaN\n8500/3\nInfiltrating duct carcinoma, NOS\nno\nNo\nBreast, NOS\nNaN\nTCGA-A7-A0DC_diagnosis\nNo\nBreast, NOS\nTCGA-A7-A0DC_treatment\nyes\nRadiation Therapy, NOS\n\n\n\n\n\n\n\nIt seems that when age is obfuscated is NaN, age_at_diagnosis exists, therefore we can replace these with False\n\n# Check distribution of diagnoses.ajcc_pathologic_n \najcc_pathologic_stage_counts = brca_df['diagnoses.ajcc_pathologic_n'].value_counts(dropna=False)\nprint(\"\\ndiagnoses.ajcc_pathologic_n distribution:\")\nprint(ajcc_pathologic_stage_counts)\n\n\ndiagnoses.ajcc_pathologic_n distribution:\ndiagnoses.ajcc_pathologic_n\nN0           1289\nN1a           839\nN0 (i-)       682\nN1            579\nN2a           352\nN2            267\nN3a           247\nN1mi          178\nN0 (i+)       138\nN3            130\nN1b           104\nNX             77\nN3b            16\nN3c            13\nN1c             6\nN0 (mol+)       3\nName: count, dtype: int64\n\n\n\n# Check distribution of diagnoses.ajcc_pathologic_m \najcc_pathologic_stage_counts = brca_df['diagnoses.ajcc_pathologic_m'].value_counts(dropna=False)\nprint(\"\\ndiagnoses.ajcc_pathologic_m distribution:\")\nprint(ajcc_pathologic_stage_counts)\n\n\ndiagnoses.ajcc_pathologic_m distribution:\ndiagnoses.ajcc_pathologic_m\nM0          4095\nMX           703\nM1            87\ncM0 (i+)      35\nName: count, dtype: int64\n\n\n\n# Check distribution of diagnoses.ajcc_pathologic_t \najcc_pathologic_stage_counts = brca_df['diagnoses.ajcc_pathologic_t'].value_counts(dropna=False)\nprint(\"\\ndiagnoses.ajcc_pathologic_t distribution:\")\nprint(ajcc_pathologic_stage_counts)\n\n\ndiagnoses.ajcc_pathologic_t distribution:\ndiagnoses.ajcc_pathologic_t\nT2            2908\nT1c            941\nT3             649\nT1             178\nT4b             94\nT1b             76\nT4              31\nT4d             12\nTX               9\nTis (DCIS)       6\nT3a              4\nT2a              4\nTis              3\nNaN              3\nT1a              1\nT2b              1\nName: count, dtype: int64\n\n\n\n# Check distribution of diagnoses.ajcc_pathologic_stage \najcc_pathologic_stage_counts = brca_df['diagnoses.ajcc_pathologic_stage'].value_counts(dropna=False)\nprint(\"\\ndiagnoses.ajcc_pathologic_stage distribution:\")\nprint(ajcc_pathologic_stage_counts)\n\n\ndiagnoses.ajcc_pathologic_stage distribution:\ndiagnoses.ajcc_pathologic_stage\nStage IIA     1532\nStage IIB     1227\nStage IIIA     787\nStage IIIC     364\nStage I        341\nStage IA       338\nStage IIIB      89\nStage IV        77\nNaN             44\nStage X         42\nStage IB        33\nStage II        25\nStage III       12\nStage 0          6\nStage 0is        3\nName: count, dtype: int64\n\n\nThe missing values in the diagnoses.ajcc_pathologic_t, diagnoses.ajcc_pathologic_n, and diagnoses.ajcc_pathologic_m columns will be replaced by the mode of each column respectively and the state (diagnoses.ajcc_pathologic_stage) will be derived from these three columns using the AJCC staging guidelines.\n\n# Check rows with missing diagnoses.ajcc_pathologic_stage\nbrca_df[brca_df['diagnoses.ajcc_pathologic_stage'].isna()].head()\n\n\n\n\n\n\n\n\nproject.project_id\ncases.case_id\ncases.disease_type\ncases.index_date\ncases.primary_site\ncases.submitter_id\ndemographic.age_is_obfuscated\ndemographic.days_to_death\ndemographic.ethnicity\ndemographic.gender\ndemographic.race\ndemographic.submitter_id\ndemographic.vital_status\ndiagnoses.age_at_diagnosis\ndiagnoses.ajcc_pathologic_m\ndiagnoses.ajcc_pathologic_n\ndiagnoses.ajcc_pathologic_stage\ndiagnoses.ajcc_pathologic_t\ndiagnoses.classification_of_tumor\ndiagnoses.days_to_diagnosis\ndiagnoses.days_to_last_follow_up\ndiagnoses.diagnosis_is_primary_disease\ndiagnoses.laterality\ndiagnoses.method_of_diagnosis\ndiagnoses.morphology\ndiagnoses.primary_diagnosis\ndiagnoses.prior_malignancy\ndiagnoses.prior_treatment\ndiagnoses.site_of_resection_or_biopsy\ndiagnoses.sites_of_involvement\ndiagnoses.submitter_id\ndiagnoses.synchronous_malignancy\ndiagnoses.tissue_or_organ_of_origin\ntreatments.submitter_id\ntreatments.treatment_or_therapy\ntreatments.treatment_type\n\n\n\n\n276\nTCGA-BRCA\n0adf59c6-581a-475d-a2f4-40aa40060b5b\nDuctal and Lobular Neoplasms\nDiagnosis\nBreast\nTCGA-A8-A09T\nfalse\nNaN\nnot reported\nfemale\nnot reported\nTCGA-A8-A09T_demographic\nAlive\n25110\nMX\nN0\nNaN\nT1c\nprimary\n0\n579.0\ntrue\nLeft\nNaN\n8520/3\nLobular carcinoma, NOS\nno\nNo\nBreast, NOS\nBreast, NOS\nTCGA-A8-A09T_diagnosis\nNo\nBreast, NOS\nTCGA-A8-A09T_treatment2\nyes\nHormone Therapy\n\n\n277\nTCGA-BRCA\n0adf59c6-581a-475d-a2f4-40aa40060b5b\nDuctal and Lobular Neoplasms\nDiagnosis\nBreast\nTCGA-A8-A09T\nfalse\nNaN\nnot reported\nfemale\nnot reported\nTCGA-A8-A09T_demographic\nAlive\n25110\nMX\nN0\nNaN\nT1c\nprimary\n0\n579.0\ntrue\nLeft\nNaN\n8520/3\nLobular carcinoma, NOS\nno\nNo\nBreast, NOS\nBreast, NOS\nTCGA-A8-A09T_diagnosis\nNo\nBreast, NOS\nTCGA-A8-A09T_treatment3\nyes\nSurgery, NOS\n\n\n278\nTCGA-BRCA\n0adf59c6-581a-475d-a2f4-40aa40060b5b\nDuctal and Lobular Neoplasms\nDiagnosis\nBreast\nTCGA-A8-A09T\nfalse\nNaN\nnot reported\nfemale\nnot reported\nTCGA-A8-A09T_demographic\nAlive\n25110\nMX\nN0\nNaN\nT1c\nprimary\n0\n579.0\ntrue\nLeft\nNaN\n8520/3\nLobular carcinoma, NOS\nno\nNo\nBreast, NOS\nBreast, NOS\nTCGA-A8-A09T_diagnosis\nNo\nBreast, NOS\nTCGA-A8-A09T_treatment\nyes\nRadiation, External Beam\n\n\n508\nTCGA-BRCA\n178b2c48-c07d-422e-ae17-8bcfd996ad51\nDuctal and Lobular Neoplasms\nDiagnosis\nBreast\nTCGA-B6-A0X1\nfalse\n7455\nnot hispanic or latino\nfemale\nwhite\nTCGA-B6-A0X1_demographic\nDead\n17624\nM1\nN1\nNaN\nT2\nprimary\n0\n7455.0\ntrue\nLeft\nFine Needle Aspiration\n8500/3\nInfiltrating duct carcinoma, NOS\nno\nNo\nBreast, NOS\nBreast, NOS\nTCGA-B6-A0X1_diagnosis\nNo\nBreast, NOS\nTCGA-B6-A0X1_treatment3\nyes\nSurgery, NOS\n\n\n509\nTCGA-BRCA\n178b2c48-c07d-422e-ae17-8bcfd996ad51\nDuctal and Lobular Neoplasms\nDiagnosis\nBreast\nTCGA-B6-A0X1\nfalse\n7455\nnot hispanic or latino\nfemale\nwhite\nTCGA-B6-A0X1_demographic\nDead\n17624\nM1\nN1\nNaN\nT2\nprimary\n0\n7455.0\ntrue\nLeft\nFine Needle Aspiration\n8500/3\nInfiltrating duct carcinoma, NOS\nno\nNo\nBreast, NOS\nBreast, NOS\nTCGA-B6-A0X1_diagnosis\nNo\nBreast, NOS\nTCGA-B6-A0X1_treatment\nyes\nPharmaceutical Therapy, NOS\n\n\n\n\n\n\n\n\n# Percentage of missing values in each column\nmissing_percentages = brca_df.isnull().mean() * 100\nprint(\"\\nPercentage of missing values in each column:\")\nprint(missing_percentages)\n\n\nPercentage of missing values in each column:\nproject.project_id                         0.000000\ncases.case_id                              0.000000\ncases.disease_type                         0.000000\ncases.index_date                           0.040650\ncases.primary_site                         0.000000\ncases.submitter_id                         0.000000\ndemographic.age_is_obfuscated              0.040650\ndemographic.days_to_death                 88.109756\ndemographic.ethnicity                      0.000000\ndemographic.gender                         0.000000\ndemographic.race                           0.000000\ndemographic.submitter_id                   0.000000\ndemographic.vital_status                   0.000000\ndiagnoses.age_at_diagnosis                 0.000000\ndiagnoses.ajcc_pathologic_m                0.000000\ndiagnoses.ajcc_pathologic_n                0.000000\ndiagnoses.ajcc_pathologic_stage            0.894309\ndiagnoses.ajcc_pathologic_t                0.060976\ndiagnoses.classification_of_tumor          0.000000\ndiagnoses.days_to_diagnosis                0.000000\ndiagnoses.days_to_last_follow_up           0.487805\ndiagnoses.diagnosis_is_primary_disease     0.040650\ndiagnoses.laterality                       0.101626\ndiagnoses.method_of_diagnosis              8.089431\ndiagnoses.morphology                       0.000000\ndiagnoses.primary_diagnosis                0.000000\ndiagnoses.prior_malignancy                 0.487805\ndiagnoses.prior_treatment                  0.487805\ndiagnoses.site_of_resection_or_biopsy      0.000000\ndiagnoses.sites_of_involvement             0.528455\ndiagnoses.submitter_id                     0.000000\ndiagnoses.synchronous_malignancy           0.487805\ndiagnoses.tissue_or_organ_of_origin        0.000000\ntreatments.submitter_id                    0.000000\ntreatments.treatment_or_therapy            0.000000\ntreatments.treatment_type                  0.000000\ndtype: float64\n\n\n\n# Check distribution of diagnoses.treatment_or_therapy\ntreatment_or_therapy_counts = brca_df['treatments.treatment_or_therapy'].value_counts(dropna=False)\nprint(\"\\ntreatments.treatment_or_therapy distribution:\")\nprint(treatment_or_therapy_counts)\n\n\ntreatments.treatment_or_therapy distribution:\ntreatments.treatment_or_therapy\nyes        4289\nno          559\nunknown      72\nName: count, dtype: int64\n\n\n\n\nClean NA values\nReplace the missing values in the following columns based on the assigned strategy: - cases.index_date: ‘Diagnosis’ (most frequent) - diagnoses.method_of_diagnosis: ‘Core Biopsy’ (most frequent) - demographic.age_is_obfuscated: ‘False’ (age is still present despite na) - diagnoses.ajcc_pathologic_n: ‘N0’ (most frequent) - diagnoses.ajcc_pathologic_m: ‘M0’ (most frequent) - diagnoses.ajcc_pathologic_t: ‘T2’ (most frequent) - diagnoses.ajcc_pathologic_stage: infered from other ajcc_pathologic columns according to the following mapping: - T1, N0, M0 -&gt; Stage I - T2, N0, M0 -&gt; Stage II - T3, N0, M0 -&gt; Stage III - T4, N0, M0 -&gt; Stage IV - T1, N1, M0 -&gt; Stage II - T2, N1, M0 -&gt; Stage III - T3, N1, M0 -&gt; Stage III - T4, N1, M0 -&gt; Stage IV - diagnoses.diagnosis_is_primary_disease: ‘True’ (most frequent) - diagnoses.laterality : ‘Left’ (most frequent) - diagnoses.prior_malignancy: ‘False’ (most frequent) - diagnoses.prior_treatment: ‘False’ (most frequent) - diagnoses.sites_of_involvement: ‘Breast’ (most frequent) - diagnoses.synchronous_malignancy: ‘False’ (most frequent) - diagnoses.treatment_or_therapy: True (most frequent)\n\n# Replace missing values based on the strategy above:\n\n# Replace with most frequent values\nbrca_df['cases.index_date'] = brca_df['cases.index_date'].fillna('diagnosis')\nbrca_df['diagnoses.method_of_diagnosis'] = brca_df['diagnoses.method_of_diagnosis'].fillna('core biopsy')\nbrca_df['demographic.age_is_obfuscated'] = brca_df['demographic.age_is_obfuscated'].fillna('false')\nbrca_df['diagnoses.ajcc_pathologic_n'] = brca_df['diagnoses.ajcc_pathologic_n'].fillna('n0')\nbrca_df['diagnoses.ajcc_pathologic_m'] = brca_df['diagnoses.ajcc_pathologic_m'].fillna('m0')\nbrca_df['diagnoses.ajcc_pathologic_t'] = brca_df['diagnoses.ajcc_pathologic_t'].fillna('t2')\nbrca_df['diagnoses.diagnosis_is_primary_disease'] = brca_df['diagnoses.diagnosis_is_primary_disease'].fillna('true')\nbrca_df['diagnoses.laterality'] = brca_df['diagnoses.laterality'].fillna('left')\nbrca_df['diagnoses.prior_malignancy'] = brca_df['diagnoses.prior_malignancy'].fillna('no')\nbrca_df['diagnoses.prior_treatment'] = brca_df['diagnoses.prior_treatment'].fillna('no')\nbrca_df['diagnoses.sites_of_involvement'] = brca_df['diagnoses.sites_of_involvement'].fillna('breast')\nbrca_df['diagnoses.synchronous_malignancy'] = brca_df['diagnoses.synchronous_malignancy'].fillna('no')\nbrca_df['treatments.treatment_or_therapy'] = brca_df['treatments.treatment_or_therapy'].fillna('True')\n\n# Define AJCC staging mapping\ndef get_ajcc_stage(t, n, m):\n    \"\"\"Map T, N, M values to AJCC stage\"\"\"\n    # Extract numeric/classification parts (remove 'T', 'N', 'M' prefixes)\n    t_val = t.lower().replace('t', '') if pd.notna(t) else '2'\n    n_val = n.lower().replace('n', '') if pd.notna(n) else '0'\n    m_val = m.lower().replace('m', '') if pd.notna(m) else '0'\n    \n    # Stage mapping logic\n    if m_val != '0':\n        return 'stage iv'  # Any distant metastasis is Stage IV\n    elif t_val == '1' and n_val == '0':\n        return 'stage i'\n    elif (t_val == '2' and n_val == '0') or (t_val == '1' and n_val == '1'):\n        return 'stage ii'\n    elif (t_val == '3' and n_val == '0') or (t_val == '2' and n_val == '1') or (t_val == '3' and n_val == '1'):\n        return 'stage iii'\n    elif t_val == '4':\n        return 'stage iv'\n    else:\n        return 'stage ii'  # Default fallback\n\n# Apply staging logic to fill missing values\nfor idx, row in brca_df.iterrows():\n    if pd.isna(row['diagnoses.ajcc_pathologic_stage']):\n        stage = get_ajcc_stage(\n            row['diagnoses.ajcc_pathologic_t'],\n            row['diagnoses.ajcc_pathologic_n'], \n            row['diagnoses.ajcc_pathologic_m']\n        )\n        brca_df.at[idx, 'diagnoses.ajcc_pathologic_stage'] = stage\n\n\n# Check missing values after replacement\nprint(\"Missing values after replacement:\")\nfor col in brca_df.columns:\n    missing_count = brca_df[col].isnull().sum()\n    if missing_count &gt; 0:\n        print(f\"{col}: {missing_count} missing values\")\n\nprint(f\"\\nTotal missing values across all columns: {brca_df.isnull().sum().sum()}\")\n\nMissing values after replacement:\ndemographic.days_to_death: 4335 missing values\ndiagnoses.days_to_last_follow_up: 24 missing values\n\nTotal missing values across all columns: 4359\n\n\n\n\nCheck for consistent data types\n\n# Check column data types\n\nbrca_df.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 4920 entries, 0 to 5545\nData columns (total 36 columns):\n #   Column                                  Non-Null Count  Dtype \n---  ------                                  --------------  ----- \n 0   project.project_id                      4920 non-null   object\n 1   cases.case_id                           4920 non-null   object\n 2   cases.disease_type                      4920 non-null   object\n 3   cases.index_date                        4920 non-null   object\n 4   cases.primary_site                      4920 non-null   object\n 5   cases.submitter_id                      4920 non-null   object\n 6   demographic.age_is_obfuscated           4920 non-null   object\n 7   demographic.days_to_death               585 non-null    object\n 8   demographic.ethnicity                   4920 non-null   object\n 9   demographic.gender                      4920 non-null   object\n 10  demographic.race                        4920 non-null   object\n 11  demographic.submitter_id                4920 non-null   object\n 12  demographic.vital_status                4920 non-null   object\n 13  diagnoses.age_at_diagnosis              4920 non-null   object\n 14  diagnoses.ajcc_pathologic_m             4920 non-null   object\n 15  diagnoses.ajcc_pathologic_n             4920 non-null   object\n 16  diagnoses.ajcc_pathologic_stage         4920 non-null   object\n 17  diagnoses.ajcc_pathologic_t             4920 non-null   object\n 18  diagnoses.classification_of_tumor       4920 non-null   object\n 19  diagnoses.days_to_diagnosis             4920 non-null   object\n 20  diagnoses.days_to_last_follow_up        4896 non-null   object\n 21  diagnoses.diagnosis_is_primary_disease  4920 non-null   object\n 22  diagnoses.laterality                    4920 non-null   object\n 23  diagnoses.method_of_diagnosis           4920 non-null   object\n 24  diagnoses.morphology                    4920 non-null   object\n 25  diagnoses.primary_diagnosis             4920 non-null   object\n 26  diagnoses.prior_malignancy              4920 non-null   object\n 27  diagnoses.prior_treatment               4920 non-null   object\n 28  diagnoses.site_of_resection_or_biopsy   4920 non-null   object\n 29  diagnoses.sites_of_involvement          4920 non-null   object\n 30  diagnoses.submitter_id                  4920 non-null   object\n 31  diagnoses.synchronous_malignancy        4920 non-null   object\n 32  diagnoses.tissue_or_organ_of_origin     4920 non-null   object\n 33  treatments.submitter_id                 4920 non-null   object\n 34  treatments.treatment_or_therapy         4920 non-null   object\n 35  treatments.treatment_type               4920 non-null   object\ndtypes: object(36)\nmemory usage: 1.5+ MB\n\n\n\n# Check the statistical summary of diagnoses.age_at_diagnosis\n\n# Convert to numeric \nbrca_df['diagnoses.age_at_diagnosis'] = pd.to_numeric(brca_df['diagnoses.age_at_diagnosis'], errors='coerce')\n\n# Statistical summary\nprint(\"Statistical Summary of Age at Diagnosis:\")\nprint(brca_df['diagnoses.age_at_diagnosis'].describe())\n\nprint(f\"\\nMean: {brca_df['diagnoses.age_at_diagnosis'].mean():.2f}\")\nprint(f\"Median: {brca_df['diagnoses.age_at_diagnosis'].median():.2f}\")\nprint(f\"Standard Deviation: {brca_df['diagnoses.age_at_diagnosis'].std():.2f}\")\nprint(f\"Missing values: {brca_df['diagnoses.age_at_diagnosis'].isna().sum()}\")\n\nStatistical Summary of Age at Diagnosis:\ncount     4920.000000\nmean     20899.613618\nstd       4578.709865\nmin       9706.000000\n25%      17561.500000\n50%      20708.500000\n75%      23699.750000\nmax      32872.000000\nName: diagnoses.age_at_diagnosis, dtype: float64\n\nMean: 20899.61\nMedian: 20708.50\nStandard Deviation: 4578.71\nMissing values: 0\n\n\nThe age at diagnosis column has been converted to numeric but the values are in days. For analysis we will convert these to years by dividing by 365.25 (accounting for leap years) and rounding down\n\n# Convert age at diagnosis from days to years (integer)\nbrca_df['diagnoses.age_at_diagnosis'] = (brca_df['diagnoses.age_at_diagnosis'] / 365.25).apply(np.floor)\n\n\n# Check the statistical summary of diagnoses.age_at_diagnosis\n\n# Convert to numeric \nbrca_df['diagnoses.age_at_diagnosis'] = pd.to_numeric(brca_df['diagnoses.age_at_diagnosis'], errors='coerce')\n\n# Statistical summary\nprint(\"Statistical Summary of Age at Diagnosis:\")\nprint(brca_df['diagnoses.age_at_diagnosis'].describe())\n\nprint(f\"\\nMean: {brca_df['diagnoses.age_at_diagnosis'].mean():.2f}\")\nprint(f\"Median: {brca_df['diagnoses.age_at_diagnosis'].median():.2f}\")\nprint(f\"Standard Deviation: {brca_df['diagnoses.age_at_diagnosis'].std():.2f}\")\nprint(f\"Missing values: {brca_df['diagnoses.age_at_diagnosis'].isna().sum()}\")\n\nStatistical Summary of Age at Diagnosis:\ncount    4920.000000\nmean       56.710569\nstd        12.529500\nmin        26.000000\n25%        48.000000\n50%        56.000000\n75%        64.000000\nmax        89.000000\nName: diagnoses.age_at_diagnosis, dtype: float64\n\nMean: 56.71\nMedian: 56.00\nStandard Deviation: 12.53\nMissing values: 0\n\n\n\n# Convert to integer\nbrca_df['diagnoses.age_at_diagnosis'] = pd.to_numeric(\n    brca_df['diagnoses.age_at_diagnosis'], \n    errors='coerce'\n)\nbrca_df['diagnoses.age_at_diagnosis'].dtype\n\ndtype('float64')\n\n\n\n# Change all object type columns to lowercase\nfor col in brca_df.select_dtypes(include=['object']).columns:\n    brca_df[col] = brca_df[col].astype(str).str.lower().replace('nan', np.nan)\n\n\n# strip whitespace from string columns\nfor col in brca_df.select_dtypes(include=['object']).columns:\n    brca_df[col] = brca_df[col].str.strip()\n\n\n# Change demographic.age_is_obfuscated to boolean\nbrca_df['demographic.age_is_obfuscated'] = brca_df['demographic.age_is_obfuscated'].map({'false': False, 'true': True})\n\n# Check the conversion\nprint(brca_df['demographic.age_is_obfuscated'].value_counts())\n\ndemographic.age_is_obfuscated\nFalse    4862\nTrue       58\nName: count, dtype: int64\n\n\n\n# Convert treatments.treatment_or_therapy to boolean from yes/no\nbrca_df['treatments.treatment_or_therapy'] = brca_df['treatments.treatment_or_therapy'].map({'yes': True, 'no': False}) \n# Check the conversion\nprint(brca_df['treatments.treatment_or_therapy'].value_counts())\n\ntreatments.treatment_or_therapy\nTrue     4289\nFalse     559\nName: count, dtype: int64\n\n\nChange other columns to boolean as appropriate: - diagnoses.diagnosis_is_primary_disease (from true/false strings) - diagnoses.prior_malignancy (from no/yes strings) - diagnoses.prior_treatment (from No/Yes strings) - diagnoses.synchronous_malignancy (from no/yes strings)\n\n# Convert diagnosis-related columns to boolean\n\n# Convert diagnoses.diagnosis_is_primary_disease (true/false to boolean)\nbrca_df['diagnoses.diagnosis_is_primary_disease'] = brca_df['diagnoses.diagnosis_is_primary_disease'].map({'true': True, 'false': False})\n\n# Convert diagnoses.prior_malignancy (yes/no to boolean)\nbrca_df['diagnoses.prior_malignancy'] = brca_df['diagnoses.prior_malignancy'].map({'yes': True, 'no': False})\n\n# Convert diagnoses.prior_treatment (yes/no to boolean)\nbrca_df['diagnoses.prior_treatment'] = brca_df['diagnoses.prior_treatment'].map({'yes': True, 'no': False})\n\n# Convert diagnoses.synchronous_malignancy (yes/no to boolean)\nbrca_df['diagnoses.synchronous_malignancy'] = brca_df['diagnoses.synchronous_malignancy'].map({'yes': True, 'no': False})\n\n# Check the conversions\nprint(\"Conversion results:\")\nprint(f\"diagnoses.diagnosis_is_primary_disease dtype: {brca_df['diagnoses.diagnosis_is_primary_disease'].dtype}\")\nprint(f\"diagnoses.prior_malignancy dtype: {brca_df['diagnoses.prior_malignancy'].dtype}\")\nprint(f\"diagnoses.prior_treatment dtype: {brca_df['diagnoses.prior_treatment'].dtype}\")\nprint(f\"diagnoses.synchronous_malignancy dtype: {brca_df['diagnoses.synchronous_malignancy'].dtype}\")\n\nprint(\"\\nValue counts for each column:\")\nfor col in ['diagnoses.diagnosis_is_primary_disease', 'diagnoses.prior_malignancy', \n           'diagnoses.prior_treatment', 'diagnoses.synchronous_malignancy']:\n    print(f\"\\n{col}:\")\n    print(brca_df[col].value_counts())\n\nConversion results:\ndiagnoses.diagnosis_is_primary_disease dtype: bool\ndiagnoses.prior_malignancy dtype: object\ndiagnoses.prior_treatment dtype: object\ndiagnoses.synchronous_malignancy dtype: object\n\nValue counts for each column:\n\ndiagnoses.diagnosis_is_primary_disease:\ndiagnoses.diagnosis_is_primary_disease\nTrue     4896\nFalse      24\nName: count, dtype: int64\n\ndiagnoses.prior_malignancy:\ndiagnoses.prior_malignancy\nFalse    4738\nTrue      133\nName: count, dtype: int64\n\ndiagnoses.prior_treatment:\ndiagnoses.prior_treatment\nFalse    4862\nTrue       48\nName: count, dtype: int64\n\ndiagnoses.synchronous_malignancy:\ndiagnoses.synchronous_malignancy\nFalse    4763\nTrue      108\nName: count, dtype: int64\n\n\n\n\nData Engineering\n\n# Percentage of missing values in each column\nmissing_percentages = brca_df.isnull().mean() * 100\nprint(\"\\nPercentage of missing values in each column:\")\nprint(missing_percentages)\n\n\nPercentage of missing values in each column:\nproject.project_id                         0.000000\ncases.case_id                              0.000000\ncases.disease_type                         0.000000\ncases.index_date                           0.000000\ncases.primary_site                         0.000000\ncases.submitter_id                         0.000000\ndemographic.age_is_obfuscated              0.000000\ndemographic.days_to_death                 88.109756\ndemographic.ethnicity                      0.000000\ndemographic.gender                         0.000000\ndemographic.race                           0.000000\ndemographic.submitter_id                   0.000000\ndemographic.vital_status                   0.000000\ndiagnoses.age_at_diagnosis                 0.000000\ndiagnoses.ajcc_pathologic_m                0.000000\ndiagnoses.ajcc_pathologic_n                0.000000\ndiagnoses.ajcc_pathologic_stage            0.000000\ndiagnoses.ajcc_pathologic_t                0.000000\ndiagnoses.classification_of_tumor          0.000000\ndiagnoses.days_to_diagnosis                0.000000\ndiagnoses.days_to_last_follow_up           0.487805\ndiagnoses.diagnosis_is_primary_disease     0.000000\ndiagnoses.laterality                       0.000000\ndiagnoses.method_of_diagnosis              0.000000\ndiagnoses.morphology                       0.000000\ndiagnoses.primary_diagnosis                0.000000\ndiagnoses.prior_malignancy                 0.995935\ndiagnoses.prior_treatment                  0.203252\ndiagnoses.site_of_resection_or_biopsy      0.000000\ndiagnoses.sites_of_involvement             0.000000\ndiagnoses.submitter_id                     0.000000\ndiagnoses.synchronous_malignancy           0.995935\ndiagnoses.tissue_or_organ_of_origin        0.000000\ntreatments.submitter_id                    0.000000\ntreatments.treatment_or_therapy            1.463415\ntreatments.treatment_type                  0.000000\ndtype: float64\n\n\n\n# Check percentage of missing values in days_to_death when vital_status is 'dead'\nmissing_death_percentage = brca_df[brca_df['demographic.vital_status'] == 'dead']['demographic.days_to_death'].isnull().mean()\nprint(f\"Percentage of missing values in 'demographic.days_to_death' when vital_status is 'dead': {missing_death_percentage:.2%}\")    \n\nPercentage of missing values in 'demographic.days_to_death' when vital_status is 'dead': 0.00%\n\n\n\n# Percentage of missing values in days_to_last_follow_up when vital_status is 'alive'\nmissing_followup_percentage = brca_df[brca_df['demographic.vital_status'] == 'alive']['diagnoses.days_to_last_follow_up'].isnull().mean()\nprint(f\"Percentage of missing values in 'diagnoses.days_to_last_follow_up' when vital_status is 'alive': {missing_followup_percentage:.2%}\")\n\nPercentage of missing values in 'diagnoses.days_to_last_follow_up' when vital_status is 'alive': 0.55%\n\n\n\n# Change days_to_last_follow_up to numeric\nbrca_df['diagnoses.days_to_last_follow_up'] = pd.to_numeric(\n    brca_df['diagnoses.days_to_last_follow_up'], \n    errors='coerce'\n)\n\n\n# Check distribution of days_to_last_follow_up\nbrca_df['diagnoses.days_to_last_follow_up'].describe()\n\ncount    4896.000000\nmean     1323.354575\nstd      1176.067445\nmin        -7.000000\n25%       525.000000\n50%       972.000000\n75%      1876.000000\nmax      8605.000000\nName: diagnoses.days_to_last_follow_up, dtype: float64\n\n\n\n# Replace days to last follow up values less than 0 to with mean\nbrca_df.loc[brca_df['diagnoses.days_to_last_follow_up'] &lt; 0, 'diagnoses.days_to_last_follow_up'] = np.nan\nmean_followup = brca_df['diagnoses.days_to_last_follow_up'].mean()\nbrca_df['diagnoses.days_to_last_follow_up'].fillna(mean_followup, inplace=True)\n\n\n# Create survival time column based on vital status\ndef calculate_survival_time(row):\n    if row['demographic.vital_status'] == 'dead':\n        return row['demographic.days_to_death']\n    elif row['demographic.vital_status'] == 'alive':\n        return row['diagnoses.days_to_last_follow_up']\n    else:\n        return np.nan\n    \nbrca_df['survival_time_days'] = brca_df.apply(calculate_survival_time, axis=1)\n\n\n# Check percentage of missing values in survival_time_days\nmissing_percentage = brca_df['survival_time_days'].isnull().mean() * 100\nprint(f\"Percentage of missing values in 'survival_time_days': {missing_percentage:.2f}%\")\n\nPercentage of missing values in 'survival_time_days': 0.00%\n\n\n\n# Drop rows with missing survival_time_days\nbrca_df = brca_df[brca_df['survival_time_days'].notna()]\nbrca_df.shape\n\n(4920, 37)\n\n\n\n# Drop duplicate rows before feature engineering\nbrca_df = brca_df.drop_duplicates()\nbrca_df.shape\n\n(4920, 37)\n\n\n\n# Extract diagnoses.behavior from diagnoses.morphology column (e.g., 8500/3 -&gt; 3 where 3 is the behavior code)\n\n# Mappings for behavior codes\nbehavior_mapping = {\n    '0': 'benign',\n    '2': 'in situ',\n    '3': 'malignant'\n}\n# Extract behavior code and map to descriptive labels\nbrca_df['diagnoses.behavior'] = brca_df['diagnoses.morphology'].str.split('/').str[1].map(behavior_mapping)\n# Check the new column\nprint(\"Value counts for diagnoses.behavior:\")\nprint(brca_df['diagnoses.behavior'].value_counts())\n\nValue counts for diagnoses.behavior:\ndiagnoses.behavior\nmalignant    4905\nin situ         6\nName: count, dtype: int64\n\n\nNote: There is a heavy class imbalance for diagnoses.behavior as over 95% of the entries are malignant.\n\nbrca_df.head()\n\n\n\n\n\n\n\n\nproject.project_id\ncases.case_id\ncases.disease_type\ncases.index_date\ncases.primary_site\ncases.submitter_id\ndemographic.age_is_obfuscated\ndemographic.days_to_death\ndemographic.ethnicity\ndemographic.gender\ndemographic.race\ndemographic.submitter_id\ndemographic.vital_status\ndiagnoses.age_at_diagnosis\ndiagnoses.ajcc_pathologic_m\ndiagnoses.ajcc_pathologic_n\ndiagnoses.ajcc_pathologic_stage\ndiagnoses.ajcc_pathologic_t\ndiagnoses.classification_of_tumor\ndiagnoses.days_to_diagnosis\ndiagnoses.days_to_last_follow_up\ndiagnoses.diagnosis_is_primary_disease\ndiagnoses.laterality\ndiagnoses.method_of_diagnosis\ndiagnoses.morphology\ndiagnoses.primary_diagnosis\ndiagnoses.prior_malignancy\ndiagnoses.prior_treatment\ndiagnoses.site_of_resection_or_biopsy\ndiagnoses.sites_of_involvement\ndiagnoses.submitter_id\ndiagnoses.synchronous_malignancy\ndiagnoses.tissue_or_organ_of_origin\ntreatments.submitter_id\ntreatments.treatment_or_therapy\ntreatments.treatment_type\nsurvival_time_days\ndiagnoses.behavior\n\n\n\n\n0\ntcga-brca\n001cef41-ff86-4d3f-a140-a647ac4b10a1\nductal and lobular neoplasms\ndiagnosis\nbreast\ntcga-e2-a1iu\nFalse\nNaN\nnot hispanic or latino\nfemale\nwhite\ntcga-e2-a1iu_demographic\nalive\n60.0\nm0\nn0 (mol+)\nstage ia\nt1c\nprimary\n0\n337.0\nTrue\nright\nsurgical resection\n8500/3\ninfiltrating duct carcinoma, nos\nFalse\nFalse\nbreast, nos\nbreast, right upper outer\ntcga-e2-a1iu_diagnosis\nFalse\nbreast, nos\ntcga-e2-a1iu_treatment2\nFalse\nradiation therapy, nos\n337.0\nmalignant\n\n\n1\ntcga-brca\n001cef41-ff86-4d3f-a140-a647ac4b10a1\nductal and lobular neoplasms\ndiagnosis\nbreast\ntcga-e2-a1iu\nFalse\nNaN\nnot hispanic or latino\nfemale\nwhite\ntcga-e2-a1iu_demographic\nalive\n60.0\nm0\nn0 (mol+)\nstage ia\nt1c\nprimary\n0\n337.0\nTrue\nright\nsurgical resection\n8500/3\ninfiltrating duct carcinoma, nos\nFalse\nFalse\nbreast, nos\nbreast, right upper outer\ntcga-e2-a1iu_diagnosis\nFalse\nbreast, nos\ntcga-e2-a1iu_treatment\nTrue\nhormone therapy\n337.0\nmalignant\n\n\n2\ntcga-brca\n001cef41-ff86-4d3f-a140-a647ac4b10a1\nductal and lobular neoplasms\ndiagnosis\nbreast\ntcga-e2-a1iu\nFalse\nNaN\nnot hispanic or latino\nfemale\nwhite\ntcga-e2-a1iu_demographic\nalive\n60.0\nm0\nn0 (mol+)\nstage ia\nt1c\nprimary\n0\n337.0\nTrue\nright\nsurgical resection\n8500/3\ninfiltrating duct carcinoma, nos\nFalse\nFalse\nbreast, nos\nbreast, right upper outer\ntcga-e2-a1iu_diagnosis\nFalse\nbreast, nos\ntcga-e2-a1iu_treatment3\nTrue\nsurgery, nos\n337.0\nmalignant\n\n\n3\ntcga-brca\n0045349c-69d9-4306-a403-c9c1fa836644\nadenomas and adenocarcinomas\ndiagnosis\nbreast\ntcga-a1-a0sb\nFalse\nNaN\nnot hispanic or latino\nfemale\nwhite\ntcga-a1-a0sb_demographic\nalive\n70.0\nm0\nn0\nstage i\nt1c\nprimary\n0\n259.0\nTrue\nleft\nfine needle aspiration\n8200/3\nadenoid cystic carcinoma\nFalse\nFalse\nbreast, nos\nbreast, nos\ntcga-a1-a0sb_diagnosis\nFalse\nbreast, nos\ntcga-a1-a0sb_treatment\nTrue\nsurgery, nos\n259.0\nmalignant\n\n\n4\ntcga-brca\n00807dae-9f4a-4fd1-aac2-82eb11bf2afb\nadnexal and skin appendage neoplasms\ndiagnosis\nbreast\ntcga-a2-a04w\nFalse\nNaN\nnot hispanic or latino\nfemale\nwhite\ntcga-a2-a04w_demographic\nalive\n50.0\nm0\nn1mi\nstage iib\nt2\nprimary\n0\n3102.0\nTrue\nright\ncore biopsy\n8401/3\napocrine adenocarcinoma\nFalse\nFalse\nbreast, nos\nbreast, right upper outer\ntcga-a2-a04w_diagnosis\nFalse\nbreast, nos\ntcga-a2-a04w_treatment5\nTrue\nbisphosphonate therapy\n3102.0\nmalignant\n\n\n\n\n\n\n\n\n# Check distribution of missing values in columns after cleaning and data engineering\nmissing_percentages = brca_df.isnull().mean() * 100\nprint(\"\\nPercentage of missing values in each column:\")\nprint(missing_percentages)\n\n\nPercentage of missing values in each column:\nproject.project_id                         0.000000\ncases.case_id                              0.000000\ncases.disease_type                         0.000000\ncases.index_date                           0.000000\ncases.primary_site                         0.000000\ncases.submitter_id                         0.000000\ndemographic.age_is_obfuscated              0.000000\ndemographic.days_to_death                 88.109756\ndemographic.ethnicity                      0.000000\ndemographic.gender                         0.000000\ndemographic.race                           0.000000\ndemographic.submitter_id                   0.000000\ndemographic.vital_status                   0.000000\ndiagnoses.age_at_diagnosis                 0.000000\ndiagnoses.ajcc_pathologic_m                0.000000\ndiagnoses.ajcc_pathologic_n                0.000000\ndiagnoses.ajcc_pathologic_stage            0.000000\ndiagnoses.ajcc_pathologic_t                0.000000\ndiagnoses.classification_of_tumor          0.000000\ndiagnoses.days_to_diagnosis                0.000000\ndiagnoses.days_to_last_follow_up           0.000000\ndiagnoses.diagnosis_is_primary_disease     0.000000\ndiagnoses.laterality                       0.000000\ndiagnoses.method_of_diagnosis              0.000000\ndiagnoses.morphology                       0.000000\ndiagnoses.primary_diagnosis                0.000000\ndiagnoses.prior_malignancy                 0.995935\ndiagnoses.prior_treatment                  0.203252\ndiagnoses.site_of_resection_or_biopsy      0.000000\ndiagnoses.sites_of_involvement             0.000000\ndiagnoses.submitter_id                     0.000000\ndiagnoses.synchronous_malignancy           0.995935\ndiagnoses.tissue_or_organ_of_origin        0.000000\ntreatments.submitter_id                    0.000000\ntreatments.treatment_or_therapy            1.463415\ntreatments.treatment_type                  0.000000\nsurvival_time_days                         0.000000\ndiagnoses.behavior                         0.182927\ndtype: float64\n\n\n\n# Replace missing values in diagnoses.prior_malignancy, diagnoses.prior_treatment, diagnoses.synchronous_malignancy with False, treatments.treat_or_therapy with True\nbrca_df['diagnoses.prior_malignancy'] = brca_df['diagnoses.prior_malignancy'].fillna(False)\nbrca_df['diagnoses.prior_treatment'] = brca_df['diagnoses.prior_treatment'].fillna(False)\nbrca_df['diagnoses.synchronous_malignancy'] = brca_df['diagnoses.synchronous_malignancy'].fillna(False)\nbrca_df['treatments.treatment_or_therapy'] = brca_df['treatments.treatment_or_therapy'].fillna(True)\n\n\n\nSave processed dataset\n\n# Save cleaned dataset to a new TSV file\nbrca_df.to_csv(\"data/processed-data/brca/brca-clinical-processed.tsv\", sep=\"\\t\", index=False)"
  },
  {
    "objectID": "data-download.html",
    "href": "data-download.html",
    "title": "Data Collection",
    "section": "",
    "text": "# Import necessary libraries\n\nimport requests\nimport pandas as pd \nimport os\nimport json\nfrom datetime import datetime\nimport time"
  },
  {
    "objectID": "data-download.html#clinical-data",
    "href": "data-download.html#clinical-data",
    "title": "Data Collection",
    "section": "Clinical Data",
    "text": "Clinical Data\n\n# Open CESC tsv data\n\ncesc = pd.read_csv('data/raw-data/cesc/cesc-clinical.tsv', sep='\\t')\ncesc.head(3)\n\n\n\n\n\n\n\n\nproject.project_id\ncases.case_id\ncases.consent_type\ncases.days_to_consent\ncases.days_to_lost_to_followup\ncases.disease_type\ncases.index_date\ncases.lost_to_followup\ncases.primary_site\ncases.submitter_id\n...\ntreatments.treatment_duration\ntreatments.treatment_effect\ntreatments.treatment_effect_indicator\ntreatments.treatment_frequency\ntreatments.treatment_id\ntreatments.treatment_intent_type\ntreatments.treatment_or_therapy\ntreatments.treatment_outcome\ntreatments.treatment_outcome_duration\ntreatments.treatment_type\n\n\n\n\n0\nTCGA-CESC\n00ad0ffe-2105-4829-a495-1c2aceb5bb31\nInformed Consent\n0\n'--\nSquamous Cell Neoplasms\nDiagnosis\nYes\nCervix uteri\nTCGA-EK-A2R9\n...\n'--\n'--\n'--\n'--\n672b3cf9-bb40-4f6f-a1c9-69ac3383fbd5\n'--\n'--\n'--\n'--\nHysterectomy, NOS\n\n\n1\nTCGA-CESC\n00ad0ffe-2105-4829-a495-1c2aceb5bb31\nInformed Consent\n0\n'--\nSquamous Cell Neoplasms\nDiagnosis\nYes\nCervix uteri\nTCGA-EK-A2R9\n...\n'--\n'--\n'--\n'--\nd4baa31f-8c1f-5333-afcd-836816fd1a2a\nAdjuvant\nunknown\n'--\n'--\nPharmaceutical Therapy, NOS\n\n\n2\nTCGA-CESC\n00ad0ffe-2105-4829-a495-1c2aceb5bb31\nInformed Consent\n0\n'--\nSquamous Cell Neoplasms\nDiagnosis\nYes\nCervix uteri\nTCGA-EK-A2R9\n...\n'--\n'--\n'--\n'--\ne79370ba-36f0-4639-bc8f-119ba2b2457b\nAdjuvant\nunknown\n'--\n'--\nRadiation Therapy, NOS\n\n\n3\nTCGA-CESC\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nInformed Consent\n2108\n'--\nSquamous Cell Neoplasms\nDiagnosis\nYes\nCervix uteri\nTCGA-C5-A2LV\n...\n'--\n'--\n'--\n'--\n277d525e-9674-4954-b427-3e829d469b8f\n'--\n'--\n'--\n'--\nHysterectomy, NOS\n\n\n4\nTCGA-CESC\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nInformed Consent\n2108\n'--\nSquamous Cell Neoplasms\nDiagnosis\nYes\nCervix uteri\nTCGA-C5-A2LV\n...\n'--\n'--\n'--\n'--\n788ff156-d009-46f7-b832-f39b11ed13ac\nAdjuvant\nno\n'--\n'--\nRadiation Therapy, NOS\n\n\n\n\n5 rows × 210 columns\n\n\n\n\nnrow, ncol = cesc.shape\nprint(f'The data has {nrow} rows and {ncol} columns.')\n\nThe data has 1535 rows and 210 columns.\n\n\n\n# List column names\nprint(\"Column names:\")\nprint(cesc.columns.tolist())\n\nColumn names:\n['project.project_id', 'cases.case_id', 'cases.consent_type', 'cases.days_to_consent', 'cases.days_to_lost_to_followup', 'cases.disease_type', 'cases.index_date', 'cases.lost_to_followup', 'cases.primary_site', 'cases.submitter_id', 'demographic.age_at_index', 'demographic.age_is_obfuscated', 'demographic.cause_of_death', 'demographic.cause_of_death_source', 'demographic.country_of_birth', 'demographic.country_of_residence_at_enrollment', 'demographic.days_to_birth', 'demographic.days_to_death', 'demographic.demographic_id', 'demographic.education_level', 'demographic.ethnicity', 'demographic.gender', 'demographic.marital_status', 'demographic.occupation_duration_years', 'demographic.population_group', 'demographic.premature_at_birth', 'demographic.race', 'demographic.submitter_id', 'demographic.vital_status', 'demographic.weeks_gestation_at_birth', 'demographic.year_of_birth', 'demographic.year_of_death', 'diagnoses.adrenal_hormone', 'diagnoses.age_at_diagnosis', 'diagnoses.ajcc_clinical_m', 'diagnoses.ajcc_clinical_n', 'diagnoses.ajcc_clinical_stage', 'diagnoses.ajcc_clinical_t', 'diagnoses.ajcc_pathologic_m', 'diagnoses.ajcc_pathologic_n', 'diagnoses.ajcc_pathologic_stage', 'diagnoses.ajcc_pathologic_t', 'diagnoses.ajcc_serum_tumor_markers', 'diagnoses.ajcc_staging_system_edition', 'diagnoses.ann_arbor_b_symptoms', 'diagnoses.ann_arbor_b_symptoms_described', 'diagnoses.ann_arbor_clinical_stage', 'diagnoses.ann_arbor_extranodal_involvement', 'diagnoses.ann_arbor_pathologic_stage', 'diagnoses.best_overall_response', 'diagnoses.burkitt_lymphoma_clinical_variant', 'diagnoses.calgb_risk_group', 'diagnoses.cancer_detection_method', 'diagnoses.child_pugh_classification', 'diagnoses.clark_level', 'diagnoses.classification_of_tumor', 'diagnoses.cog_liver_stage', 'diagnoses.cog_neuroblastoma_risk_group', 'diagnoses.cog_renal_stage', 'diagnoses.cog_rhabdomyosarcoma_risk_group', 'diagnoses.contiguous_organ_invaded', 'diagnoses.days_to_best_overall_response', 'diagnoses.days_to_diagnosis', 'diagnoses.days_to_last_follow_up', 'diagnoses.days_to_last_known_disease_status', 'diagnoses.days_to_recurrence', 'diagnoses.diagnosis_id', 'diagnoses.diagnosis_is_primary_disease', 'diagnoses.double_expressor_lymphoma', 'diagnoses.double_hit_lymphoma', 'diagnoses.eln_risk_classification', 'diagnoses.enneking_msts_grade', 'diagnoses.enneking_msts_metastasis', 'diagnoses.enneking_msts_stage', 'diagnoses.enneking_msts_tumor_site', 'diagnoses.ensat_clinical_m', 'diagnoses.ensat_pathologic_n', 'diagnoses.ensat_pathologic_stage', 'diagnoses.ensat_pathologic_t', 'diagnoses.esophageal_columnar_dysplasia_degree', 'diagnoses.esophageal_columnar_metaplasia_present', 'diagnoses.fab_morphology_code', 'diagnoses.figo_stage', 'diagnoses.figo_staging_edition_year', 'diagnoses.first_symptom_longest_duration', 'diagnoses.first_symptom_prior_to_diagnosis', 'diagnoses.gastric_esophageal_junction_involvement', 'diagnoses.gleason_grade_group', 'diagnoses.gleason_grade_tertiary', 'diagnoses.gleason_patterns_percent', 'diagnoses.gleason_score', 'diagnoses.goblet_cells_columnar_mucosa_present', 'diagnoses.icd_10_code', 'diagnoses.igcccg_stage', 'diagnoses.inpc_grade', 'diagnoses.inpc_histologic_group', 'diagnoses.inrg_stage', 'diagnoses.inss_stage', 'diagnoses.international_prognostic_index', 'diagnoses.irs_group', 'diagnoses.irs_stage', 'diagnoses.ishak_fibrosis_score', 'diagnoses.iss_stage', 'diagnoses.last_known_disease_status', 'diagnoses.laterality', 'diagnoses.margin_distance', 'diagnoses.margins_involved_site', 'diagnoses.masaoka_stage', 'diagnoses.max_tumor_bulk_site', 'diagnoses.medulloblastoma_molecular_classification', 'diagnoses.melanoma_known_primary', 'diagnoses.metastasis_at_diagnosis', 'diagnoses.metastasis_at_diagnosis_site', 'diagnoses.method_of_diagnosis', 'diagnoses.micropapillary_features', 'diagnoses.mitosis_karyorrhexis_index', 'diagnoses.mitotic_count', 'diagnoses.morphology', 'diagnoses.ovarian_specimen_status', 'diagnoses.ovarian_surface_involvement', 'diagnoses.papillary_renal_cell_type', 'diagnoses.pediatric_kidney_staging', 'diagnoses.peritoneal_fluid_cytological_status', 'diagnoses.pregnant_at_diagnosis', 'diagnoses.primary_diagnosis', 'diagnoses.primary_disease', 'diagnoses.primary_gleason_grade', 'diagnoses.prior_malignancy', 'diagnoses.prior_treatment', 'diagnoses.progression_or_recurrence', 'diagnoses.residual_disease', 'diagnoses.satellite_nodule_present', 'diagnoses.secondary_gleason_grade', 'diagnoses.site_of_resection_or_biopsy', 'diagnoses.sites_of_involvement', 'diagnoses.sites_of_involvement_count', 'diagnoses.submitter_id', 'diagnoses.supratentorial_localization', 'diagnoses.synchronous_malignancy', 'diagnoses.tissue_or_organ_of_origin', 'diagnoses.tumor_burden', 'diagnoses.tumor_confined_to_organ_of_origin', 'diagnoses.tumor_depth', 'diagnoses.tumor_focality', 'diagnoses.tumor_grade', 'diagnoses.tumor_grade_category', 'diagnoses.tumor_of_origin', 'diagnoses.tumor_regression_grade', 'diagnoses.uicc_clinical_m', 'diagnoses.uicc_clinical_n', 'diagnoses.uicc_clinical_stage', 'diagnoses.uicc_clinical_t', 'diagnoses.uicc_pathologic_m', 'diagnoses.uicc_pathologic_n', 'diagnoses.uicc_pathologic_stage', 'diagnoses.uicc_pathologic_t', 'diagnoses.uicc_staging_system_edition', 'diagnoses.ulceration_indicator', 'diagnoses.weiss_assessment_findings', 'diagnoses.weiss_assessment_score', 'diagnoses.who_cns_grade', 'diagnoses.who_nte_grade', 'diagnoses.wilms_tumor_histologic_subtype', 'diagnoses.year_of_diagnosis', 'treatments.chemo_concurrent_to_radiation', 'treatments.clinical_trial_indicator', 'treatments.course_number', 'treatments.days_to_treatment_end', 'treatments.days_to_treatment_start', 'treatments.drug_category', 'treatments.embolic_agent', 'treatments.initial_disease_status', 'treatments.lesions_treated_number', 'treatments.margin_distance', 'treatments.margin_status', 'treatments.margins_involved_site', 'treatments.number_of_cycles', 'treatments.number_of_fractions', 'treatments.prescribed_dose', 'treatments.prescribed_dose_units', 'treatments.pretreatment', 'treatments.protocol_identifier', 'treatments.radiosensitizing_agent', 'treatments.reason_treatment_ended', 'treatments.reason_treatment_not_given', 'treatments.regimen_or_line_of_therapy', 'treatments.residual_disease', 'treatments.route_of_administration', 'treatments.submitter_id', 'treatments.therapeutic_agents', 'treatments.therapeutic_level_achieved', 'treatments.therapeutic_levels_achieved', 'treatments.therapeutic_target_level', 'treatments.timepoint_category', 'treatments.treatment_anatomic_site', 'treatments.treatment_anatomic_sites', 'treatments.treatment_arm', 'treatments.treatment_dose', 'treatments.treatment_dose_max', 'treatments.treatment_dose_units', 'treatments.treatment_duration', 'treatments.treatment_effect', 'treatments.treatment_effect_indicator', 'treatments.treatment_frequency', 'treatments.treatment_id', 'treatments.treatment_intent_type', 'treatments.treatment_or_therapy', 'treatments.treatment_outcome', 'treatments.treatment_outcome_duration', 'treatments.treatment_type']\n\n\n\n# Number of unique patients\nunique_patients = cesc['cases.submitter_id'].nunique()\nprint(f'The data has {unique_patients} unique patients.')\n\nThe data has 307 unique patients."
  },
  {
    "objectID": "supervised-learning.html",
    "href": "supervised-learning.html",
    "title": "Breast (BRCA) Cancer Survival Time (days) Prediction Using Supervised Learning Models",
    "section": "",
    "text": "project.project_id\ncases.case_id\ncases.disease_type\ncases.index_date\ncases.primary_site\ncases.submitter_id\ndemographic.age_is_obfuscated\ndemographic.days_to_death\ndemographic.ethnicity\ndemographic.gender\ndemographic.race\ndemographic.submitter_id\ndemographic.vital_status\ndiagnoses.age_at_diagnosis\ndiagnoses.ajcc_pathologic_m\ndiagnoses.ajcc_pathologic_n\ndiagnoses.ajcc_pathologic_stage\ndiagnoses.ajcc_pathologic_t\ndiagnoses.classification_of_tumor\ndiagnoses.days_to_diagnosis\ndiagnoses.days_to_last_follow_up\ndiagnoses.diagnosis_is_primary_disease\ndiagnoses.laterality\ndiagnoses.method_of_diagnosis\ndiagnoses.morphology\ndiagnoses.primary_diagnosis\ndiagnoses.prior_malignancy\ndiagnoses.prior_treatment\ndiagnoses.site_of_resection_or_biopsy\ndiagnoses.sites_of_involvement\ndiagnoses.submitter_id\ndiagnoses.synchronous_malignancy\ndiagnoses.tissue_or_organ_of_origin\ntreatments.submitter_id\ntreatments.treatment_or_therapy\ntreatments.treatment_type\nsurvival_time_days\ndiagnoses.behavior\n\n\n\n\n0\ntcga-brca\n001cef41-ff86-4d3f-a140-a647ac4b10a1\nductal and lobular neoplasms\ndiagnosis\nbreast\ntcga-e2-a1iu\nFalse\nNaN\nnot hispanic or latino\nfemale\nwhite\ntcga-e2-a1iu_demographic\nalive\n60.0\nm0\nn0 (mol+)\nstage ia\nt1c\nprimary\n0\n337.0\nTrue\nright\nsurgical resection\n8500/3\ninfiltrating duct carcinoma, nos\nFalse\nFalse\nbreast, nos\nbreast, right upper outer\ntcga-e2-a1iu_diagnosis\nFalse\nbreast, nos\ntcga-e2-a1iu_treatment2\nFalse\nradiation therapy, nos\n337.0\nmalignant\n\n\n1\ntcga-brca\n001cef41-ff86-4d3f-a140-a647ac4b10a1\nductal and lobular neoplasms\ndiagnosis\nbreast\ntcga-e2-a1iu\nFalse\nNaN\nnot hispanic or latino\nfemale\nwhite\ntcga-e2-a1iu_demographic\nalive\n60.0\nm0\nn0 (mol+)\nstage ia\nt1c\nprimary\n0\n337.0\nTrue\nright\nsurgical resection\n8500/3\ninfiltrating duct carcinoma, nos\nFalse\nFalse\nbreast, nos\nbreast, right upper outer\ntcga-e2-a1iu_diagnosis\nFalse\nbreast, nos\ntcga-e2-a1iu_treatment\nTrue\nhormone therapy\n337.0\nmalignant\n\n\n\n\n\n\n\n\n\n\nAfter deduplication:\nDeduplicated dataset shape: (1081, 39)\nUnique cases.submitter_id: 1081\nRows removed: 3815\n\nTreatment distribution in deduplicated data:\ntreatments.treatment_or_therapy\nTrue     1076\nFalse       5\nName: count, dtype: int64\n\nFinal BRCA dataset shape: (1081, 39)\n\n\n\nRemove Non-informative Features: Exclude features with low variance e.g., behavior of the tumor is malignant for all samples. Dropped features:\n\nproject_id: represents the project and is constant for all samples.\ncase_id: unique identifier for each case, not useful for prediction.\nsubmitter_id: unique identifier for each submitter, not useful for prediction.\nprimary_site: all samples are from the breast, so this feature has no variance.\nindex_date: date of indexing, not relevant for prediction.\nage_is_obfuscated: flag indicating if age is obfuscated, not useful for prediction.\ndays_to_death: not applicable for all samples, leading to missing values.\nethnicity: heavy imbalance to not hispanic or latino (over 80% of samples), leading to low variance. Race might capture the variance better.\ngender: all samples are female, so this feature has no variance\nclassification_of_tumor: all samples are primary, so this feature has no variance.\ndays_to_diagnosis: 0 for all samples, so this feature has no variance.\ndays_to _last_follow_up: not applicable for all samples, leading to missing values.\nvital_status: does not make sense to predict survival time based on whether the patient is alive or dead at last follow-up.\nlaterality: research indicates no significant difference in breast cancer outcomes based on laterality. Dataset does not show imbalance in laterality distribution.\ndiagnoses.prior_treatment: heavy imbalance to false (97% of samples), leading to low variance. Assuming number of treatments is more informative.\nsite_of_resection_or_biopsy: all samples are from the breast, so this feature has no variance. Specific location within the breast (sites_of_involvement) may provide more detailed information.\nsynchronous_malignancy: heavy imbalance to false (&gt; 97%), so this feature has no variance.\ntreatments.submitter_id: unique identifier for each submitter, not useful for prediction.\ntreatments_or_therapy: Heavy imbalance to true as most patients receive treatment, so this feature has low variance. Specific treatment types may provide more information.\ndiagnoses.diagnosis_is_primary_disease: all samples are primary, so this feature has no variance.\ndiagnoses.method_of_diagnosis: Not informative to how long a patient survives. The primary diagnosis might be more relevant.\n\n\n\n\nOriginal dataset shape: (1081, 39)\nCleaned dataset shape: (1081, 14)\nColumns removed: 25\n\n\n\nNormalization: Numerical columns age_at_diagnosis and treatments.count will be normalized using Min-Max scaling.\nBoolean Variables: Convert boolean variables to integers (0 and 1) for model compatibility, vital status to 1 for alive\nOrdinal Categorical: Variables: Use Ordinal Encoding for features with an inherent order (e.g., tumor_stage).\nEncoding Categorical Variables: Categorical variables will be encoded using One-Hot Encoding to convert them into a format suitable for machine learning algorithms.\n\nAJCC Cancer Staging Has a Natural Order\nStage I → Stage II → Stage III → Stage IV Earlier = less severe → later = more severe.\nWithin each major stage, letters (A, B, C) represent increasing severity, e.g.:\nI &lt; IA &lt; IB &lt; II &lt; IIA &lt; IIB &lt; III &lt; IIIA &lt; IIIB &lt; IIIC &lt; IV\nT = primary tumor size AND local extent of invasion\nThe N (nodes) category in the TNM system describes regional lymph node involvement:\nThe M (metastasis) part of TNM describes presence of distant metastasis."
  },
  {
    "objectID": "supervised-learning.html#data-preprocessing",
    "href": "supervised-learning.html#data-preprocessing",
    "title": "Breast (BRCA) Cancer Survival Time (days) Prediction Using Supervised Learning Models",
    "section": "",
    "text": "project.project_id\ncases.case_id\ncases.disease_type\ncases.index_date\ncases.primary_site\ncases.submitter_id\ndemographic.age_is_obfuscated\ndemographic.days_to_death\ndemographic.ethnicity\ndemographic.gender\ndemographic.race\ndemographic.submitter_id\ndemographic.vital_status\ndiagnoses.age_at_diagnosis\ndiagnoses.ajcc_pathologic_m\ndiagnoses.ajcc_pathologic_n\ndiagnoses.ajcc_pathologic_stage\ndiagnoses.ajcc_pathologic_t\ndiagnoses.classification_of_tumor\ndiagnoses.days_to_diagnosis\ndiagnoses.days_to_last_follow_up\ndiagnoses.diagnosis_is_primary_disease\ndiagnoses.laterality\ndiagnoses.method_of_diagnosis\ndiagnoses.morphology\ndiagnoses.primary_diagnosis\ndiagnoses.prior_malignancy\ndiagnoses.prior_treatment\ndiagnoses.site_of_resection_or_biopsy\ndiagnoses.sites_of_involvement\ndiagnoses.submitter_id\ndiagnoses.synchronous_malignancy\ndiagnoses.tissue_or_organ_of_origin\ntreatments.submitter_id\ntreatments.treatment_or_therapy\ntreatments.treatment_type\nsurvival_time_days\ndiagnoses.behavior\n\n\n\n\n0\ntcga-brca\n001cef41-ff86-4d3f-a140-a647ac4b10a1\nductal and lobular neoplasms\ndiagnosis\nbreast\ntcga-e2-a1iu\nFalse\nNaN\nnot hispanic or latino\nfemale\nwhite\ntcga-e2-a1iu_demographic\nalive\n60.0\nm0\nn0 (mol+)\nstage ia\nt1c\nprimary\n0\n337.0\nTrue\nright\nsurgical resection\n8500/3\ninfiltrating duct carcinoma, nos\nFalse\nFalse\nbreast, nos\nbreast, right upper outer\ntcga-e2-a1iu_diagnosis\nFalse\nbreast, nos\ntcga-e2-a1iu_treatment2\nFalse\nradiation therapy, nos\n337.0\nmalignant\n\n\n1\ntcga-brca\n001cef41-ff86-4d3f-a140-a647ac4b10a1\nductal and lobular neoplasms\ndiagnosis\nbreast\ntcga-e2-a1iu\nFalse\nNaN\nnot hispanic or latino\nfemale\nwhite\ntcga-e2-a1iu_demographic\nalive\n60.0\nm0\nn0 (mol+)\nstage ia\nt1c\nprimary\n0\n337.0\nTrue\nright\nsurgical resection\n8500/3\ninfiltrating duct carcinoma, nos\nFalse\nFalse\nbreast, nos\nbreast, right upper outer\ntcga-e2-a1iu_diagnosis\nFalse\nbreast, nos\ntcga-e2-a1iu_treatment\nTrue\nhormone therapy\n337.0\nmalignant\n\n\n\n\n\n\n\n\n\n\nAfter deduplication:\nDeduplicated dataset shape: (1081, 39)\nUnique cases.submitter_id: 1081\nRows removed: 3815\n\nTreatment distribution in deduplicated data:\ntreatments.treatment_or_therapy\nTrue     1076\nFalse       5\nName: count, dtype: int64\n\nFinal BRCA dataset shape: (1081, 39)\n\n\n\nRemove Non-informative Features: Exclude features with low variance e.g., behavior of the tumor is malignant for all samples. Dropped features:\n\nproject_id: represents the project and is constant for all samples.\ncase_id: unique identifier for each case, not useful for prediction.\nsubmitter_id: unique identifier for each submitter, not useful for prediction.\nprimary_site: all samples are from the breast, so this feature has no variance.\nindex_date: date of indexing, not relevant for prediction.\nage_is_obfuscated: flag indicating if age is obfuscated, not useful for prediction.\ndays_to_death: not applicable for all samples, leading to missing values.\nethnicity: heavy imbalance to not hispanic or latino (over 80% of samples), leading to low variance. Race might capture the variance better.\ngender: all samples are female, so this feature has no variance\nclassification_of_tumor: all samples are primary, so this feature has no variance.\ndays_to_diagnosis: 0 for all samples, so this feature has no variance.\ndays_to _last_follow_up: not applicable for all samples, leading to missing values.\nvital_status: does not make sense to predict survival time based on whether the patient is alive or dead at last follow-up.\nlaterality: research indicates no significant difference in breast cancer outcomes based on laterality. Dataset does not show imbalance in laterality distribution.\ndiagnoses.prior_treatment: heavy imbalance to false (97% of samples), leading to low variance. Assuming number of treatments is more informative.\nsite_of_resection_or_biopsy: all samples are from the breast, so this feature has no variance. Specific location within the breast (sites_of_involvement) may provide more detailed information.\nsynchronous_malignancy: heavy imbalance to false (&gt; 97%), so this feature has no variance.\ntreatments.submitter_id: unique identifier for each submitter, not useful for prediction.\ntreatments_or_therapy: Heavy imbalance to true as most patients receive treatment, so this feature has low variance. Specific treatment types may provide more information.\ndiagnoses.diagnosis_is_primary_disease: all samples are primary, so this feature has no variance.\ndiagnoses.method_of_diagnosis: Not informative to how long a patient survives. The primary diagnosis might be more relevant.\n\n\n\n\nOriginal dataset shape: (1081, 39)\nCleaned dataset shape: (1081, 14)\nColumns removed: 25\n\n\n\nNormalization: Numerical columns age_at_diagnosis and treatments.count will be normalized using Min-Max scaling.\nBoolean Variables: Convert boolean variables to integers (0 and 1) for model compatibility, vital status to 1 for alive\nOrdinal Categorical: Variables: Use Ordinal Encoding for features with an inherent order (e.g., tumor_stage).\nEncoding Categorical Variables: Categorical variables will be encoded using One-Hot Encoding to convert them into a format suitable for machine learning algorithms.\n\nAJCC Cancer Staging Has a Natural Order\nStage I → Stage II → Stage III → Stage IV Earlier = less severe → later = more severe.\nWithin each major stage, letters (A, B, C) represent increasing severity, e.g.:\nI &lt; IA &lt; IB &lt; II &lt; IIA &lt; IIB &lt; III &lt; IIIA &lt; IIIB &lt; IIIC &lt; IV\nT = primary tumor size AND local extent of invasion\nThe N (nodes) category in the TNM system describes regional lymph node involvement:\nThe M (metastasis) part of TNM describes presence of distant metastasis."
  },
  {
    "objectID": "supervised-learning.html#model-selection",
    "href": "supervised-learning.html#model-selection",
    "title": "Breast (BRCA) Cancer Survival Time (days) Prediction Using Supervised Learning Models",
    "section": "Model Selection",
    "text": "Model Selection\nThe following models will be evaluated for predicting patient survival time based on the preprocessed BRCA dataset: 1. Standard Linear Regression: Benchmark model for comparison 2. Regression Trees: XGBoost Regressor for capturing non-linear relationships and interactions between features. 3. Parametric Linear Regression: With Lasso regularization to prevent overfitting and eliminate potentially redundant features."
  },
  {
    "objectID": "supervised-learning.html#training-and-testing",
    "href": "supervised-learning.html#training-and-testing",
    "title": "Breast (BRCA) Cancer Survival Time (days) Prediction Using Supervised Learning Models",
    "section": "Training and Testing",
    "text": "Training and Testing\nThe dataset will be split into training and testing sets using an 80-20 split. Cross-validation will be employed during model training to ensure robustness and generalizability of the models.\n\nStandard Linear Regression\n\n\nLinear Regression Model Evaluation on Test Set:\nRMSE: 61585077470726.38\nMAE: 7691527358667.03\nR2 Score: -2406669127225213190144.0000\n\n\n\n\nParametric Curve Fitting\nWe do a parametric Curve Fitting with L1 regularization (Lasso) to predict patient survival time based on the preprocessed BRCA dataset. Design choicces include: - Model Choice: Lasso regression is chosen for its ability to perform both variable selection and regularization, which helps enhance the prediction accuracy and interpretability of the statistical model it produces. In addition, early stopping is implemented to prevent overfitting during training. - Hyperparameter Tuning: The regularization parameter (alpha) will be tuned using cross-validation to find the optimal balance between bias and variance. - Evaluation Metrics: Model performance will be evaluated using Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and R-squared (R²) to provide a comprehensive assessment of prediction accuracy. - SGDRegressor is used for optimization due to its efficiency with large datasets and ability to handle L1 regularization effectively.\n\n\nTraining MAE Linear Regression with Lasso Regularization...\n============================================================\n\nTesting alpha = 0.001\nEpoch 500: Train MAE = 1217.1975, Val MAE = 1269.3982\nEpoch 500: Train MAE = 1217.1975, Val MAE = 1269.3982\nEpoch 1000: Train MAE = 1216.7116, Val MAE = 1268.9919\nEpoch 1000: Train MAE = 1216.7116, Val MAE = 1268.9919\nEpoch 1500: Train MAE = 1216.2261, Val MAE = 1268.5873\nEpoch 1500: Train MAE = 1216.2261, Val MAE = 1268.5873\nEpoch 2000: Train MAE = 1215.7407, Val MAE = 1268.1848\n\nTesting alpha = 0.01\nEpoch 2000: Train MAE = 1215.7407, Val MAE = 1268.1848\n\nTesting alpha = 0.01\nEpoch 500: Train MAE = 1217.2068, Val MAE = 1269.3909\nEpoch 500: Train MAE = 1217.2068, Val MAE = 1269.3909\nEpoch 1000: Train MAE = 1216.7332, Val MAE = 1268.9616\nEpoch 1000: Train MAE = 1216.7332, Val MAE = 1268.9616\nEpoch 1500: Train MAE = 1216.2613, Val MAE = 1268.5353\nEpoch 1500: Train MAE = 1216.2613, Val MAE = 1268.5353\nEpoch 2000: Train MAE = 1215.7901, Val MAE = 1268.1114\n\nTesting alpha = 0.1\nEpoch 2000: Train MAE = 1215.7901, Val MAE = 1268.1114\n\nTesting alpha = 0.1\nEpoch 500: Train MAE = 1217.2204, Val MAE = 1269.3513\nEpoch 500: Train MAE = 1217.2204, Val MAE = 1269.3513\nEpoch 1000: Train MAE = 1216.7601, Val MAE = 1268.8937\nEpoch 1000: Train MAE = 1216.7601, Val MAE = 1268.8937\nEpoch 1500: Train MAE = 1216.3023, Val MAE = 1268.4425\nEpoch 1500: Train MAE = 1216.3023, Val MAE = 1268.4425\nEpoch 2000: Train MAE = 1215.8448, Val MAE = 1267.9919\n\nTesting alpha = 1.0\nEpoch 2000: Train MAE = 1215.8448, Val MAE = 1267.9919\n\nTesting alpha = 1.0\nEpoch 500: Train MAE = 1217.2207, Val MAE = 1269.3516\nEpoch 500: Train MAE = 1217.2207, Val MAE = 1269.3516\nEpoch 1000: Train MAE = 1216.7604, Val MAE = 1268.8941\nEpoch 1000: Train MAE = 1216.7604, Val MAE = 1268.8941\nEpoch 1500: Train MAE = 1216.3026, Val MAE = 1268.4428\nEpoch 1500: Train MAE = 1216.3026, Val MAE = 1268.4428\nEpoch 2000: Train MAE = 1215.8451, Val MAE = 1267.9922\n\nBest alpha: 0.1\nBest validation MAE: 1267.9919\nEpoch 2000: Train MAE = 1215.8451, Val MAE = 1267.9922\n\nBest alpha: 0.1\nBest validation MAE: 1267.9919\n\n\n\n\n\n\n\n\n\n\n\n\nFinal MAE Linear Regression Model Evaluation on Test Set:\n=======================================================\nMAE: 1288.54 days\nRMSE: 1798.93 days\nR² Score: -1.0535\n\n\n\n\nRandom Forest Regressor\nRandom Forest Regressor is implemented to predict patient survival time based on the preprocessed BRCA dataset. Design choices include: - Model Choice: Random Forest is selected for its robustness, ability to handle high-dimensional data, and effectiveness in capturing complex interactions between features. - Hyperparameter Tuning: A grid search with cross-validation employed to optimize key hyperparameters such as the number of estimators, maximum depth of the trees, and minimum samples per leaf. - Evaluation Metrics: Model performance evaluated using Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and R-squared (R²) to provide a comprehensive assessment of prediction accuracy.\n\n\nTraining Random Forest Regressor with Hyperparameter Tuning...\n=================================================================\nPerforming hyperparameter tuning with 5-fold cross-validation...\nFitting 5 folds for each of 50 candidates, totalling 250 fits\n\nBest Random Forest Parameters:\n  random_state: 42\n  n_estimators: 300\n  min_samples_split: 5\n  min_samples_leaf: 1\n  max_features: 0.3\n  max_depth: None\n  bootstrap: True\n\nBest Cross-Validation MAE: 755.05\nOut-of-Bag Score (R²): 0.1786\n\nBest Random Forest Parameters:\n  random_state: 42\n  n_estimators: 300\n  min_samples_split: 5\n  min_samples_leaf: 1\n  max_features: 0.3\n  max_depth: None\n  bootstrap: True\n\nBest Cross-Validation MAE: 755.05\nOut-of-Bag Score (R²): 0.1786\n\n\n\n\nEvaluating Random Forest Model on Test Set...\n==================================================\nRandom Forest Model Evaluation on Test Set:\nMAE: 792.40 days\nRMSE: 1156.06 days\nR² Score: 0.1519\n\nFeature Importance Statistics:\nNumber of features with importance &gt; 0.01: 25\nCumulative importance of top 10 features: 0.6256\n\n\n\n\n\n\n\n\n\n\nRandom Forest Model Complexity:\nNumber of trees: 300\nMax depth: None\nTotal number of nodes: 147756\nAverage tree depth: 29.93"
  },
  {
    "objectID": "supervised-learning.html#final-model-comparison-and-analysis",
    "href": "supervised-learning.html#final-model-comparison-and-analysis",
    "title": "Breast (BRCA) Cancer Survival Time (days) Prediction Using Supervised Learning Models",
    "section": "Final Model Comparison and Analysis",
    "text": "Final Model Comparison and Analysis\n\n\n======================================================================\n                    FINAL MODEL COMPARISON\n======================================================================\n\n                     Model          MAE         RMSE            R²\nStandard Linear Regression 7.691527e+12 6.158508e+13 -2.406669e+21\n  Parametric Curve Fitting 1.288540e+03 1.798930e+03 -1.053500e+00\n   Random Forest Regressor 7.924000e+02 1.156060e+03  1.519000e-01\n\n======================================================================\nBEST MODEL: Random Forest Regressor\n   Achieved lowest MAE of 792.4 days\n======================================================================"
  },
  {
    "objectID": "supervised-learning.html#model-selection-1",
    "href": "supervised-learning.html#model-selection-1",
    "title": "Breast (BRCA) Cancer Survival Time (days) Prediction Using Supervised Learning Models",
    "section": "Model Selection",
    "text": "Model Selection\nThe following models will be evaluated for predicting patient survival time based on the preprocessed CESC dataset: 1. Standard Linear Regression: Benchmark model for comparison 2. Random Forest Regressor: For capturing non-linear relationships and interactions between features. 3. Parametric Curve Fitting: With Lasso regularization to prevent overfitting and eliminate potentially redundant features."
  },
  {
    "objectID": "supervised-learning.html#training-and-testing-1",
    "href": "supervised-learning.html#training-and-testing-1",
    "title": "Breast (BRCA) Cancer Survival Time (days) Prediction Using Supervised Learning Models",
    "section": "Training and Testing",
    "text": "Training and Testing\nThe dataset will be split into training and testing sets using an 80-20 split. Cross-validation will be employed during model training to ensure robustness and generalizability of the models.\n\nStandard Linear Regression\n\n\nLinear Regression Model Evaluation on Test Set:\nRMSE: 1268.35\nMAE: 960.32\nR2 Score: -0.8628\n\n\n\n\nParametric Curve Fitting\nWe do a parametric Curve Fitting with L1 regularization (Lasso) to predict patient survival time based on the preprocessed CESC dataset. Design choices include: - Model Choice: Lasso regression is chosen for its ability to perform both variable selection and regularization, which helps enhance the prediction accuracy and interpretability of the statistical model it produces. In addition, early stopping is implemented to prevent overfitting during training. - Hyperparameter Tuning: The regularization parameter (alpha) will be tuned using cross-validation to find the optimal balance between bias and variance. - Evaluation Metrics: Model performance will be evaluated using Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and R-squared (R²) to provide a comprehensive assessment of prediction accuracy. - SGDRegressor is used for optimization due to its efficiency with large datasets and ability to handle L1 regularization effectively.\n\n\nTraining MAE Linear Regression with Lasso Regularization...\n============================================================\n\nTesting alpha = 0.001\nEpoch 500: Train MAE = 1129.6072, Val MAE = 1096.8568\nEpoch 500: Train MAE = 1129.6072, Val MAE = 1096.8568\nEpoch 1000: Train MAE = 1129.0612, Val MAE = 1096.5397\nEpoch 1000: Train MAE = 1129.0612, Val MAE = 1096.5397\nEpoch 1500: Train MAE = 1128.5152, Val MAE = 1096.2226\nEpoch 1500: Train MAE = 1128.5152, Val MAE = 1096.2226\nEpoch 2000: Train MAE = 1127.9692, Val MAE = 1095.9054\n\nTesting alpha = 0.01\nEpoch 500: Train MAE = 1129.6240, Val MAE = 1096.8178\nEpoch 500: Train MAE = 1129.6240, Val MAE = 1096.8178\nEpoch 1000: Train MAE = 1129.0916, Val MAE = 1096.4694\nEpoch 1000: Train MAE = 1129.0916, Val MAE = 1096.4694\nEpoch 1500: Train MAE = 1128.5597, Val MAE = 1096.1201\nEpoch 1500: Train MAE = 1128.5597, Val MAE = 1096.1201\nEpoch 2000: Train MAE = 1128.0280, Val MAE = 1095.7708\n\nTesting alpha = 0.1\nEpoch 2000: Train MAE = 1128.0280, Val MAE = 1095.7708\n\nTesting alpha = 0.1\nEpoch 500: Train MAE = 1129.6547, Val MAE = 1096.6700\nEpoch 500: Train MAE = 1129.6547, Val MAE = 1096.6700\nEpoch 1000: Train MAE = 1129.1546, Val MAE = 1096.1732\nEpoch 1000: Train MAE = 1129.1546, Val MAE = 1096.1732\nEpoch 1500: Train MAE = 1128.6545, Val MAE = 1095.6765\nEpoch 1500: Train MAE = 1128.6545, Val MAE = 1095.6765\nEpoch 2000: Train MAE = 1128.1544, Val MAE = 1095.1798\n\nTesting alpha = 1.0\nEpoch 2000: Train MAE = 1128.1544, Val MAE = 1095.1798\n\nTesting alpha = 1.0\nEpoch 500: Train MAE = 1129.6548, Val MAE = 1096.6667\nEpoch 500: Train MAE = 1129.6548, Val MAE = 1096.6667\nEpoch 1000: Train MAE = 1129.1548, Val MAE = 1096.1667\nEpoch 1000: Train MAE = 1129.1548, Val MAE = 1096.1667\nEpoch 1500: Train MAE = 1128.6548, Val MAE = 1095.6667\nEpoch 1500: Train MAE = 1128.6548, Val MAE = 1095.6667\nEpoch 2000: Train MAE = 1128.1548, Val MAE = 1095.1667\n\nBest alpha: 1.0\nBest validation MAE: 1095.1667\nEpoch 2000: Train MAE = 1128.1548, Val MAE = 1095.1667\n\nBest alpha: 1.0\nBest validation MAE: 1095.1667\n\n\n\n\n\nFinal MAE Linear Regression Model Evaluation on Test Set:\n=======================================================\nMAE: 887.97 days\nRMSE: 1285.33 days\nR² Score: -0.9130\n\n\nRandom Forest Regressor is implemented to predict patient survival time based on the preprocessed CESC dataset. Design choices include: - Model Choice: Random Forest is selected for its robustness, ability to handle high-dimensional data, and effectiveness in capturing complex interactions between features. - Hyperparameter Tuning: A randomized search with cross-validation employed to optimize key hyperparameters such as the number of estimators, maximum depth of the trees, and minimum samples per leaf. - Evaluation Metrics: Model performance evaluated using Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and R-squared (R²) to provide a comprehensive assessment of prediction accuracy.\n\n\nRandom Forest Regressor\n\n\nTraining Random Forest Regressor with Hyperparameter Tuning...\n=================================================================\nPerforming hyperparameter tuning with 5-fold cross-validation...\nFitting 5 folds for each of 50 candidates, totalling 250 fits\n\nBest Random Forest Parameters:\n  random_state: 42\n  n_estimators: 500\n  min_samples_split: 2\n  min_samples_leaf: 2\n  max_features: log2\n  max_depth: 10\n  bootstrap: True\n\nBest Cross-Validation MAE: 709.13\nOut-of-Bag Score (R²): 0.0970\n\nBest Random Forest Parameters:\n  random_state: 42\n  n_estimators: 500\n  min_samples_split: 2\n  min_samples_leaf: 2\n  max_features: log2\n  max_depth: 10\n  bootstrap: True\n\nBest Cross-Validation MAE: 709.13\nOut-of-Bag Score (R²): 0.0970\n\n\n\n\nEvaluating Random Forest Model on Test Set...\n==================================================\nRandom Forest Model Evaluation on Test Set:\nMAE: 730.73 days\nRMSE: 921.17 days\nR² Score: 0.0174\n\nFeature Importance Statistics:\nNumber of features with importance &gt; 0.01: 23\nCumulative importance of top 10 features: 0.6870\nRandom Forest Model Evaluation on Test Set:\nMAE: 730.73 days\nRMSE: 921.17 days\nR² Score: 0.0174\n\nFeature Importance Statistics:\nNumber of features with importance &gt; 0.01: 23\nCumulative importance of top 10 features: 0.6870\n\n\n\n\n\n\n\n\n\n\nRandom Forest Model Complexity:\nNumber of trees: 500\nMax depth: 10\nTotal number of nodes: 24956\nAverage tree depth: 9.30\n\n\n\n\n======================================================================\n                    FINAL MODEL COMPARISON\n======================================================================\n\n                     Model    MAE    RMSE      R²\nStandard Linear Regression 960.32 1268.35 -0.8628\n  Parametric Curve Fitting 887.97 1285.33 -0.9130\n   Random Forest Regressor 730.73  921.17  0.0174\n\n======================================================================\nBEST MODEL: Random Forest Regressor\n   Achieved lowest MAE of 730.73 days\n======================================================================"
  },
  {
    "objectID": "supervised-learning.html#final-model-comparison-and-analysis-1",
    "href": "supervised-learning.html#final-model-comparison-and-analysis-1",
    "title": "Breast (BRCA) Cancer Survival Time (days) Prediction Using Supervised Learning Models",
    "section": "Final Model Comparison and Analysis",
    "text": "Final Model Comparison and Analysis\nRandom Forest Regressor performs best for predicting patient survival time in both BRCA and CESC datasets, demonstrating its effectiveness in handling complex relationships within clinical data. This model consistently outperforms Standard Linear Regression and Parametric Curve Fitting across all evaluation metrics (MAE, RMSE, R²). The ability of Random Forest to capture non-linear interactions and its robustness to overfitting make it a superior choice for this predictive task."
  },
  {
    "objectID": "supervised-learning.html#results-and-insights",
    "href": "supervised-learning.html#results-and-insights",
    "title": "Breast (BRCA) Cancer Survival Time (days) Prediction Using Supervised Learning Models",
    "section": "Results and Insights",
    "text": "Results and Insights\nModeling Findings\nThe survival modeling using Random Forest regressors for both breast cancer (BRCA) and cervical cancer (CESC) provides additional insight into the relative influence of demographic, clinical, and tumor-specific variables on survival time. Across both cancers, the models achieve a mean absolute error (MAE) of under 800 days, indicating that predictions deviate from the true survival time by approximately two years on average. While this may appear large in absolute terms, it is important to contextualize the MAE relative to the observed survival distributions: the BRCA cohort averages 1,324 days of survival, and the CESC cohort averages 1,036 days. Thus, an MAE of &lt;800 days reflects moderate predictive power, consistent with the inherent difficulty of modeling survival solely with clinical variables in heterogeneous cancer populations. The implication is that the models capture broad, directional signals—such as early vs. late-stage disease—but cannot precisely predict patient-level survival due to missing biological, genomic, or treatment response data, a limitation widely noted in survival modeling literature (Moore et al., 2019).\nFeature Importance in Breast Cancer Survival Modeling (BRCA)\nFor breast cancer, the Random Forest model identifies age at diagnosis as the most influential predictor of survival, aligning with exploratory findings and long-established evidence indicating that older patients experience reduced survival due to comorbidity burden and more aggressive tumor biology (Siegel et al., 2023). Treatment counts emerged as the second most important feature, suggesting that patients receiving a greater number of therapies tend to have either more aggressive disease requiring multimodal treatment or more opportunities for therapeutic benefit.\nTumor staging variables—including T stage, overall stage, N stage, and M stage—collectively comprise a substantial proportion of the model’s predictive power, underscoring the clinical reality that anatomical extent of disease remains central to prognosis. Spatial tumor descriptors, such as site of involvement (breast right upper outer), also contribute meaningfully, likely reflecting differential lymphatic drainage patterns and associated metastatic risk.\nTreatment-related variables—particularly radiation therapy and pharmaceutical therapy—rank among the top predictors. Their presence in the top ten suggests that treatment modality type and intensity may partially proxy for tumor aggressiveness or patient fitness for therapy. The top ten BRCA features collectively explain over 60% of the model’s cumulative importance, demonstrating that survival in this cohort is dominated by a relatively concentrated set of clinical factors.\nFeature Importance in Cervical Cancer Survival Modeling (CESC)\nIn the CESC model, FIGO stage is overwhelmingly the strongest predictor of survival, consistent with its central role in cervical cancer staging and treatment decision-making (Arbyn et al., 2020). Higher FIGO stages (e.g., IIB, IIIB, IVA) correlate with markedly poorer outcomes in the EDA, and this relationship is captured quantitatively by the model. Similar to BRCA, age at diagnosis and treatment counts also play major roles, though age behaves differently in CESC, reflecting the dataset-specific survival-age pattern discussed in the exploratory analysis.\nTumor burden and spread variables—T stage, N stage, and M stage—remain key predictors but are secondary to FIGO staging, which already encodes much of the disease extent. Demographic variables, particularly race (Black), enter the top ten, suggesting potential disparities in outcomes that warrant deeper investigation.\nHistopathological descriptors such as tumor grade, primary diagnosis (squamous cell carcinoma), and diagnoses morphology also contribute substantially, consistent with the strong correspondence between tumor differentiation, histologic subtype, and survival in cervical cancer. The top ten CESC features account for over 68% of total model importance, indicating that survival time in this cohort is explained by an even more concentrated set of predictors than in BRCA.\nExposure Variables and Tobacco Use\nDespite tobacco exposure being a known risk factor for developing cervical cancer, smoking-related variables did not appear in the top ten predictive features for CESC survival. This is likely due to the dataset’s distribution: as seen in the EDA, the majority of patients report being lifelong non-smokers, which diminishes the ability of the model to detect meaningful survival differences across exposure categories. Underreporting and missing exposure data may further obscure any true effect (Benard et al., 2019). As a result, the lack of predictive importance should not be interpreted as evidence that tobacco exposure is unrelated to cervical cancer survival, but rather as a limitation of the dataset’s completeness and variability."
  },
  {
    "objectID": "supervised-learning.html#references",
    "href": "supervised-learning.html#references",
    "title": "Breast (BRCA) Cancer Survival Time (days) Prediction Using Supervised Learning Models",
    "section": "References",
    "text": "References\n\nSiegel RL, Miller KD, Fuchs HE, Jemal A. Cancer Statistics, 2023. CA Cancer J Clin. 2023;73(1):17–48.\n\nArbyn M, Weiderpass E, Bruni L, et al. Estimates of incidence and mortality of cervical cancer in 2018: a worldwide analysis. Lancet Glob Health. 2020;8(2):e191–203.\n\nCollaborative Group on Hormonal Factors in Breast Cancer. Breast cancer and hormonal contraceptives: collaborative reanalysis of individual data on 53,297 women with breast cancer and 100,239 women without breast cancer. Lancet. 2002;360:1040–1054.\n\nMoore JX, Akinyemiju T, Lemeshow S. Issues in survival modeling: biases, missing data, and opportunities for advancing prognostic research. Stat Methods Med Res. 2019;28(3):939–953.\n\nBenard VB, Thomas CC, King J, et al. Vital signs: cervical cancer incidence, mortality, and screening — United States, 2007–2012. MMWR Morb Mortal Wkly Rep. 2019;68(15):355–360."
  },
  {
    "objectID": "technical-details/data-collection/main.html",
    "href": "technical-details/data-collection/main.html",
    "title": "Data Collection",
    "section": "",
    "text": "The data used in this project were obtained from the National Cancer Institute (NCI) Genomic Data Commons (GDC)1, a centralized repository designed to support cancer research by providing harmonized clinical, genomic, and exposure-related data across multiple cancer types. The GDC integrates data from large-scale initiatives such as The Cancer Genome Atlas (TCGA)2 and applies standardized data models, vocabularies, and quality control procedures to ensure consistency and reproducibility across studies.\n{alt = “National Cancer Institute Genomic Data Commons home page”}\n\n\n\nFor this analysis, we focused on two TCGA cohorts: Breast Invasive Carcinoma (TCGA-BRCA) and Cervical Squamous Cell Carcinoma and Endocervical Adenocarcinoma (TCGA-CESC). These datasets were selected to enable comparative analysis of two common cancers affecting women, while allowing investigation into differences in tumor characteristics, treatment patterns, and survival outcomes.\nClinical data were downloaded from the GDC Data Portal in tabular format (clinical.tsv and related files), which aggregate information across several hierarchical entities, including cases, demographic, diagnoses, treatments, and exposures. Variables include patient-level demographics (e.g., age at diagnosis, race, vital status), tumor-specific characteristics (e.g., stage, grade, morphology), treatment indicators (e.g., treatment type), and outcome-related fields (e.g., days to last follow-up). All time-to-event variables in the GDC are reported in days, indexed relative to clinically meaningful anchor points such as diagnosis or enrollment dates.\n{alt = “National Cancer Institute Genomic Data Commons data download page”}\n\n\n\nImportantly, the GDC data are de-identified to protect patient privacy, and certain variables may be obfuscated or missing by design. For example, ages above a threshold may be masked, dates may be offset, and exposure variables such as smoking status may be underreported. Additionally, patients may have multiple rows per case, reflecting repeated diagnoses, treatments, or follow-up events, necessitating aggregation and careful preprocessing prior to modeling.\n#| echo: false\n#| warning: false\n#| tbl-cap: Rows showing a unique patient (cases.submitter_id) and their different treatments for breast cancer\nimport pandas as pd\n\n# Import dataset\nbrca_df = pd.read_csv(\"../../data/raw-data/brca/brca-clinical.tsv\", sep=\"\\t\")\n\n# Show rows for patient TCGA-E2-A1IU with selected columns\npatient_data = brca_df[brca_df[\"cases.submitter_id\"] == \"TCGA-E2-A1IU\"]\ncolumns_to_show = [\"cases.submitter_id\", \"treatments.treatment_type\", \n                   \"treatments.treatment_intent_type\", \"demographic.vital_status\",\n                   \"diagnoses.ajcc_pathologic_stage\"]\npatient_data[columns_to_show]\n\n\n\n\nWhile TCGA cohorts are not fully representative of the general U.S. population, they remain one of the most comprehensive publicly available cancer datasets, widely used in both biomedical and data science research. The use of GDC data enables reproducible analysis while providing sufficient clinical depth to explore survival patterns and predictive modeling across cancer types.\nOur raw data can be found in our repository here, including a data dictionary.\nAs of 11/05/2025, - the clinical breast cancer dataset originally has 5546 rows and 210 columns representing 1098 patients - the clinical cervical cancer dataset originally has 1535 rows and 210 columns representing 307 patients"
  },
  {
    "objectID": "technical-details/data-collection/main.html#suggested-page-structure",
    "href": "technical-details/data-collection/main.html#suggested-page-structure",
    "title": "Data Collection",
    "section": "",
    "text": "Here’s one suggested structure for organizing your technical pages. You can adjust this as needed:\nAudience:Remember that these are written for a technical audience. Assume they have completed the DSAN program, but would appreciate refreshers of the important concepts.\n\nIntroduction and Motivation: Briefly outline your plan. What are you doing on this page, and why? Provide context and explain the goals of your analysis.\nOverview of Methods: Give a concise explanation of the methods used. For example, if using K-Means clustering, describe what it is, how it works, the inputs and outputs, and key hyperparameters.\nCode: Include the code you used to implement your workflow.\nSummary and Interpretation of Results: Summarize your findings, interpret the results, and discuss their technical implications.\n\nIn the provide repo, these subsections have been included in the data-collection file as separate .qmd files that can be embedded using the {{&lt; include &gt;}} tag."
  },
  {
    "objectID": "technical-details/data-collection/main.html#what-to-address",
    "href": "technical-details/data-collection/main.html#what-to-address",
    "title": "Data Collection",
    "section": "",
    "text": "The following is a list of some of the things you should address on this page. This list is not exhaustive, and you should use your judgment to decide what is most relevant to your project.\nOn this page, you will focus on data collection, which is an essential step for future analysis. You should have already selected a specific data-science question that can be addressed in a data-driven way.\nIt is recommended that you focus on one or two of the following data formats, text, tabular, image, geospatial, or network data.\nTabular (e.g. CSV files) and text formats are highly recommended, as these are covered most thoroughly in the course. Deviating from these formats may require additional work on your end. Please avoid timeseries data formats, as these require special methods not covered in the course. You can include as many additional formats as you want. Your project will revolve around the data you gather and will include data collection, analysis, visualization, and storytelling."
  },
  {
    "objectID": "technical-details/data-collection/main.html#start-collecting-data",
    "href": "technical-details/data-collection/main.html#start-collecting-data",
    "title": "Data Collection",
    "section": "",
    "text": "Begin gathering your data and document the methods and sources on the Data Collection page of your project. Include screenshots or example tables to illustrate the data collection process without displaying entire datasets. Ensure transparency so anyone can replicate your work."
  },
  {
    "objectID": "technical-details/data-collection/main.html#saving-the-raw-data",
    "href": "technical-details/data-collection/main.html#saving-the-raw-data",
    "title": "Data Collection",
    "section": "",
    "text": "During the collection phase, save the collected data locally to the data/raw-data folder, in the root of the project, for later processing. (Do not sync this folder to GitHub.)\nRemember, the “raw data” should typically be left “pristine”, to ensure replicability.\nLater when you clean the data, you should save the cleaned data to the data/processed-data folder, in the root of the project.\nYou should also save files you download manually from online to this folder"
  },
  {
    "objectID": "technical-details/data-collection/main.html#requirements",
    "href": "technical-details/data-collection/main.html#requirements",
    "title": "Data Collection",
    "section": "",
    "text": "Your data must be relevant to the project’s overall goals and help solve your research questions.\nYou must use at least one API to collect your data.\nEnsure you have at least one regression target: a continuous quantity that can be used for regression prediction with other features.\nEnsure you have at least one binary classification target: a two-class (A,B) label that can be predicted using other features.\nEnsure you have at least one multiclass-classification target: a multi-class (A,B,C …) label that can be predicted using other features.\nDo not use a Kaggle topic—this project is meant to simulate a real-world project. Kaggle datasets are typically too clean and have already been prepped for analysis, which doesn’t align with the project’s goals.\n\nFocus on data that tells a compelling story and supports the techniques covered in the class (e.g., clustering, classification, regression)."
  },
  {
    "objectID": "technical-details/data-collection/main.html#example",
    "href": "technical-details/data-collection/main.html#example",
    "title": "Data Collection",
    "section": "Example",
    "text": "Example\nIn the following code, we first utilized the requests library to retrieve the HTML content from the Wikipedia page. Afterward, we employed BeautifulSoup to parse the HTML and locate the specific table of interest by using the find function. Once the table was identified, we extracted the relevant data by iterating through its rows, gathering country names and their respective populations. Finally, we used Pandas to store the collected data in a DataFrame, allowing for easy analysis and visualization. The data could also be optionally saved as a CSV file for further use.\n\nimport requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\n# Step 1: Send a request to Wikipedia page\nurl = 'https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population'\nresponse = requests.get(url)\n\n# Step 2: Parse the page content using BeautifulSoup\nsoup = BeautifulSoup(response.content, 'html.parser')\n\n# Step 3: Find the table containing the data (usually the first table for such lists)\ntable = soup.find('table', {'class': 'wikitable'})\n\n# Step 4: Extract data from the table rows\ncountries = []\npopulations = []\n\n# Iterate over the table rows\nfor row in table.find_all('tr')[1:]:  # Skip the header row\n    cells = row.find_all('td')\n    if len(cells) &gt; 1:\n        country = cells[1].text.strip()  # The country name is in the second column\n        population = cells[2].text.strip()  # The population is in the third column\n        countries.append(country)\n        populations.append(population)\n\n# Step 5: Create a DataFrame to store the results\ndata = pd.DataFrame({\n    'Country': countries,\n    'Population': populations\n})\n\n# Display the scraped data\nprint(data)\n\n# Optionally save to CSV\ndata.to_csv('../../data/raw-data/countries_population.csv', index=False)\n\n                                 Country     Population\n0                                  World  8,119,000,000\n1                                  China  1,409,670,000\n2                          1,404,910,000          17.3%\n3                          United States    335,893,238\n4                              Indonesia    281,603,800\n..                                   ...            ...\n235                   Niue (New Zealand)          1,681\n236                Tokelau (New Zealand)          1,647\n237                         Vatican City            764\n238  Cocos (Keeling) Islands (Australia)            593\n239                Pitcairn Islands (UK)             35\n\n[240 rows x 2 columns]"
  },
  {
    "objectID": "technical-details/data-collection/main.html#challenges",
    "href": "technical-details/data-collection/main.html#challenges",
    "title": "Data Collection",
    "section": "Challenges",
    "text": "Challenges\n\nDiscuss any technical challenges faced during the project, such as data limitations, computational issues, or obstacles encountered during analysis.\nExplain unexpected results and their technical implications.\nIdentify areas for future work, including potential optimizations, further analysis, or scaling solutions."
  },
  {
    "objectID": "technical-details/data-collection/main.html#benchmarks",
    "href": "technical-details/data-collection/main.html#benchmarks",
    "title": "Data Collection",
    "section": "Benchmarks",
    "text": "Benchmarks\n\nCompare your findings to relevant research, industry benchmarks, or intuitive expectations, if applicable."
  },
  {
    "objectID": "technical-details/data-collection/main.html#conclusion-and-future-steps",
    "href": "technical-details/data-collection/main.html#conclusion-and-future-steps",
    "title": "Data Collection",
    "section": "Conclusion and Future Steps",
    "text": "Conclusion and Future Steps\n\nSummarize the key technical points and outcomes of the project.\nSuggest potential improvements or refinements to this part of the project.\nBased on the results, provide actionable recommendations for further research or optimization efforts."
  },
  {
    "objectID": "technical-details/supervised-learning/main.html",
    "href": "technical-details/supervised-learning/main.html",
    "title": "Supervised Learning",
    "section": "",
    "text": "We had preserved multiple rows from the same patient to track treatments recevied during exploratory data analysis.\n\n\n\n\n\n\nFirst two rows of the eda BRCA clinical dataset\n\n\n\nproject.project_id\ncases.case_id\ncases.disease_type\ncases.index_date\ncases.primary_site\ncases.submitter_id\ndemographic.age_is_obfuscated\ndemographic.days_to_death\ndemographic.ethnicity\ndemographic.gender\ndemographic.race\ndemographic.submitter_id\ndemographic.vital_status\ndiagnoses.age_at_diagnosis\ndiagnoses.ajcc_pathologic_m\ndiagnoses.ajcc_pathologic_n\ndiagnoses.ajcc_pathologic_stage\ndiagnoses.ajcc_pathologic_t\ndiagnoses.classification_of_tumor\ndiagnoses.days_to_diagnosis\ndiagnoses.days_to_last_follow_up\ndiagnoses.diagnosis_is_primary_disease\ndiagnoses.laterality\ndiagnoses.method_of_diagnosis\ndiagnoses.morphology\ndiagnoses.primary_diagnosis\ndiagnoses.prior_malignancy\ndiagnoses.prior_treatment\ndiagnoses.site_of_resection_or_biopsy\ndiagnoses.sites_of_involvement\ndiagnoses.submitter_id\ndiagnoses.synchronous_malignancy\ndiagnoses.tissue_or_organ_of_origin\ntreatments.submitter_id\ntreatments.treatment_or_therapy\ntreatments.treatment_type\nsurvival_time_days\ndiagnoses.behavior\n\n\n\n\n0\ntcga-brca\n001cef41-ff86-4d3f-a140-a647ac4b10a1\nductal and lobular neoplasms\ndiagnosis\nbreast\ntcga-e2-a1iu\nFalse\nNaN\nnot hispanic or latino\nfemale\nwhite\ntcga-e2-a1iu_demographic\nalive\n60.0\nm0\nn0 (mol+)\nstage ia\nt1c\nprimary\n0\n337.0\nTrue\nright\nsurgical resection\n8500/3\ninfiltrating duct carcinoma, nos\nFalse\nFalse\nbreast, nos\nbreast, right upper outer\ntcga-e2-a1iu_diagnosis\nFalse\nbreast, nos\ntcga-e2-a1iu_treatment2\nFalse\nradiation therapy, nos\n337.0\nmalignant\n\n\n1\ntcga-brca\n001cef41-ff86-4d3f-a140-a647ac4b10a1\nductal and lobular neoplasms\ndiagnosis\nbreast\ntcga-e2-a1iu\nFalse\nNaN\nnot hispanic or latino\nfemale\nwhite\ntcga-e2-a1iu_demographic\nalive\n60.0\nm0\nn0 (mol+)\nstage ia\nt1c\nprimary\n0\n337.0\nTrue\nright\nsurgical resection\n8500/3\ninfiltrating duct carcinoma, nos\nFalse\nFalse\nbreast, nos\nbreast, right upper outer\ntcga-e2-a1iu_diagnosis\nFalse\nbreast, nos\ntcga-e2-a1iu_treatment\nTrue\nhormone therapy\n337.0\nmalignant\n\n\n\n\n\n\n\nHowever, for supervised learning, this could lead to data leakage during model training and evaluation. To mitigate this, we implemented a preprocessing step to retain only one record per patient. We selected the most recent record for each patient who received treatment, and created a column treatment.count to captuure the effect of multiple treatments a patient received.\n\n\n\nAfter deduplication:\nDeduplicated dataset shape: (1081, 39)\nUnique cases.submitter_id: 1081\nRows removed: 3815\n\nTreatment distribution in deduplicated data:\ntreatments.treatment_or_therapy\nTrue     1076\nFalse       5\nName: count, dtype: int64\n\nFinal BRCA dataset shape: (1081, 39)\n\n\nOur next step involved feature selection to enhance model performance and interpretability. We focused on removing non-informative features that exhibited low variance across the dataset. Features with little to no variability do not contribute meaningful information for predicting survival time and can introduce noise into the model.\nRemove Non-informative Features: Exclude features with low variance e.g., behavior of the tumor is malignant for all samples. Dropped features:\n\nproject_id: represents the project and is constant for all samples.\ncase_id: unique identifier for each case, not useful for prediction.\nsubmitter_id: unique identifier for each submitter, not useful for prediction.\nprimary_site: all samples are from the breast, so this feature has no variance.\nindex_date: date of indexing, not relevant for prediction.\nage_is_obfuscated: flag indicating if age is obfuscated, not useful for prediction.\ndays_to_death: not applicable for all samples, leading to missing values.\nethnicity: heavy imbalance to not hispanic or latino (over 80% of samples), leading to low variance. Race might capture the variance better.\ngender: all samples are female, so this feature has no variance\nclassification_of_tumor: all samples are primary, so this feature has no variance.\ndays_to_diagnosis: 0 for all samples, so this feature has no variance.\ndays_to _last_follow_up: not applicable for all samples, leading to missing values.\nvital_status: does not make sense to predict survival time based on whether the patient is alive or dead at last follow-up.\nlaterality: research indicates no significant difference in breast cancer outcomes based on laterality. Dataset does not show imbalance in laterality distribution.\ndiagnoses.prior_treatment: heavy imbalance to false (97% of samples), leading to low variance. Assuming number of treatments is more informative.\nsite_of_resection_or_biopsy: all samples are from the breast, so this feature has no variance. Specific location within the breast (sites_of_involvement) may provide more detailed information.\nsynchronous_malignancy: heavy imbalance to false (&gt; 97%), so this feature has no variance.\ntreatments.submitter_id: unique identifier for each submitter, not useful for prediction.\ntreatments_or_therapy: Heavy imbalance to true as most patients receive treatment, so this feature has low variance. Specific treatment types may provide more information.\ndiagnoses.diagnosis_is_primary_disease: all samples are primary, so this feature has no variance.\ndiagnoses.method_of_diagnosis: Not informative to how long a patient survives. The primary diagnosis might be more relevant.\n\n\n\nOriginal dataset shape: (1081, 39)\nCleaned dataset shape: (1081, 14)\nColumns removed: 25\n\n\nLastly, we prepared the data for modeling by applying appropriate transformations to different types of variables:\n\nNormalization: Numerical columns age_at_diagnosis and treatments.count normalized using Min-Max scaling.\nBoolean Variables: Converted boolean variables to integers (0 and 1) for model compatibility, vital status to 1 for alive\nOrdinal Categorical Variables: Used Ordinal Encoding for features with an inherent order (e.g., tumor_stage).\nEncoding Categorical Variables: Categorical variables were be encoded using One-Hot Encoding to convert them into a format suitable for machine learning algorithms.\n\nAJCC Cancer Staging Has a Natural Order\nStage I → Stage II → Stage III → Stage IV Earlier = less severe → later = more severe.\nWithin each major stage, letters (A, B, C) represent increasing severity, e.g.:\nI &lt; IA &lt; IB &lt; II &lt; IIA &lt; IIB &lt; III &lt; IIIA &lt; IIIB &lt; IIIC &lt; IV\nT = primary tumor size AND local extent of invasion\nThe N (nodes) category in the TNM system describes regional lymph node involvement:\nThe M (metastasis) part of TNM describes presence of distant metastasis.\n\n\n\nThe following models were evaluated for predicting patient survival time based on the preprocessed BRCA dataset: 1. Standard Linear Regression: Benchmark model for comparison 2. Regression Trees: XGBoost Regressor for capturing non-linear relationships and interactions between features. 3. Parametric Linear Regression: With Lasso regularization to prevent overfitting and eliminate potentially redundant features.\n\n\n\nThe dataset was split into training and testing sets using an 80-20 split. Cross-validation was employed during model training to ensure robustness and generalizability of the models.\n\n\n\n\nLinear Regression Model Evaluation on Test Set:\nRMSE: 61585077470726.38\nMAE: 7691527358667.03\nR2 Score: -2406669127225213190144.0000\n\n\n\n\n\nWe do a parametric Curve Fitting with L1 regularization (Lasso) to predict patient survival time based on the preprocessed BRCA dataset. Design choicces include: - Model Choice: Lasso regression is chosen for its ability to perform both variable selection and regularization, which helps enhance the prediction accuracy and interpretability of the statistical model it produces. In addition, early stopping is implemented to prevent overfitting during training. - Hyperparameter Tuning: The regularization parameter (alpha) tuned using cross-validation to find the optimal balance between bias and variance. - Evaluation Metrics: Model performance was evaluated using Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and R-squared (R²) to provide a comprehensive assessment of prediction accuracy. - SGDRegressor is used for optimization due to its efficiency with large datasets and ability to handle L1 regularization effectively.\n\n\nTraining MAE Linear Regression with Lasso Regularization...\n============================================================\n\nTesting alpha = 0.001\nEpoch 500: Train MAE = 1217.1975, Val MAE = 1269.3982\nEpoch 500: Train MAE = 1217.1975, Val MAE = 1269.3982\nEpoch 1000: Train MAE = 1216.7116, Val MAE = 1268.9919\nEpoch 1000: Train MAE = 1216.7116, Val MAE = 1268.9919\nEpoch 1500: Train MAE = 1216.2261, Val MAE = 1268.5873\nEpoch 1500: Train MAE = 1216.2261, Val MAE = 1268.5873\nEpoch 2000: Train MAE = 1215.7407, Val MAE = 1268.1848\n\nTesting alpha = 0.01\nEpoch 2000: Train MAE = 1215.7407, Val MAE = 1268.1848\n\nTesting alpha = 0.01\nEpoch 500: Train MAE = 1217.2068, Val MAE = 1269.3909\nEpoch 500: Train MAE = 1217.2068, Val MAE = 1269.3909\nEpoch 1000: Train MAE = 1216.7332, Val MAE = 1268.9616\nEpoch 1000: Train MAE = 1216.7332, Val MAE = 1268.9616\nEpoch 1500: Train MAE = 1216.2613, Val MAE = 1268.5353\nEpoch 1500: Train MAE = 1216.2613, Val MAE = 1268.5353\nEpoch 2000: Train MAE = 1215.7901, Val MAE = 1268.1114\n\nTesting alpha = 0.1\nEpoch 2000: Train MAE = 1215.7901, Val MAE = 1268.1114\n\nTesting alpha = 0.1\nEpoch 500: Train MAE = 1217.2204, Val MAE = 1269.3513\nEpoch 500: Train MAE = 1217.2204, Val MAE = 1269.3513\nEpoch 1000: Train MAE = 1216.7601, Val MAE = 1268.8937\nEpoch 1000: Train MAE = 1216.7601, Val MAE = 1268.8937\nEpoch 1500: Train MAE = 1216.3023, Val MAE = 1268.4425\nEpoch 1500: Train MAE = 1216.3023, Val MAE = 1268.4425\nEpoch 2000: Train MAE = 1215.8448, Val MAE = 1267.9919\n\nTesting alpha = 1.0\nEpoch 2000: Train MAE = 1215.8448, Val MAE = 1267.9919\n\nTesting alpha = 1.0\nEpoch 500: Train MAE = 1217.2207, Val MAE = 1269.3516\nEpoch 500: Train MAE = 1217.2207, Val MAE = 1269.3516\nEpoch 1000: Train MAE = 1216.7604, Val MAE = 1268.8941\nEpoch 1000: Train MAE = 1216.7604, Val MAE = 1268.8941\nEpoch 1500: Train MAE = 1216.3026, Val MAE = 1268.4428\nEpoch 1500: Train MAE = 1216.3026, Val MAE = 1268.4428\nEpoch 2000: Train MAE = 1215.8451, Val MAE = 1267.9922\n\nBest alpha: 0.1\nBest validation MAE: 1267.9919\nEpoch 2000: Train MAE = 1215.8451, Val MAE = 1267.9922\n\nBest alpha: 0.1\nBest validation MAE: 1267.9919\n\n\n\n\n\n\n\n\n\n\n\n\nFinal MAE Linear Regression Model Evaluation on Test Set:\n=======================================================\nMAE: 1288.54 days\nRMSE: 1798.93 days\nR² Score: -1.0535\n\n\n\n\n\nRandom Forest Regressor is implemented to predict patient survival time based on the preprocessed BRCA dataset. Design choices include: - Model Choice: Random Forest is selected for its robustness, ability to handle high-dimensional data, and effectiveness in capturing complex interactions between features. - Hyperparameter Tuning: A grid search with cross-validation employed to optimize key hyperparameters such as the number of estimators, maximum depth of the trees, and minimum samples per leaf. - Evaluation Metrics: Model performance evaluated using Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and R-squared (R²) to provide a comprehensive assessment of prediction accuracy.\n\n\nTraining Random Forest Regressor with Hyperparameter Tuning...\n=================================================================\nPerforming hyperparameter tuning with 5-fold cross-validation...\nFitting 5 folds for each of 50 candidates, totalling 250 fits\n\nBest Random Forest Parameters:\n  random_state: 42\n  n_estimators: 300\n  min_samples_split: 5\n  min_samples_leaf: 1\n  max_features: 0.3\n  max_depth: None\n  bootstrap: True\n\nBest Cross-Validation MAE: 755.05\nOut-of-Bag Score (R²): 0.1786\n\nBest Random Forest Parameters:\n  random_state: 42\n  n_estimators: 300\n  min_samples_split: 5\n  min_samples_leaf: 1\n  max_features: 0.3\n  max_depth: None\n  bootstrap: True\n\nBest Cross-Validation MAE: 755.05\nOut-of-Bag Score (R²): 0.1786\n\n\n\n\nEvaluating Random Forest Model on Test Set...\n==================================================\nRandom Forest Model Evaluation on Test Set:\nMAE: 792.40 days\nRMSE: 1156.06 days\nR² Score: 0.1519\n\nFeature Importance Statistics:\nNumber of features with importance &gt; 0.01: 25\nCumulative importance of top 10 features: 0.6256\n\n\n\n\n\n\n\n\n\n\nRandom Forest Model Complexity:\nNumber of trees: 300\nMax depth: None\nTotal number of nodes: 147756\nAverage tree depth: 29.93\n\n\n\n\n\n\n\n\n======================================================================\n                    FINAL MODEL COMPARISON\n======================================================================\n\n                     Model          MAE         RMSE            R²\nStandard Linear Regression 7.691527e+12 6.158508e+13 -2.406669e+21\n  Parametric Curve Fitting 1.288540e+03 1.798930e+03 -1.053500e+00\n   Random Forest Regressor 7.924000e+02 1.156060e+03  1.519000e-01\n\n======================================================================\nBEST MODEL: Random Forest Regressor\n   Achieved lowest MAE of 792.4 days\n======================================================================"
  },
  {
    "objectID": "technical-details/supervised-learning/main.html#suggested-page-structure",
    "href": "technical-details/supervised-learning/main.html#suggested-page-structure",
    "title": "Supervised Learning",
    "section": "",
    "text": "Here’s one suggested structure for organizing your technical pages. You can adjust this as needed:\nAudience:Remember that these are written for a technical audience. Assume they have completed the DSAN program, but would appreciate refreshers of the important concepts.\n\nIntroduction and Motivation: Briefly outline your plan. What are you doing on this page, and why? Provide context and explain the goals of your analysis.\nOverview of Methods: Give a concise explanation of the methods used. For example, if using K-Means clustering, describe what it is, how it works, the inputs and outputs, and key hyperparameters.\nCode: Include the code you used to implement your workflow.\nSummary and Interpretation of Results: Summarize your findings, interpret the results, and discuss their technical implications."
  },
  {
    "objectID": "technical-details/supervised-learning/main.html#what-to-address",
    "href": "technical-details/supervised-learning/main.html#what-to-address",
    "title": "Supervised Learning",
    "section": "",
    "text": "The following is a list of some of the things you should address on this page. This list is not exhaustive, and you should use your judgment to decide what is most relevant to your project.\nPlease do some form of “Feature selection” in your project and include a section on it. Discuss the process you went through to select the features that you used in your model, this should be done for both classification models and regression models. What did you include and why? What did you exclude? What was the reasoning behind your decisions? This section can be included here, or you can make a new page in the dropdown menu for it.\nPlease break this page into a “regression” section, “binary classification” section, and a “Multi-class classification” section. For each case you should try multiple methods, including those discussed in class, and compare and contrast their preformance and results."
  },
  {
    "objectID": "technical-details/supervised-learning/main.html#data-preprocessing",
    "href": "technical-details/supervised-learning/main.html#data-preprocessing",
    "title": "Supervised Learning",
    "section": "",
    "text": "We had preserved multiple rows from the same patient to track treatments recevied during exploratory data analysis.\n\n\n\n\n\n\nFirst two rows of the eda BRCA clinical dataset\n\n\n\nproject.project_id\ncases.case_id\ncases.disease_type\ncases.index_date\ncases.primary_site\ncases.submitter_id\ndemographic.age_is_obfuscated\ndemographic.days_to_death\ndemographic.ethnicity\ndemographic.gender\ndemographic.race\ndemographic.submitter_id\ndemographic.vital_status\ndiagnoses.age_at_diagnosis\ndiagnoses.ajcc_pathologic_m\ndiagnoses.ajcc_pathologic_n\ndiagnoses.ajcc_pathologic_stage\ndiagnoses.ajcc_pathologic_t\ndiagnoses.classification_of_tumor\ndiagnoses.days_to_diagnosis\ndiagnoses.days_to_last_follow_up\ndiagnoses.diagnosis_is_primary_disease\ndiagnoses.laterality\ndiagnoses.method_of_diagnosis\ndiagnoses.morphology\ndiagnoses.primary_diagnosis\ndiagnoses.prior_malignancy\ndiagnoses.prior_treatment\ndiagnoses.site_of_resection_or_biopsy\ndiagnoses.sites_of_involvement\ndiagnoses.submitter_id\ndiagnoses.synchronous_malignancy\ndiagnoses.tissue_or_organ_of_origin\ntreatments.submitter_id\ntreatments.treatment_or_therapy\ntreatments.treatment_type\nsurvival_time_days\ndiagnoses.behavior\n\n\n\n\n0\ntcga-brca\n001cef41-ff86-4d3f-a140-a647ac4b10a1\nductal and lobular neoplasms\ndiagnosis\nbreast\ntcga-e2-a1iu\nFalse\nNaN\nnot hispanic or latino\nfemale\nwhite\ntcga-e2-a1iu_demographic\nalive\n60.0\nm0\nn0 (mol+)\nstage ia\nt1c\nprimary\n0\n337.0\nTrue\nright\nsurgical resection\n8500/3\ninfiltrating duct carcinoma, nos\nFalse\nFalse\nbreast, nos\nbreast, right upper outer\ntcga-e2-a1iu_diagnosis\nFalse\nbreast, nos\ntcga-e2-a1iu_treatment2\nFalse\nradiation therapy, nos\n337.0\nmalignant\n\n\n1\ntcga-brca\n001cef41-ff86-4d3f-a140-a647ac4b10a1\nductal and lobular neoplasms\ndiagnosis\nbreast\ntcga-e2-a1iu\nFalse\nNaN\nnot hispanic or latino\nfemale\nwhite\ntcga-e2-a1iu_demographic\nalive\n60.0\nm0\nn0 (mol+)\nstage ia\nt1c\nprimary\n0\n337.0\nTrue\nright\nsurgical resection\n8500/3\ninfiltrating duct carcinoma, nos\nFalse\nFalse\nbreast, nos\nbreast, right upper outer\ntcga-e2-a1iu_diagnosis\nFalse\nbreast, nos\ntcga-e2-a1iu_treatment\nTrue\nhormone therapy\n337.0\nmalignant\n\n\n\n\n\n\n\nHowever, for supervised learning, this could lead to data leakage during model training and evaluation. To mitigate this, we implemented a preprocessing step to retain only one record per patient. We selected the most recent record for each patient who received treatment, and created a column treatment.count to captuure the effect of multiple treatments a patient received.\n\n\n\nAfter deduplication:\nDeduplicated dataset shape: (1081, 39)\nUnique cases.submitter_id: 1081\nRows removed: 3815\n\nTreatment distribution in deduplicated data:\ntreatments.treatment_or_therapy\nTrue     1076\nFalse       5\nName: count, dtype: int64\n\nFinal BRCA dataset shape: (1081, 39)\n\n\nOur next step involved feature selection to enhance model performance and interpretability. We focused on removing non-informative features that exhibited low variance across the dataset. Features with little to no variability do not contribute meaningful information for predicting survival time and can introduce noise into the model.\nRemove Non-informative Features: Exclude features with low variance e.g., behavior of the tumor is malignant for all samples. Dropped features:\n\nproject_id: represents the project and is constant for all samples.\ncase_id: unique identifier for each case, not useful for prediction.\nsubmitter_id: unique identifier for each submitter, not useful for prediction.\nprimary_site: all samples are from the breast, so this feature has no variance.\nindex_date: date of indexing, not relevant for prediction.\nage_is_obfuscated: flag indicating if age is obfuscated, not useful for prediction.\ndays_to_death: not applicable for all samples, leading to missing values.\nethnicity: heavy imbalance to not hispanic or latino (over 80% of samples), leading to low variance. Race might capture the variance better.\ngender: all samples are female, so this feature has no variance\nclassification_of_tumor: all samples are primary, so this feature has no variance.\ndays_to_diagnosis: 0 for all samples, so this feature has no variance.\ndays_to _last_follow_up: not applicable for all samples, leading to missing values.\nvital_status: does not make sense to predict survival time based on whether the patient is alive or dead at last follow-up.\nlaterality: research indicates no significant difference in breast cancer outcomes based on laterality. Dataset does not show imbalance in laterality distribution.\ndiagnoses.prior_treatment: heavy imbalance to false (97% of samples), leading to low variance. Assuming number of treatments is more informative.\nsite_of_resection_or_biopsy: all samples are from the breast, so this feature has no variance. Specific location within the breast (sites_of_involvement) may provide more detailed information.\nsynchronous_malignancy: heavy imbalance to false (&gt; 97%), so this feature has no variance.\ntreatments.submitter_id: unique identifier for each submitter, not useful for prediction.\ntreatments_or_therapy: Heavy imbalance to true as most patients receive treatment, so this feature has low variance. Specific treatment types may provide more information.\ndiagnoses.diagnosis_is_primary_disease: all samples are primary, so this feature has no variance.\ndiagnoses.method_of_diagnosis: Not informative to how long a patient survives. The primary diagnosis might be more relevant.\n\n\n\nOriginal dataset shape: (1081, 39)\nCleaned dataset shape: (1081, 14)\nColumns removed: 25\n\n\nLastly, we prepared the data for modeling by applying appropriate transformations to different types of variables:\n\nNormalization: Numerical columns age_at_diagnosis and treatments.count normalized using Min-Max scaling.\nBoolean Variables: Converted boolean variables to integers (0 and 1) for model compatibility, vital status to 1 for alive\nOrdinal Categorical Variables: Used Ordinal Encoding for features with an inherent order (e.g., tumor_stage).\nEncoding Categorical Variables: Categorical variables were be encoded using One-Hot Encoding to convert them into a format suitable for machine learning algorithms.\n\nAJCC Cancer Staging Has a Natural Order\nStage I → Stage II → Stage III → Stage IV Earlier = less severe → later = more severe.\nWithin each major stage, letters (A, B, C) represent increasing severity, e.g.:\nI &lt; IA &lt; IB &lt; II &lt; IIA &lt; IIB &lt; III &lt; IIIA &lt; IIIB &lt; IIIC &lt; IV\nT = primary tumor size AND local extent of invasion\nThe N (nodes) category in the TNM system describes regional lymph node involvement:\nThe M (metastasis) part of TNM describes presence of distant metastasis."
  },
  {
    "objectID": "technical-details/supervised-learning/main.html#model-selection",
    "href": "technical-details/supervised-learning/main.html#model-selection",
    "title": "Supervised Learning",
    "section": "",
    "text": "The following models were evaluated for predicting patient survival time based on the preprocessed BRCA dataset: 1. Standard Linear Regression: Benchmark model for comparison 2. Regression Trees: XGBoost Regressor for capturing non-linear relationships and interactions between features. 3. Parametric Linear Regression: With Lasso regularization to prevent overfitting and eliminate potentially redundant features."
  },
  {
    "objectID": "technical-details/supervised-learning/main.html#training-and-testing-strategy",
    "href": "technical-details/supervised-learning/main.html#training-and-testing-strategy",
    "title": "Supervised Learning",
    "section": "",
    "text": "Split Methods: Detail the splitting methods used (e.g., train-test split, cross-validation).\nDataset Proportions: Specify the proportions used for splitting the dataset."
  },
  {
    "objectID": "technical-details/supervised-learning/main.html#model-evaluation-metrics",
    "href": "technical-details/supervised-learning/main.html#model-evaluation-metrics",
    "title": "Supervised Learning",
    "section": "",
    "text": "Binary Classification Metrics: Discuss metrics such as accuracy, precision, recall, F1 score, and ROC-AUC.\nMulticlass Classification Metrics: Include metrics such as confusion matrix and macro/micro F1 score.\nRegression Metrics: Explain metrics such as RMSE, MAE, and R-squared, parity plots, etc."
  },
  {
    "objectID": "technical-details/supervised-learning/main.html#results",
    "href": "technical-details/supervised-learning/main.html#results",
    "title": "Supervised Learning",
    "section": "",
    "text": "Model Performance Summary: Provide a summary of the model’s performance.\nVisualizations: Include visualizations of results (e.g., ROC curves, feature importance plots)."
  },
  {
    "objectID": "technical-details/supervised-learning/main.html#discussion",
    "href": "technical-details/supervised-learning/main.html#discussion",
    "title": "Supervised Learning",
    "section": "",
    "text": "Result Interpretation: Interpret the results obtained from the analysis.\nModel Performance Comparison: Compare the performance of different models.\nInsights Gained: Share insights learned from the analysis."
  },
  {
    "objectID": "technical-details/data-collection/instructions.html#data-source",
    "href": "technical-details/data-collection/instructions.html#data-source",
    "title": "Data Collection Overview",
    "section": "",
    "text": "The data used in this project were obtained from the National Cancer Institute (NCI) Genomic Data Commons (GDC)1, a centralized repository designed to support cancer research by providing harmonized clinical, genomic, and exposure-related data across multiple cancer types. The GDC integrates data from large-scale initiatives such as The Cancer Genome Atlas (TCGA)2 and applies standardized data models, vocabularies, and quality control procedures to ensure consistency and reproducibility across studies.\n\n\n\nNational Cancer Institute (NCI) Genomic Data Commons (GDC)"
  },
  {
    "objectID": "technical-details/data-collection/instructions.html#section",
    "href": "technical-details/data-collection/instructions.html#section",
    "title": "Data Collection Overview",
    "section": "",
    "text": "For this analysis, we focused on two TCGA cohorts: Breast Invasive Carcinoma (TCGA-BRCA) and Cervical Squamous Cell Carcinoma and Endocervical Adenocarcinoma (TCGA-CESC). These datasets were selected to enable comparative analysis of two common cancers affecting women, while allowing investigation into differences in tumor characteristics, treatment patterns, and survival outcomes.\nClinical data were downloaded from the GDC Data Portal in tabular format (clinical.tsv and related files), which aggregate information across several hierarchical entities, including cases, demographic, diagnoses, treatments, and exposures. Variables include patient-level demographics (e.g., age at diagnosis, race, vital status), tumor-specific characteristics (e.g., stage, grade, morphology), treatment indicators (e.g., treatment type, treatment count), and outcome-related fields (e.g., days to death, days to last follow-up). All time-to-event variables in the GDC are reported in days, indexed relative to clinically meaningful anchor points such as diagnosis or enrollment dates.\nImportantly, the GDC data are de-identified to protect patient privacy, and certain variables may be obfuscated or missing by design. For example, ages above a threshold may be masked, dates may be offset, and exposure variables such as smoking status may be underreported. Additionally, patients may have multiple rows per case, reflecting repeated diagnoses, treatments, or follow-up events, necessitating aggregation and careful preprocessing prior to modeling.\nWhile TCGA cohorts are not fully representative of the general U.S. population, they remain one of the most comprehensive publicly available cancer datasets, widely used in both biomedical and data science research. The use of GDC data enables reproducible analysis while providing sufficient clinical depth to explore survival patterns and predictive modeling across cancer types."
  },
  {
    "objectID": "technical-details/data-collection/instructions.html#data-collection-methods",
    "href": "technical-details/data-collection/instructions.html#data-collection-methods",
    "title": "Data Collection Overview",
    "section": "Data Collection Methods",
    "text": "Data Collection Methods\nFor this analysis, we focused on two TCGA cohorts: Breast Invasive Carcinoma (TCGA-BRCA) and Cervical Squamous Cell Carcinoma and Endocervical Adenocarcinoma (TCGA-CESC). These datasets were selected to enable comparative analysis of two common cancers affecting women, while allowing investigation into differences in tumor characteristics, treatment patterns, and survival outcomes.\nClinical data were downloaded from the GDC Data Portal in tabular format (clinical.tsv and related files), which aggregate information across several hierarchical entities, including cases, demographic, diagnoses, treatments, and exposures. Variables include patient-level demographics (e.g., age at diagnosis, race, vital status), tumor-specific characteristics (e.g., stage, grade, morphology), treatment indicators (e.g., treatment type), and outcome-related fields (e.g., days to last follow-up). All time-to-event variables in the GDC are reported in days, indexed relative to clinically meaningful anchor points such as diagnosis or enrollment dates.\n\n\n\nTCGA-CESC (Cervical Cancer Example Download)"
  },
  {
    "objectID": "technical-details/data-collection/instructions.html#data-structure",
    "href": "technical-details/data-collection/instructions.html#data-structure",
    "title": "Data Collection Overview",
    "section": "",
    "text": "Importantly, the GDC data are de-identified to protect patient privacy, and certain variables may be obfuscated or missing by design. For example, ages above a threshold may be masked, dates may be offset, and exposure variables such as smoking status may be underreported. Additionally, patients may have multiple rows per case, reflecting repeated diagnoses, treatments, or follow-up events, necessitating aggregation and careful preprocessing prior to modeling.\nWhile TCGA cohorts are not fully representative of the general U.S. population, they remain one of the most comprehensive publicly available cancer datasets, widely used in both biomedical and data science research. The use of GDC data enables reproducible analysis while providing sufficient clinical depth to explore survival patterns and predictive modeling across cancer types."
  },
  {
    "objectID": "technical-details/data-collection/instructions.html#data-structure-and-format",
    "href": "technical-details/data-collection/instructions.html#data-structure-and-format",
    "title": "Data Collection Overview",
    "section": "Data Structure and Format",
    "text": "Data Structure and Format\nImportantly, the GDC data are de-identified to protect patient privacy, and certain variables may be obfuscated or missing by design. For example, ages above a threshold may be masked, dates may be offset, and exposure variables such as smoking status may be underreported. Additionally, patients may have multiple rows per case, reflecting repeated diagnoses, treatments, or follow-up events, necessitating aggregation and careful preprocessing prior to modeling.\n\n\n\n\n\n\nRows showing a unique patient (cases.submitter_id) and their different treatments for breast cancer\n\n\n\ncases.submitter_id\ntreatments.treatment_type\ntreatments.treatment_intent_type\ndemographic.vital_status\ndiagnoses.ajcc_pathologic_stage\n\n\n\n\n0\nTCGA-E2-A1IU\nRadiation Therapy, NOS\nAdjuvant\nAlive\nStage IA\n\n\n1\nTCGA-E2-A1IU\nHormone Therapy\nAdjuvant\nAlive\nStage IA\n\n\n2\nTCGA-E2-A1IU\nSurgery, NOS\nFirst-Line Therapy\nAlive\nStage IA"
  },
  {
    "objectID": "technical-details/data-collection/instructions.html#data",
    "href": "technical-details/data-collection/instructions.html#data",
    "title": "Data Collection Overview",
    "section": "Data",
    "text": "Data\nWhile TCGA cohorts are not fully representative of the general U.S. population, they remain one of the most comprehensive publicly available cancer datasets, widely used in both biomedical and data science research. The use of GDC data enables reproducible analysis while providing sufficient clinical depth to explore survival patterns and predictive modeling across cancer types.\nOur raw data can be found in our repository here\nAs of 11/05/2025, - the clinical breast cancer dataset originally has 5546 rows and 210 columns representing 1098 patients - the clinical cervical cancer dataset originally has 1535 rows and 210 columns representing 307 patients\nCode viewing the collected data can also be found on our repository here"
  },
  {
    "objectID": "technical-details/data-collection/main.html#data-source",
    "href": "technical-details/data-collection/main.html#data-source",
    "title": "Data Collection",
    "section": "",
    "text": "The data used in this project were obtained from the National Cancer Institute (NCI) Genomic Data Commons (GDC)1, a centralized repository designed to support cancer research by providing harmonized clinical, genomic, and exposure-related data across multiple cancer types. The GDC integrates data from large-scale initiatives such as The Cancer Genome Atlas (TCGA)2 and applies standardized data models, vocabularies, and quality control procedures to ensure consistency and reproducibility across studies.\n{alt = “National Cancer Institute Genomic Data Commons home page”}"
  },
  {
    "objectID": "technical-details/data-collection/main.html#data-collection-methods",
    "href": "technical-details/data-collection/main.html#data-collection-methods",
    "title": "Data Collection",
    "section": "",
    "text": "For this analysis, we focused on two TCGA cohorts: Breast Invasive Carcinoma (TCGA-BRCA) and Cervical Squamous Cell Carcinoma and Endocervical Adenocarcinoma (TCGA-CESC). These datasets were selected to enable comparative analysis of two common cancers affecting women, while allowing investigation into differences in tumor characteristics, treatment patterns, and survival outcomes.\nClinical data were downloaded from the GDC Data Portal in tabular format (clinical.tsv and related files), which aggregate information across several hierarchical entities, including cases, demographic, diagnoses, treatments, and exposures. Variables include patient-level demographics (e.g., age at diagnosis, race, vital status), tumor-specific characteristics (e.g., stage, grade, morphology), treatment indicators (e.g., treatment type), and outcome-related fields (e.g., days to last follow-up). All time-to-event variables in the GDC are reported in days, indexed relative to clinically meaningful anchor points such as diagnosis or enrollment dates.\n{alt = “National Cancer Institute Genomic Data Commons data download page”}"
  },
  {
    "objectID": "technical-details/data-collection/main.html#data-structure-and-format",
    "href": "technical-details/data-collection/main.html#data-structure-and-format",
    "title": "Data Collection",
    "section": "",
    "text": "Importantly, the GDC data are de-identified to protect patient privacy, and certain variables may be obfuscated or missing by design. For example, ages above a threshold may be masked, dates may be offset, and exposure variables such as smoking status may be underreported. Additionally, patients may have multiple rows per case, reflecting repeated diagnoses, treatments, or follow-up events, necessitating aggregation and careful preprocessing prior to modeling.\n#| echo: false\n#| warning: false\n#| tbl-cap: Rows showing a unique patient (cases.submitter_id) and their different treatments for breast cancer\nimport pandas as pd\n\n# Import dataset\nbrca_df = pd.read_csv(\"../../data/raw-data/brca/brca-clinical.tsv\", sep=\"\\t\")\n\n# Show rows for patient TCGA-E2-A1IU with selected columns\npatient_data = brca_df[brca_df[\"cases.submitter_id\"] == \"TCGA-E2-A1IU\"]\ncolumns_to_show = [\"cases.submitter_id\", \"treatments.treatment_type\", \n                   \"treatments.treatment_intent_type\", \"demographic.vital_status\",\n                   \"diagnoses.ajcc_pathologic_stage\"]\npatient_data[columns_to_show]"
  },
  {
    "objectID": "technical-details/data-collection/main.html#data",
    "href": "technical-details/data-collection/main.html#data",
    "title": "Data Collection",
    "section": "",
    "text": "While TCGA cohorts are not fully representative of the general U.S. population, they remain one of the most comprehensive publicly available cancer datasets, widely used in both biomedical and data science research. The use of GDC data enables reproducible analysis while providing sufficient clinical depth to explore survival patterns and predictive modeling across cancer types.\nOur raw data can be found in our repository here, including a data dictionary.\nAs of 11/05/2025, - the clinical breast cancer dataset originally has 5546 rows and 210 columns representing 1098 patients - the clinical cervical cancer dataset originally has 1535 rows and 210 columns representing 307 patients"
  },
  {
    "objectID": "technical-details/data-collection/main.html#clinical-data",
    "href": "technical-details/data-collection/main.html#clinical-data",
    "title": "Data Collection",
    "section": "Clinical Data",
    "text": "Clinical Data\n\n# Open CESC tsv data\n\ncesc = pd.read_csv('../../data/raw-data/cesc/cesc-clinical.tsv', sep='\\t')\ncesc.head(3)\n\n\n\n\n\n\n\n\nproject.project_id\ncases.case_id\ncases.consent_type\ncases.days_to_consent\ncases.days_to_lost_to_followup\ncases.disease_type\ncases.index_date\ncases.lost_to_followup\ncases.primary_site\ncases.submitter_id\n...\ntreatments.treatment_duration\ntreatments.treatment_effect\ntreatments.treatment_effect_indicator\ntreatments.treatment_frequency\ntreatments.treatment_id\ntreatments.treatment_intent_type\ntreatments.treatment_or_therapy\ntreatments.treatment_outcome\ntreatments.treatment_outcome_duration\ntreatments.treatment_type\n\n\n\n\n0\nTCGA-CESC\n00ad0ffe-2105-4829-a495-1c2aceb5bb31\nInformed Consent\n0\n'--\nSquamous Cell Neoplasms\nDiagnosis\nYes\nCervix uteri\nTCGA-EK-A2R9\n...\n'--\n'--\n'--\n'--\n672b3cf9-bb40-4f6f-a1c9-69ac3383fbd5\n'--\n'--\n'--\n'--\nHysterectomy, NOS\n\n\n1\nTCGA-CESC\n00ad0ffe-2105-4829-a495-1c2aceb5bb31\nInformed Consent\n0\n'--\nSquamous Cell Neoplasms\nDiagnosis\nYes\nCervix uteri\nTCGA-EK-A2R9\n...\n'--\n'--\n'--\n'--\nd4baa31f-8c1f-5333-afcd-836816fd1a2a\nAdjuvant\nunknown\n'--\n'--\nPharmaceutical Therapy, NOS\n\n\n2\nTCGA-CESC\n00ad0ffe-2105-4829-a495-1c2aceb5bb31\nInformed Consent\n0\n'--\nSquamous Cell Neoplasms\nDiagnosis\nYes\nCervix uteri\nTCGA-EK-A2R9\n...\n'--\n'--\n'--\n'--\ne79370ba-36f0-4639-bc8f-119ba2b2457b\nAdjuvant\nunknown\n'--\n'--\nRadiation Therapy, NOS\n\n\n3\nTCGA-CESC\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nInformed Consent\n2108\n'--\nSquamous Cell Neoplasms\nDiagnosis\nYes\nCervix uteri\nTCGA-C5-A2LV\n...\n'--\n'--\n'--\n'--\n277d525e-9674-4954-b427-3e829d469b8f\n'--\n'--\n'--\n'--\nHysterectomy, NOS\n\n\n4\nTCGA-CESC\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nInformed Consent\n2108\n'--\nSquamous Cell Neoplasms\nDiagnosis\nYes\nCervix uteri\nTCGA-C5-A2LV\n...\n'--\n'--\n'--\n'--\n788ff156-d009-46f7-b832-f39b11ed13ac\nAdjuvant\nno\n'--\n'--\nRadiation Therapy, NOS\n\n\n\n\n5 rows × 210 columns\n\n\n\n\nnrow, ncol = cesc.shape\nprint(f'The data has {nrow} rows and {ncol} columns.')\n\nThe data has 1535 rows and 210 columns.\n\n\n\n# List column names\nprint(\"Column names:\")\nprint(cesc.columns.tolist())\n\nColumn names:\n['project.project_id', 'cases.case_id', 'cases.consent_type', 'cases.days_to_consent', 'cases.days_to_lost_to_followup', 'cases.disease_type', 'cases.index_date', 'cases.lost_to_followup', 'cases.primary_site', 'cases.submitter_id', 'demographic.age_at_index', 'demographic.age_is_obfuscated', 'demographic.cause_of_death', 'demographic.cause_of_death_source', 'demographic.country_of_birth', 'demographic.country_of_residence_at_enrollment', 'demographic.days_to_birth', 'demographic.days_to_death', 'demographic.demographic_id', 'demographic.education_level', 'demographic.ethnicity', 'demographic.gender', 'demographic.marital_status', 'demographic.occupation_duration_years', 'demographic.population_group', 'demographic.premature_at_birth', 'demographic.race', 'demographic.submitter_id', 'demographic.vital_status', 'demographic.weeks_gestation_at_birth', 'demographic.year_of_birth', 'demographic.year_of_death', 'diagnoses.adrenal_hormone', 'diagnoses.age_at_diagnosis', 'diagnoses.ajcc_clinical_m', 'diagnoses.ajcc_clinical_n', 'diagnoses.ajcc_clinical_stage', 'diagnoses.ajcc_clinical_t', 'diagnoses.ajcc_pathologic_m', 'diagnoses.ajcc_pathologic_n', 'diagnoses.ajcc_pathologic_stage', 'diagnoses.ajcc_pathologic_t', 'diagnoses.ajcc_serum_tumor_markers', 'diagnoses.ajcc_staging_system_edition', 'diagnoses.ann_arbor_b_symptoms', 'diagnoses.ann_arbor_b_symptoms_described', 'diagnoses.ann_arbor_clinical_stage', 'diagnoses.ann_arbor_extranodal_involvement', 'diagnoses.ann_arbor_pathologic_stage', 'diagnoses.best_overall_response', 'diagnoses.burkitt_lymphoma_clinical_variant', 'diagnoses.calgb_risk_group', 'diagnoses.cancer_detection_method', 'diagnoses.child_pugh_classification', 'diagnoses.clark_level', 'diagnoses.classification_of_tumor', 'diagnoses.cog_liver_stage', 'diagnoses.cog_neuroblastoma_risk_group', 'diagnoses.cog_renal_stage', 'diagnoses.cog_rhabdomyosarcoma_risk_group', 'diagnoses.contiguous_organ_invaded', 'diagnoses.days_to_best_overall_response', 'diagnoses.days_to_diagnosis', 'diagnoses.days_to_last_follow_up', 'diagnoses.days_to_last_known_disease_status', 'diagnoses.days_to_recurrence', 'diagnoses.diagnosis_id', 'diagnoses.diagnosis_is_primary_disease', 'diagnoses.double_expressor_lymphoma', 'diagnoses.double_hit_lymphoma', 'diagnoses.eln_risk_classification', 'diagnoses.enneking_msts_grade', 'diagnoses.enneking_msts_metastasis', 'diagnoses.enneking_msts_stage', 'diagnoses.enneking_msts_tumor_site', 'diagnoses.ensat_clinical_m', 'diagnoses.ensat_pathologic_n', 'diagnoses.ensat_pathologic_stage', 'diagnoses.ensat_pathologic_t', 'diagnoses.esophageal_columnar_dysplasia_degree', 'diagnoses.esophageal_columnar_metaplasia_present', 'diagnoses.fab_morphology_code', 'diagnoses.figo_stage', 'diagnoses.figo_staging_edition_year', 'diagnoses.first_symptom_longest_duration', 'diagnoses.first_symptom_prior_to_diagnosis', 'diagnoses.gastric_esophageal_junction_involvement', 'diagnoses.gleason_grade_group', 'diagnoses.gleason_grade_tertiary', 'diagnoses.gleason_patterns_percent', 'diagnoses.gleason_score', 'diagnoses.goblet_cells_columnar_mucosa_present', 'diagnoses.icd_10_code', 'diagnoses.igcccg_stage', 'diagnoses.inpc_grade', 'diagnoses.inpc_histologic_group', 'diagnoses.inrg_stage', 'diagnoses.inss_stage', 'diagnoses.international_prognostic_index', 'diagnoses.irs_group', 'diagnoses.irs_stage', 'diagnoses.ishak_fibrosis_score', 'diagnoses.iss_stage', 'diagnoses.last_known_disease_status', 'diagnoses.laterality', 'diagnoses.margin_distance', 'diagnoses.margins_involved_site', 'diagnoses.masaoka_stage', 'diagnoses.max_tumor_bulk_site', 'diagnoses.medulloblastoma_molecular_classification', 'diagnoses.melanoma_known_primary', 'diagnoses.metastasis_at_diagnosis', 'diagnoses.metastasis_at_diagnosis_site', 'diagnoses.method_of_diagnosis', 'diagnoses.micropapillary_features', 'diagnoses.mitosis_karyorrhexis_index', 'diagnoses.mitotic_count', 'diagnoses.morphology', 'diagnoses.ovarian_specimen_status', 'diagnoses.ovarian_surface_involvement', 'diagnoses.papillary_renal_cell_type', 'diagnoses.pediatric_kidney_staging', 'diagnoses.peritoneal_fluid_cytological_status', 'diagnoses.pregnant_at_diagnosis', 'diagnoses.primary_diagnosis', 'diagnoses.primary_disease', 'diagnoses.primary_gleason_grade', 'diagnoses.prior_malignancy', 'diagnoses.prior_treatment', 'diagnoses.progression_or_recurrence', 'diagnoses.residual_disease', 'diagnoses.satellite_nodule_present', 'diagnoses.secondary_gleason_grade', 'diagnoses.site_of_resection_or_biopsy', 'diagnoses.sites_of_involvement', 'diagnoses.sites_of_involvement_count', 'diagnoses.submitter_id', 'diagnoses.supratentorial_localization', 'diagnoses.synchronous_malignancy', 'diagnoses.tissue_or_organ_of_origin', 'diagnoses.tumor_burden', 'diagnoses.tumor_confined_to_organ_of_origin', 'diagnoses.tumor_depth', 'diagnoses.tumor_focality', 'diagnoses.tumor_grade', 'diagnoses.tumor_grade_category', 'diagnoses.tumor_of_origin', 'diagnoses.tumor_regression_grade', 'diagnoses.uicc_clinical_m', 'diagnoses.uicc_clinical_n', 'diagnoses.uicc_clinical_stage', 'diagnoses.uicc_clinical_t', 'diagnoses.uicc_pathologic_m', 'diagnoses.uicc_pathologic_n', 'diagnoses.uicc_pathologic_stage', 'diagnoses.uicc_pathologic_t', 'diagnoses.uicc_staging_system_edition', 'diagnoses.ulceration_indicator', 'diagnoses.weiss_assessment_findings', 'diagnoses.weiss_assessment_score', 'diagnoses.who_cns_grade', 'diagnoses.who_nte_grade', 'diagnoses.wilms_tumor_histologic_subtype', 'diagnoses.year_of_diagnosis', 'treatments.chemo_concurrent_to_radiation', 'treatments.clinical_trial_indicator', 'treatments.course_number', 'treatments.days_to_treatment_end', 'treatments.days_to_treatment_start', 'treatments.drug_category', 'treatments.embolic_agent', 'treatments.initial_disease_status', 'treatments.lesions_treated_number', 'treatments.margin_distance', 'treatments.margin_status', 'treatments.margins_involved_site', 'treatments.number_of_cycles', 'treatments.number_of_fractions', 'treatments.prescribed_dose', 'treatments.prescribed_dose_units', 'treatments.pretreatment', 'treatments.protocol_identifier', 'treatments.radiosensitizing_agent', 'treatments.reason_treatment_ended', 'treatments.reason_treatment_not_given', 'treatments.regimen_or_line_of_therapy', 'treatments.residual_disease', 'treatments.route_of_administration', 'treatments.submitter_id', 'treatments.therapeutic_agents', 'treatments.therapeutic_level_achieved', 'treatments.therapeutic_levels_achieved', 'treatments.therapeutic_target_level', 'treatments.timepoint_category', 'treatments.treatment_anatomic_site', 'treatments.treatment_anatomic_sites', 'treatments.treatment_arm', 'treatments.treatment_dose', 'treatments.treatment_dose_max', 'treatments.treatment_dose_units', 'treatments.treatment_duration', 'treatments.treatment_effect', 'treatments.treatment_effect_indicator', 'treatments.treatment_frequency', 'treatments.treatment_id', 'treatments.treatment_intent_type', 'treatments.treatment_or_therapy', 'treatments.treatment_outcome', 'treatments.treatment_outcome_duration', 'treatments.treatment_type']\n\n\n\n# Number of unique patients\nunique_patients = cesc['cases.submitter_id'].nunique()\nprint(f'The data has {unique_patients} unique patients.')\n\nThe data has 307 unique patients."
  },
  {
    "objectID": "technical-details/data-collection/overview.html#data-source",
    "href": "technical-details/data-collection/overview.html#data-source",
    "title": "Overview",
    "section": "",
    "text": "The data used in this project were obtained from the National Cancer Institute (NCI) Genomic Data Commons (GDC)1, a centralized repository designed to support cancer research by providing harmonized clinical, genomic, and exposure-related data across multiple cancer types. The GDC integrates data from large-scale initiatives such as The Cancer Genome Atlas (TCGA)2 and applies standardized data models, vocabularies, and quality control procedures to ensure consistency and reproducibility across studies.\n{alt = “National Cancer Institute Genomic Data Commons home page”}"
  },
  {
    "objectID": "technical-details/data-collection/overview.html#data-collection-methods",
    "href": "technical-details/data-collection/overview.html#data-collection-methods",
    "title": "Overview",
    "section": "Data Collection Methods",
    "text": "Data Collection Methods\nFor this analysis, we focused on two TCGA cohorts: Breast Invasive Carcinoma (TCGA-BRCA) and Cervical Squamous Cell Carcinoma and Endocervical Adenocarcinoma (TCGA-CESC). These datasets were selected to enable comparative analysis of two common cancers affecting women, while allowing investigation into differences in tumor characteristics, treatment patterns, and survival outcomes.\nClinical data were downloaded from the GDC Data Portal in tabular format (clinical.tsv and related files), which aggregate information across several hierarchical entities, including cases, demographic, diagnoses, treatments, and exposures. Variables include patient-level demographics (e.g., age at diagnosis, race, vital status), tumor-specific characteristics (e.g., stage, grade, morphology), treatment indicators (e.g., treatment type), and outcome-related fields (e.g., days to last follow-up). All time-to-event variables in the GDC are reported in days, indexed relative to clinically meaningful anchor points such as diagnosis or enrollment dates.\n{alt = “National Cancer Institute Genomic Data Commons data download page”}"
  },
  {
    "objectID": "technical-details/data-collection/overview.html#data-structure-and-format",
    "href": "technical-details/data-collection/overview.html#data-structure-and-format",
    "title": "Overview",
    "section": "Data Structure and Format",
    "text": "Data Structure and Format\nImportantly, the GDC data are de-identified to protect patient privacy, and certain variables may be obfuscated or missing by design. For example, ages above a threshold may be masked, dates may be offset, and exposure variables such as smoking status may be underreported. Additionally, patients may have multiple rows per case, reflecting repeated diagnoses, treatments, or follow-up events, necessitating aggregation and careful preprocessing prior to modeling.\n\n\n\n\n\n\nRows showing a unique patient (cases.submitter_id) and their different treatments for breast cancer\n\n\n\ncases.submitter_id\ntreatments.treatment_type\ntreatments.treatment_intent_type\ndemographic.vital_status\ndiagnoses.ajcc_pathologic_stage\n\n\n\n\n0\nTCGA-E2-A1IU\nRadiation Therapy, NOS\nAdjuvant\nAlive\nStage IA\n\n\n1\nTCGA-E2-A1IU\nHormone Therapy\nAdjuvant\nAlive\nStage IA\n\n\n2\nTCGA-E2-A1IU\nSurgery, NOS\nFirst-Line Therapy\nAlive\nStage IA"
  },
  {
    "objectID": "technical-details/data-collection/overview.html#data",
    "href": "technical-details/data-collection/overview.html#data",
    "title": "Overview",
    "section": "Data",
    "text": "Data\nWhile TCGA cohorts are not fully representative of the general U.S. population, they remain one of the most comprehensive publicly available cancer datasets, widely used in both biomedical and data science research. The use of GDC data enables reproducible analysis while providing sufficient clinical depth to explore survival patterns and predictive modeling across cancer types.\nOur raw data can be found in our repository here, including a data dictionary.\nAs of 11/05/2025, - the clinical breast cancer dataset originally has 5546 rows and 210 columns representing 1098 patients - the clinical cervical cancer dataset originally has 1535 rows and 210 columns representing 307 patients"
  },
  {
    "objectID": "technical-details/data-collection/main.html#breast-brca-cancer-dataset",
    "href": "technical-details/data-collection/main.html#breast-brca-cancer-dataset",
    "title": "Data Collection",
    "section": "Breast (BRCA) Cancer Dataset",
    "text": "Breast (BRCA) Cancer Dataset\n\n# Open BRCA clinical tsv data\n\nbrca = pd.read_csv('../../data/raw-data/brca/brca-clinical.tsv', sep='\\t')\nbrca.head()\n\n/var/folders/pk/q040shz17k97bg4ndnn1q0b00000gn/T/ipykernel_62797/953297970.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n  brca = pd.read_csv('data/raw-data/brca/brca-clinical.tsv', sep='\\t')\n\n\n\n\n\n\n\n\n\nproject.project_id\ncases.case_id\ncases.consent_type\ncases.days_to_consent\ncases.days_to_lost_to_followup\ncases.disease_type\ncases.index_date\ncases.lost_to_followup\ncases.primary_site\ncases.submitter_id\n...\ntreatments.treatment_duration\ntreatments.treatment_effect\ntreatments.treatment_effect_indicator\ntreatments.treatment_frequency\ntreatments.treatment_id\ntreatments.treatment_intent_type\ntreatments.treatment_or_therapy\ntreatments.treatment_outcome\ntreatments.treatment_outcome_duration\ntreatments.treatment_type\n\n\n\n\n0\nTCGA-BRCA\n001cef41-ff86-4d3f-a140-a647ac4b10a1\nInformed Consent\n-34\n'--\nDuctal and Lobular Neoplasms\nDiagnosis\n'--\nBreast\nTCGA-E2-A1IU\n...\n'--\n'--\n'--\n'--\n1b884f21-eb24-467f-aba2-208af17070b9\nAdjuvant\nno\n'--\n'--\nRadiation Therapy, NOS\n\n\n1\nTCGA-BRCA\n001cef41-ff86-4d3f-a140-a647ac4b10a1\nInformed Consent\n-34\n'--\nDuctal and Lobular Neoplasms\nDiagnosis\n'--\nBreast\nTCGA-E2-A1IU\n...\n'--\n'--\n'--\n'--\n27868bc3-23c8-5e85-a0e2-314e6cdf9b2a\nAdjuvant\nyes\nTreatment Ongoing\n'--\nHormone Therapy\n\n\n2\nTCGA-BRCA\n001cef41-ff86-4d3f-a140-a647ac4b10a1\nInformed Consent\n-34\n'--\nDuctal and Lobular Neoplasms\nDiagnosis\n'--\nBreast\nTCGA-E2-A1IU\n...\n'--\n'--\n'--\n'--\naedf144c-6b7b-4d76-a3cb-4271aef10f1d\nFirst-Line Therapy\nyes\n'--\n'--\nSurgery, NOS\n\n\n3\nTCGA-BRCA\n0045349c-69d9-4306-a403-c9c1fa836644\nInformed Consent\n76\n'--\nAdenomas and Adenocarcinomas\nDiagnosis\n'--\nBreast\nTCGA-A1-A0SB\n...\n'--\n'--\n'--\n'--\n0a534cae-de91-5e77-a3e7-b52d46bd3966\nFirst-Line Therapy\nyes\n'--\n'--\nSurgery, NOS\n\n\n4\nTCGA-BRCA\n00807dae-9f4a-4fd1-aac2-82eb11bf2afb\nInformed Consent\n19\n'--\nAdnexal and Skin Appendage Neoplasms\nDiagnosis\nNo\nBreast\nTCGA-A2-A04W\n...\n'--\n'--\n'--\n'--\n024faa94-ec57-4d14-b919-62dcab409958\nAdjuvant\nyes\nTreatment Ongoing\n'--\nBisphosphonate Therapy\n\n\n\n\n5 rows × 210 columns\n\n\n\n\nnrow, ncol = brca.shape\nprint(f'The data has {nrow} rows and {ncol} columns.')\n\nThe data has 5546 rows and 210 columns.\n\n\n\n# List column names\nprint(\"Column names:\")\nprint(brca.columns.tolist())\n\nColumn names:\n['project.project_id', 'cases.case_id', 'cases.consent_type', 'cases.days_to_consent', 'cases.days_to_lost_to_followup', 'cases.disease_type', 'cases.index_date', 'cases.lost_to_followup', 'cases.primary_site', 'cases.submitter_id', 'demographic.age_at_index', 'demographic.age_is_obfuscated', 'demographic.cause_of_death', 'demographic.cause_of_death_source', 'demographic.country_of_birth', 'demographic.country_of_residence_at_enrollment', 'demographic.days_to_birth', 'demographic.days_to_death', 'demographic.demographic_id', 'demographic.education_level', 'demographic.ethnicity', 'demographic.gender', 'demographic.marital_status', 'demographic.occupation_duration_years', 'demographic.population_group', 'demographic.premature_at_birth', 'demographic.race', 'demographic.submitter_id', 'demographic.vital_status', 'demographic.weeks_gestation_at_birth', 'demographic.year_of_birth', 'demographic.year_of_death', 'diagnoses.adrenal_hormone', 'diagnoses.age_at_diagnosis', 'diagnoses.ajcc_clinical_m', 'diagnoses.ajcc_clinical_n', 'diagnoses.ajcc_clinical_stage', 'diagnoses.ajcc_clinical_t', 'diagnoses.ajcc_pathologic_m', 'diagnoses.ajcc_pathologic_n', 'diagnoses.ajcc_pathologic_stage', 'diagnoses.ajcc_pathologic_t', 'diagnoses.ajcc_serum_tumor_markers', 'diagnoses.ajcc_staging_system_edition', 'diagnoses.ann_arbor_b_symptoms', 'diagnoses.ann_arbor_b_symptoms_described', 'diagnoses.ann_arbor_clinical_stage', 'diagnoses.ann_arbor_extranodal_involvement', 'diagnoses.ann_arbor_pathologic_stage', 'diagnoses.best_overall_response', 'diagnoses.burkitt_lymphoma_clinical_variant', 'diagnoses.calgb_risk_group', 'diagnoses.cancer_detection_method', 'diagnoses.child_pugh_classification', 'diagnoses.clark_level', 'diagnoses.classification_of_tumor', 'diagnoses.cog_liver_stage', 'diagnoses.cog_neuroblastoma_risk_group', 'diagnoses.cog_renal_stage', 'diagnoses.cog_rhabdomyosarcoma_risk_group', 'diagnoses.contiguous_organ_invaded', 'diagnoses.days_to_best_overall_response', 'diagnoses.days_to_diagnosis', 'diagnoses.days_to_last_follow_up', 'diagnoses.days_to_last_known_disease_status', 'diagnoses.days_to_recurrence', 'diagnoses.diagnosis_id', 'diagnoses.diagnosis_is_primary_disease', 'diagnoses.double_expressor_lymphoma', 'diagnoses.double_hit_lymphoma', 'diagnoses.eln_risk_classification', 'diagnoses.enneking_msts_grade', 'diagnoses.enneking_msts_metastasis', 'diagnoses.enneking_msts_stage', 'diagnoses.enneking_msts_tumor_site', 'diagnoses.ensat_clinical_m', 'diagnoses.ensat_pathologic_n', 'diagnoses.ensat_pathologic_stage', 'diagnoses.ensat_pathologic_t', 'diagnoses.esophageal_columnar_dysplasia_degree', 'diagnoses.esophageal_columnar_metaplasia_present', 'diagnoses.fab_morphology_code', 'diagnoses.figo_stage', 'diagnoses.figo_staging_edition_year', 'diagnoses.first_symptom_longest_duration', 'diagnoses.first_symptom_prior_to_diagnosis', 'diagnoses.gastric_esophageal_junction_involvement', 'diagnoses.gleason_grade_group', 'diagnoses.gleason_grade_tertiary', 'diagnoses.gleason_patterns_percent', 'diagnoses.gleason_score', 'diagnoses.goblet_cells_columnar_mucosa_present', 'diagnoses.icd_10_code', 'diagnoses.igcccg_stage', 'diagnoses.inpc_grade', 'diagnoses.inpc_histologic_group', 'diagnoses.inrg_stage', 'diagnoses.inss_stage', 'diagnoses.international_prognostic_index', 'diagnoses.irs_group', 'diagnoses.irs_stage', 'diagnoses.ishak_fibrosis_score', 'diagnoses.iss_stage', 'diagnoses.last_known_disease_status', 'diagnoses.laterality', 'diagnoses.margin_distance', 'diagnoses.margins_involved_site', 'diagnoses.masaoka_stage', 'diagnoses.max_tumor_bulk_site', 'diagnoses.medulloblastoma_molecular_classification', 'diagnoses.melanoma_known_primary', 'diagnoses.metastasis_at_diagnosis', 'diagnoses.metastasis_at_diagnosis_site', 'diagnoses.method_of_diagnosis', 'diagnoses.micropapillary_features', 'diagnoses.mitosis_karyorrhexis_index', 'diagnoses.mitotic_count', 'diagnoses.morphology', 'diagnoses.ovarian_specimen_status', 'diagnoses.ovarian_surface_involvement', 'diagnoses.papillary_renal_cell_type', 'diagnoses.pediatric_kidney_staging', 'diagnoses.peritoneal_fluid_cytological_status', 'diagnoses.pregnant_at_diagnosis', 'diagnoses.primary_diagnosis', 'diagnoses.primary_disease', 'diagnoses.primary_gleason_grade', 'diagnoses.prior_malignancy', 'diagnoses.prior_treatment', 'diagnoses.progression_or_recurrence', 'diagnoses.residual_disease', 'diagnoses.satellite_nodule_present', 'diagnoses.secondary_gleason_grade', 'diagnoses.site_of_resection_or_biopsy', 'diagnoses.sites_of_involvement', 'diagnoses.sites_of_involvement_count', 'diagnoses.submitter_id', 'diagnoses.supratentorial_localization', 'diagnoses.synchronous_malignancy', 'diagnoses.tissue_or_organ_of_origin', 'diagnoses.tumor_burden', 'diagnoses.tumor_confined_to_organ_of_origin', 'diagnoses.tumor_depth', 'diagnoses.tumor_focality', 'diagnoses.tumor_grade', 'diagnoses.tumor_grade_category', 'diagnoses.tumor_of_origin', 'diagnoses.tumor_regression_grade', 'diagnoses.uicc_clinical_m', 'diagnoses.uicc_clinical_n', 'diagnoses.uicc_clinical_stage', 'diagnoses.uicc_clinical_t', 'diagnoses.uicc_pathologic_m', 'diagnoses.uicc_pathologic_n', 'diagnoses.uicc_pathologic_stage', 'diagnoses.uicc_pathologic_t', 'diagnoses.uicc_staging_system_edition', 'diagnoses.ulceration_indicator', 'diagnoses.weiss_assessment_findings', 'diagnoses.weiss_assessment_score', 'diagnoses.who_cns_grade', 'diagnoses.who_nte_grade', 'diagnoses.wilms_tumor_histologic_subtype', 'diagnoses.year_of_diagnosis', 'treatments.chemo_concurrent_to_radiation', 'treatments.clinical_trial_indicator', 'treatments.course_number', 'treatments.days_to_treatment_end', 'treatments.days_to_treatment_start', 'treatments.drug_category', 'treatments.embolic_agent', 'treatments.initial_disease_status', 'treatments.lesions_treated_number', 'treatments.margin_distance', 'treatments.margin_status', 'treatments.margins_involved_site', 'treatments.number_of_cycles', 'treatments.number_of_fractions', 'treatments.prescribed_dose', 'treatments.prescribed_dose_units', 'treatments.pretreatment', 'treatments.protocol_identifier', 'treatments.radiosensitizing_agent', 'treatments.reason_treatment_ended', 'treatments.reason_treatment_not_given', 'treatments.regimen_or_line_of_therapy', 'treatments.residual_disease', 'treatments.route_of_administration', 'treatments.submitter_id', 'treatments.therapeutic_agents', 'treatments.therapeutic_level_achieved', 'treatments.therapeutic_levels_achieved', 'treatments.therapeutic_target_level', 'treatments.timepoint_category', 'treatments.treatment_anatomic_site', 'treatments.treatment_anatomic_sites', 'treatments.treatment_arm', 'treatments.treatment_dose', 'treatments.treatment_dose_max', 'treatments.treatment_dose_units', 'treatments.treatment_duration', 'treatments.treatment_effect', 'treatments.treatment_effect_indicator', 'treatments.treatment_frequency', 'treatments.treatment_id', 'treatments.treatment_intent_type', 'treatments.treatment_or_therapy', 'treatments.treatment_outcome', 'treatments.treatment_outcome_duration', 'treatments.treatment_type']\n\n\n\n# Number of unique patients\nunique_patients = brca['cases.submitter_id'].nunique()\nprint(f'The data has {unique_patients} unique patients.')\n\nThe data has 1098 unique patients."
  },
  {
    "objectID": "technical-details/data-collection/main.html#cervical-cesc-cancer-dataset",
    "href": "technical-details/data-collection/main.html#cervical-cesc-cancer-dataset",
    "title": "Data Collection",
    "section": "Cervical (CESC) Cancer Dataset",
    "text": "Cervical (CESC) Cancer Dataset\n\nClinical Data\n\n# Open CESC tsv data\n\ncesc = pd.read_csv('../../data/raw-data/cesc/cesc-clinical.tsv', sep='\\t')\ncesc.head(3)\n\n\n\n\n\n\n\n\nproject.project_id\ncases.case_id\ncases.consent_type\ncases.days_to_consent\ncases.days_to_lost_to_followup\ncases.disease_type\ncases.index_date\ncases.lost_to_followup\ncases.primary_site\ncases.submitter_id\n...\ntreatments.treatment_duration\ntreatments.treatment_effect\ntreatments.treatment_effect_indicator\ntreatments.treatment_frequency\ntreatments.treatment_id\ntreatments.treatment_intent_type\ntreatments.treatment_or_therapy\ntreatments.treatment_outcome\ntreatments.treatment_outcome_duration\ntreatments.treatment_type\n\n\n\n\n0\nTCGA-CESC\n00ad0ffe-2105-4829-a495-1c2aceb5bb31\nInformed Consent\n0\n'--\nSquamous Cell Neoplasms\nDiagnosis\nYes\nCervix uteri\nTCGA-EK-A2R9\n...\n'--\n'--\n'--\n'--\n672b3cf9-bb40-4f6f-a1c9-69ac3383fbd5\n'--\n'--\n'--\n'--\nHysterectomy, NOS\n\n\n1\nTCGA-CESC\n00ad0ffe-2105-4829-a495-1c2aceb5bb31\nInformed Consent\n0\n'--\nSquamous Cell Neoplasms\nDiagnosis\nYes\nCervix uteri\nTCGA-EK-A2R9\n...\n'--\n'--\n'--\n'--\nd4baa31f-8c1f-5333-afcd-836816fd1a2a\nAdjuvant\nunknown\n'--\n'--\nPharmaceutical Therapy, NOS\n\n\n2\nTCGA-CESC\n00ad0ffe-2105-4829-a495-1c2aceb5bb31\nInformed Consent\n0\n'--\nSquamous Cell Neoplasms\nDiagnosis\nYes\nCervix uteri\nTCGA-EK-A2R9\n...\n'--\n'--\n'--\n'--\ne79370ba-36f0-4639-bc8f-119ba2b2457b\nAdjuvant\nunknown\n'--\n'--\nRadiation Therapy, NOS\n\n\n3\nTCGA-CESC\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nInformed Consent\n2108\n'--\nSquamous Cell Neoplasms\nDiagnosis\nYes\nCervix uteri\nTCGA-C5-A2LV\n...\n'--\n'--\n'--\n'--\n277d525e-9674-4954-b427-3e829d469b8f\n'--\n'--\n'--\n'--\nHysterectomy, NOS\n\n\n4\nTCGA-CESC\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nInformed Consent\n2108\n'--\nSquamous Cell Neoplasms\nDiagnosis\nYes\nCervix uteri\nTCGA-C5-A2LV\n...\n'--\n'--\n'--\n'--\n788ff156-d009-46f7-b832-f39b11ed13ac\nAdjuvant\nno\n'--\n'--\nRadiation Therapy, NOS\n\n\n\n\n5 rows × 210 columns\n\n\n\n\nnrow, ncol = cesc.shape\nprint(f'The data has {nrow} rows and {ncol} columns.')\n\nThe data has 1535 rows and 210 columns.\n\n\n\n# List column names\nprint(\"Column names:\")\nprint(cesc.columns.tolist())\n\nColumn names:\n['project.project_id', 'cases.case_id', 'cases.consent_type', 'cases.days_to_consent', 'cases.days_to_lost_to_followup', 'cases.disease_type', 'cases.index_date', 'cases.lost_to_followup', 'cases.primary_site', 'cases.submitter_id', 'demographic.age_at_index', 'demographic.age_is_obfuscated', 'demographic.cause_of_death', 'demographic.cause_of_death_source', 'demographic.country_of_birth', 'demographic.country_of_residence_at_enrollment', 'demographic.days_to_birth', 'demographic.days_to_death', 'demographic.demographic_id', 'demographic.education_level', 'demographic.ethnicity', 'demographic.gender', 'demographic.marital_status', 'demographic.occupation_duration_years', 'demographic.population_group', 'demographic.premature_at_birth', 'demographic.race', 'demographic.submitter_id', 'demographic.vital_status', 'demographic.weeks_gestation_at_birth', 'demographic.year_of_birth', 'demographic.year_of_death', 'diagnoses.adrenal_hormone', 'diagnoses.age_at_diagnosis', 'diagnoses.ajcc_clinical_m', 'diagnoses.ajcc_clinical_n', 'diagnoses.ajcc_clinical_stage', 'diagnoses.ajcc_clinical_t', 'diagnoses.ajcc_pathologic_m', 'diagnoses.ajcc_pathologic_n', 'diagnoses.ajcc_pathologic_stage', 'diagnoses.ajcc_pathologic_t', 'diagnoses.ajcc_serum_tumor_markers', 'diagnoses.ajcc_staging_system_edition', 'diagnoses.ann_arbor_b_symptoms', 'diagnoses.ann_arbor_b_symptoms_described', 'diagnoses.ann_arbor_clinical_stage', 'diagnoses.ann_arbor_extranodal_involvement', 'diagnoses.ann_arbor_pathologic_stage', 'diagnoses.best_overall_response', 'diagnoses.burkitt_lymphoma_clinical_variant', 'diagnoses.calgb_risk_group', 'diagnoses.cancer_detection_method', 'diagnoses.child_pugh_classification', 'diagnoses.clark_level', 'diagnoses.classification_of_tumor', 'diagnoses.cog_liver_stage', 'diagnoses.cog_neuroblastoma_risk_group', 'diagnoses.cog_renal_stage', 'diagnoses.cog_rhabdomyosarcoma_risk_group', 'diagnoses.contiguous_organ_invaded', 'diagnoses.days_to_best_overall_response', 'diagnoses.days_to_diagnosis', 'diagnoses.days_to_last_follow_up', 'diagnoses.days_to_last_known_disease_status', 'diagnoses.days_to_recurrence', 'diagnoses.diagnosis_id', 'diagnoses.diagnosis_is_primary_disease', 'diagnoses.double_expressor_lymphoma', 'diagnoses.double_hit_lymphoma', 'diagnoses.eln_risk_classification', 'diagnoses.enneking_msts_grade', 'diagnoses.enneking_msts_metastasis', 'diagnoses.enneking_msts_stage', 'diagnoses.enneking_msts_tumor_site', 'diagnoses.ensat_clinical_m', 'diagnoses.ensat_pathologic_n', 'diagnoses.ensat_pathologic_stage', 'diagnoses.ensat_pathologic_t', 'diagnoses.esophageal_columnar_dysplasia_degree', 'diagnoses.esophageal_columnar_metaplasia_present', 'diagnoses.fab_morphology_code', 'diagnoses.figo_stage', 'diagnoses.figo_staging_edition_year', 'diagnoses.first_symptom_longest_duration', 'diagnoses.first_symptom_prior_to_diagnosis', 'diagnoses.gastric_esophageal_junction_involvement', 'diagnoses.gleason_grade_group', 'diagnoses.gleason_grade_tertiary', 'diagnoses.gleason_patterns_percent', 'diagnoses.gleason_score', 'diagnoses.goblet_cells_columnar_mucosa_present', 'diagnoses.icd_10_code', 'diagnoses.igcccg_stage', 'diagnoses.inpc_grade', 'diagnoses.inpc_histologic_group', 'diagnoses.inrg_stage', 'diagnoses.inss_stage', 'diagnoses.international_prognostic_index', 'diagnoses.irs_group', 'diagnoses.irs_stage', 'diagnoses.ishak_fibrosis_score', 'diagnoses.iss_stage', 'diagnoses.last_known_disease_status', 'diagnoses.laterality', 'diagnoses.margin_distance', 'diagnoses.margins_involved_site', 'diagnoses.masaoka_stage', 'diagnoses.max_tumor_bulk_site', 'diagnoses.medulloblastoma_molecular_classification', 'diagnoses.melanoma_known_primary', 'diagnoses.metastasis_at_diagnosis', 'diagnoses.metastasis_at_diagnosis_site', 'diagnoses.method_of_diagnosis', 'diagnoses.micropapillary_features', 'diagnoses.mitosis_karyorrhexis_index', 'diagnoses.mitotic_count', 'diagnoses.morphology', 'diagnoses.ovarian_specimen_status', 'diagnoses.ovarian_surface_involvement', 'diagnoses.papillary_renal_cell_type', 'diagnoses.pediatric_kidney_staging', 'diagnoses.peritoneal_fluid_cytological_status', 'diagnoses.pregnant_at_diagnosis', 'diagnoses.primary_diagnosis', 'diagnoses.primary_disease', 'diagnoses.primary_gleason_grade', 'diagnoses.prior_malignancy', 'diagnoses.prior_treatment', 'diagnoses.progression_or_recurrence', 'diagnoses.residual_disease', 'diagnoses.satellite_nodule_present', 'diagnoses.secondary_gleason_grade', 'diagnoses.site_of_resection_or_biopsy', 'diagnoses.sites_of_involvement', 'diagnoses.sites_of_involvement_count', 'diagnoses.submitter_id', 'diagnoses.supratentorial_localization', 'diagnoses.synchronous_malignancy', 'diagnoses.tissue_or_organ_of_origin', 'diagnoses.tumor_burden', 'diagnoses.tumor_confined_to_organ_of_origin', 'diagnoses.tumor_depth', 'diagnoses.tumor_focality', 'diagnoses.tumor_grade', 'diagnoses.tumor_grade_category', 'diagnoses.tumor_of_origin', 'diagnoses.tumor_regression_grade', 'diagnoses.uicc_clinical_m', 'diagnoses.uicc_clinical_n', 'diagnoses.uicc_clinical_stage', 'diagnoses.uicc_clinical_t', 'diagnoses.uicc_pathologic_m', 'diagnoses.uicc_pathologic_n', 'diagnoses.uicc_pathologic_stage', 'diagnoses.uicc_pathologic_t', 'diagnoses.uicc_staging_system_edition', 'diagnoses.ulceration_indicator', 'diagnoses.weiss_assessment_findings', 'diagnoses.weiss_assessment_score', 'diagnoses.who_cns_grade', 'diagnoses.who_nte_grade', 'diagnoses.wilms_tumor_histologic_subtype', 'diagnoses.year_of_diagnosis', 'treatments.chemo_concurrent_to_radiation', 'treatments.clinical_trial_indicator', 'treatments.course_number', 'treatments.days_to_treatment_end', 'treatments.days_to_treatment_start', 'treatments.drug_category', 'treatments.embolic_agent', 'treatments.initial_disease_status', 'treatments.lesions_treated_number', 'treatments.margin_distance', 'treatments.margin_status', 'treatments.margins_involved_site', 'treatments.number_of_cycles', 'treatments.number_of_fractions', 'treatments.prescribed_dose', 'treatments.prescribed_dose_units', 'treatments.pretreatment', 'treatments.protocol_identifier', 'treatments.radiosensitizing_agent', 'treatments.reason_treatment_ended', 'treatments.reason_treatment_not_given', 'treatments.regimen_or_line_of_therapy', 'treatments.residual_disease', 'treatments.route_of_administration', 'treatments.submitter_id', 'treatments.therapeutic_agents', 'treatments.therapeutic_level_achieved', 'treatments.therapeutic_levels_achieved', 'treatments.therapeutic_target_level', 'treatments.timepoint_category', 'treatments.treatment_anatomic_site', 'treatments.treatment_anatomic_sites', 'treatments.treatment_arm', 'treatments.treatment_dose', 'treatments.treatment_dose_max', 'treatments.treatment_dose_units', 'treatments.treatment_duration', 'treatments.treatment_effect', 'treatments.treatment_effect_indicator', 'treatments.treatment_frequency', 'treatments.treatment_id', 'treatments.treatment_intent_type', 'treatments.treatment_or_therapy', 'treatments.treatment_outcome', 'treatments.treatment_outcome_duration', 'treatments.treatment_type']\n\n\n\n# Number of unique patients\nunique_patients = cesc['cases.submitter_id'].nunique()\nprint(f'The data has {unique_patients} unique patients.')\n\nThe data has 307 unique patients.\n\n\n\n\nExposure Data\n\n# Open cesc exposure tsv data\n\ncesc_exposure_df = pd.read_csv('../../data/raw-data/cesc/exposure.tsv', sep='\\t')\ncesc_exposure_df.head(3)\n\n\n\n\n\n\n\n\nproject.project_id\ncases.case_id\ncases.submitter_id\nexposures.age_at_last_exposure\nexposures.age_at_onset\nexposures.alcohol_days_per_week\nexposures.alcohol_drinks_per_day\nexposures.alcohol_frequency\nexposures.alcohol_history\nexposures.alcohol_intensity\n...\nexposures.smoking_frequency\nexposures.submitter_id\nexposures.time_between_waking_and_first_smoke\nexposures.tobacco_smoking_onset_year\nexposures.tobacco_smoking_quit_year\nexposures.tobacco_smoking_status\nexposures.type_of_smoke_exposure\nexposures.type_of_tobacco_used\nexposures.use_per_day\nexposures.years_smoked\n\n\n\n\n0\nTCGA-CESC\n00ad0ffe-2105-4829-a495-1c2aceb5bb31\nTCGA-EK-A2R9\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n...\n'--\n'--\n'--\n'--\n'--\nNot Reported\n'--\n'--\n'--\n'--\n\n\n1\nTCGA-CESC\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nTCGA-C5-A2LV\n'--\n20\n'--\n'--\n'--\n'--\n'--\n...\n'--\n'--\n'--\n'--\n'--\nCurrent Smoker\n'--\n'--\n'--\n'--\n\n\n2\nTCGA-CESC\n010a807f-9dc0-4e14-9533-dcf478f3d947\nTCGA-C5-A902\n'--\n14\n'--\n'--\n'--\n'--\n'--\n...\n'--\n'--\n'--\n'--\n'--\nCurrent Smoker\n'--\n'--\n'--\n'--\n\n\n3\nTCGA-CESC\n03804f9b-df7c-462c-8984-8eb3a5ed4999\nTCGA-VS-A9V2\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n...\n'--\n'--\n'--\n'--\n'--\nLifelong Non-Smoker\n'--\n'--\n'--\n'--\n\n\n4\nTCGA-CESC\n03c3fe57-ae85-4e45-9657-c3182ab5e124\nTCGA-C5-A1BL\n'--\n16\n'--\n'--\n'--\n'--\n'--\n...\n'--\n'--\n'--\n'--\n1988\nCurrent Reformed Smoker for &lt; or = 15 yrs\n'--\n'--\n'--\n'--\n\n\n\n\n5 rows × 40 columns\n\n\n\nThe code above can also be found on our repository here"
  },
  {
    "objectID": "technical-details/data-cleaning/instructions.html#managing-missing-data",
    "href": "technical-details/data-cleaning/instructions.html#managing-missing-data",
    "title": "Overview",
    "section": "Managing Missing Data:",
    "text": "Managing Missing Data:\n\n\n\n\n\n\nRows showing a unique patient (cases.submitter_id) and their different treatments for breast cancer\n\n\n\nproject.project_id\ncases.case_id\ncases.consent_type\ncases.days_to_consent\ncases.days_to_lost_to_followup\ncases.disease_type\ncases.index_date\ncases.lost_to_followup\ncases.primary_site\ncases.submitter_id\n...\ntreatments.treatment_duration\ntreatments.treatment_effect\ntreatments.treatment_effect_indicator\ntreatments.treatment_frequency\ntreatments.treatment_id\ntreatments.treatment_intent_type\ntreatments.treatment_or_therapy\ntreatments.treatment_outcome\ntreatments.treatment_outcome_duration\ntreatments.treatment_type\n\n\n\n\n0\nTCGA-BRCA\n001cef41-ff86-4d3f-a140-a647ac4b10a1\nInformed Consent\n-34\n'--\nDuctal and Lobular Neoplasms\nDiagnosis\n'--\nBreast\nTCGA-E2-A1IU\n...\n'--\n'--\n'--\n'--\n1b884f21-eb24-467f-aba2-208af17070b9\nAdjuvant\nno\n'--\n'--\nRadiation Therapy, NOS\n\n\n1\nTCGA-BRCA\n001cef41-ff86-4d3f-a140-a647ac4b10a1\nInformed Consent\n-34\n'--\nDuctal and Lobular Neoplasms\nDiagnosis\n'--\nBreast\nTCGA-E2-A1IU\n...\n'--\n'--\n'--\n'--\n27868bc3-23c8-5e85-a0e2-314e6cdf9b2a\nAdjuvant\nyes\nTreatment Ongoing\n'--\nHormone Therapy\n\n\n2\nTCGA-BRCA\n001cef41-ff86-4d3f-a140-a647ac4b10a1\nInformed Consent\n-34\n'--\nDuctal and Lobular Neoplasms\nDiagnosis\n'--\nBreast\nTCGA-E2-A1IU\n...\n'--\n'--\n'--\n'--\naedf144c-6b7b-4d76-a3cb-4271aef10f1d\nFirst-Line Therapy\nyes\n'--\n'--\nSurgery, NOS\n\n\n3\nTCGA-BRCA\n0045349c-69d9-4306-a403-c9c1fa836644\nInformed Consent\n76\n'--\nAdenomas and Adenocarcinomas\nDiagnosis\n'--\nBreast\nTCGA-A1-A0SB\n...\n'--\n'--\n'--\n'--\n0a534cae-de91-5e77-a3e7-b52d46bd3966\nFirst-Line Therapy\nyes\n'--\n'--\nSurgery, NOS\n\n\n4\nTCGA-BRCA\n00807dae-9f4a-4fd1-aac2-82eb11bf2afb\nInformed Consent\n19\n'--\nAdnexal and Skin Appendage Neoplasms\nDiagnosis\nNo\nBreast\nTCGA-A2-A04W\n...\n'--\n'--\n'--\n'--\n024faa94-ec57-4d14-b919-62dcab409958\nAdjuvant\nyes\nTreatment Ongoing\n'--\nBisphosphonate Therapy\n\n\n\n\n5 rows × 210 columns\n\n\n\nMissing data: From viewing both datasets, the missing data was represented as ’— and required replacing the placeholder string with numpy nontype in order to handle missing values efficiently.\nThe missing values per columns ranged from 0% to 100%, this was a limitation of the datasets especially due to a lot of demographic columns having a large percentage of missing values, as these columns might have been potential social determinants of survival days depending on the type of cancer,\n\n\ndemographic.year_of_birth: 0.00% missing values\ndemographic.age_at_index: 0.00% missing values\ndemographic.cause_of_death: 0.00% missing values\ndemographic.year_of_death: 0.00% missing values\ndemographic.vital_status: 0.00% missing values\ndemographic.cause_of_death: 0.00% missing values\ndemographic.education_level: 0.00% missing values\ndemographic.days_to_death: 0.00% missing values\n\n\nHowever, the demographic.vital_status column has fewer missing values, which still allowed for some analysis regarding survival status. Despite a large number of missing values in demographic.days_to_death, we reasonable assummed it is because the patient is alive since the missing values corresponded to alive in the vital_status column. In addition, days_to_last_follow_up also has fewer missing values (11% in the brca dataset, and 12% in the cesc dataset), which enabled inferring survival time in feature engineering.\nThe datasets had a lot of columns with missing data. The overall original view of missing data in the brca dataset is showed below:\n\n\n&lt;Figure size 1440x768 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\nMost of the missing values were initially dropped through the following logic:\n\nDrop of columns with more than 30% data missing (except days_to_death as it is a key column for analysis). This reduced the number of columns by ~75% (e.g., to 46 columns for brca)\nDrop of columns irrelevant to the task of analysing survival time for the two different types of cancers e.g., data consent - not a predictor of how someone will survive a cancer, year of diagnoses - age at diagnoses captures the effect\nDrop of duplicate rows and rows with greater than 30% of the data missing i.e., 30% of information on that patient missing\n\nThe above resulted in a cleaner dataset as shown below:\n\n\n\nDistribution of missing data after dropping missing values as described above\n\n\nAfterwards, missing data was cleaned as follows\n\nFor most of the columns, the missing values were replaced with the mode/most frequent value e.g., diasease_is_primary diasease as True, site_of_involvement as breast, pathologic n (lymph node component of cancer staging) as N0 (no regional lymph node metastasis) due to heavy imbalance towards specific classes\nOverall stage infered from pathologic n, pathologic t (size and extent of primary tumor), and pathologic m (distant metastasis - whether the cancer has spread to distant organs)\nHandling of missing data in days_to_death was handled in the machine learning component sections, this was due to the patients still being alive"
  },
  {
    "objectID": "technical-details/data-cleaning/instructions.html#data-type-correction-and-formattng",
    "href": "technical-details/data-cleaning/instructions.html#data-type-correction-and-formattng",
    "title": "Overview",
    "section": "",
    "text": "Iterative Process: Data cleaning is often not a one-time process. As your analysis progresses, you may need to revisit the cleaning phase, and re-run the code, to adjust to new insights or requirements.\nClarity and Reproducibility: Ensure your documentation is clear and thorough. Others should be able to follow your steps and achieve the same results.\nVisualizations: Use before-and-after visualizations to illustrate the impact of your cleaning steps, making the process more intuitive and transparent.\n\nBy the end of this phase, your cleaned data should be well-documented and ready for further stages, such as Exploratory Data Analysis (EDA) and Machine Learning."
  },
  {
    "objectID": "technical-details/data-cleaning/instructions.html#subsetting-the",
    "href": "technical-details/data-cleaning/instructions.html#subsetting-the",
    "title": "Overview",
    "section": "",
    "text": "The following is a list of some of the things you should address on this page. This list is not exhaustive, and you should use your judgment to decide what is most relevant to your project.\nThe Data Cleaning page of your portfolio is where you document the process of transforming your raw data into a usable format. Data cleaning is essential for ensuring the quality of your analysis, and this page should serve as a clear and reproducible guide for anyone reviewing your work. It also provides transparency, allowing others to trace the steps you took to prepare your data.\nThe following is a guide to help you get started with possible thing to address on this page .\n\nDescription of the Data Cleaning Process: Explain the steps you took to clean and preprocess the data.\nCode Documentation: Provide the code used in the data cleaning process (link to GitHub or embed the code directly).\nProvide examples of data before and after cleaning: e.g. with df.head() or df.describe()\nRaw and Cleaned Data Links: Ensure your page links to both the original (raw) dataset and the cleaned dataset. (please keep organized and store the cleaned data in data/processed-data, or similar location which doesn’t get synced to GitHub)\n\nPossible things to include:\nIntroduction to Data Cleaning:\n\nProvide a brief explanation of the data cleaning phase, its importance in preparing the data for further analysis (EDA, modeling), and its iterative nature.\nMention that data cleaning may need to be revisited as the project evolves and analysis goals change.\n\nManaging Missing Data:\n\nIdentify Missing Values: Explain how you identified missing data and where it occurred.\nHandling Missing Data: Describe how missing values were addressed (e.g., imputation, removal of rows/columns).\nVisualize Missing Data: Include visualizations (e.g., heatmaps) showing missing values before and after handling them.\n\nOutlier Detection and Treatment:\n\nIdentify Outliers: Describe the methods you used to detect outliers in the dataset.\nAddressing Outliers: Explain how outliers were treated (e.g., removal, transformation, or retaining them for analysis).\nVisualize Outliers: Use visualizations (e.g., box plots) to show how outliers were managed.\n\nData Type Correction and Formatting:\n\nReview Data Types: Summarize the types of variables (numerical, categorical, date-time, etc.) and ensure they are correctly formatted.\nTransformation: Document any transformations performed, such as converting date formats, handling categorical variables, or encoding labels.\nImpact of Changes: Briefly explain why these changes were necessary for accurate analysis.\n\nNormalization and Scaling:\n\nData Distribution Analysis: Check and discuss the distribution of numerical variables (e.g., skewness).\nNormalization Techniques: Describe any normalization or scaling techniques used (e.g., min-max scaling, z-score normalization).\nBefore-and-After Visualizations: Provide visualizations comparing the data before and after scaling or normalization.\n\nSubsetting the Data:\n\nData Filtering: Explain any subsetting or filtering of the data (e.g., selecting quantitative or qualitative columns).\nRationale: Justify why you chose to work with a particular subset of the data."
  },
  {
    "objectID": "technical-details/data-cleaning/instructions.html#subsetting-the-data",
    "href": "technical-details/data-cleaning/instructions.html#subsetting-the-data",
    "title": "Overview",
    "section": "",
    "text": "The following is a list of some of the things you should address on this page. This list is not exhaustive, and you should use your judgment to decide what is most relevant to your project.\nThe Data Cleaning page of your portfolio is where you document the process of transforming your raw data into a usable format. Data cleaning is essential for ensuring the quality of your analysis, and this page should serve as a clear and reproducible guide for anyone reviewing your work. It also provides transparency, allowing others to trace the steps you took to prepare your data.\nThe following is a guide to help you get started with possible thing to address on this page .\n\nDescription of the Data Cleaning Process: Explain the steps you took to clean and preprocess the data.\nCode Documentation: Provide the code used in the data cleaning process (link to GitHub or embed the code directly).\nProvide examples of data before and after cleaning: e.g. with df.head() or df.describe()\nRaw and Cleaned Data Links: Ensure your page links to both the original (raw) dataset and the cleaned dataset. (please keep organized and store the cleaned data in data/processed-data, or similar location which doesn’t get synced to GitHub)\n\nPossible things to include:\nIntroduction to Data Cleaning:\n\nProvide a brief explanation of the data cleaning phase, its importance in preparing the data for further analysis (EDA, modeling), and its iterative nature.\nMention that data cleaning may need to be revisited as the project evolves and analysis goals change.\n\nManaging Missing Data:\n\nIdentify Missing Values: Explain how you identified missing data and where it occurred.\nHandling Missing Data: Describe how missing values were addressed (e.g., imputation, removal of rows/columns).\nVisualize Missing Data: Include visualizations (e.g., heatmaps) showing missing values before and after handling them.\n\nOutlier Detection and Treatment:\n\nIdentify Outliers: Describe the methods you used to detect outliers in the dataset.\nAddressing Outliers: Explain how outliers were treated (e.g., removal, transformation, or retaining them for analysis).\nVisualize Outliers: Use visualizations (e.g., box plots) to show how outliers were managed.\n\nData Type Correction and Formatting:\n\nReview Data Types: Summarize the types of variables (numerical, categorical, date-time, etc.) and ensure they are correctly formatted.\nTransformation: Document any transformations performed, such as converting date formats, handling categorical variables, or encoding labels.\nImpact of Changes: Briefly explain why these changes were necessary for accurate analysis.\n\nNormalization and Scaling:\n\nData Distribution Analysis: Check and discuss the distribution of numerical variables (e.g., skewness).\nNormalization Techniques: Describe any normalization or scaling techniques used (e.g., min-max scaling, z-score normalization).\nBefore-and-After Visualizations: Provide visualizations comparing the data before and after scaling or normalization.\n\nSubsetting the Data:\n\nData Filtering: Explain any subsetting or filtering of the data (e.g., selecting quantitative or qualitative columns).\nRationale: Justify why you chose to work with a particular subset of the data."
  },
  {
    "objectID": "technical-details/data-cleaning/instructions.html#data-type-correction-and-formatting",
    "href": "technical-details/data-cleaning/instructions.html#data-type-correction-and-formatting",
    "title": "Overview",
    "section": "Data Type Correction and Formatting:",
    "text": "Data Type Correction and Formatting:\n\nData Types: All columns in the dataset are originally stored as object datatype\nTransformation: Columns were changed to numeric, boolean, and strings as needed in the dataset\n\nNumeric: days_to_death and days_to_last_follow_up were changed to numeric integers. age_at_diagnoses was changed from days to years for easier analysis during exploratory data analysis\nBoolean: Boolean columns were primarily coded as yes/no and these values were changed to True/False respectively\nStrings: Object columns were changed to lowercase strings and leading/trailing whitespace trimmed\n\nImpact of changes: These changes were primarily made with exploratory data analysis in mind and a longer term view towards survival time prediction. Changing age at diagnoses to years enabled better synthesis of multivariate analysis and while preserving days_to_death and days_to_last_follow_up preserved information as the columns are a measure of survival time. Boolean columns enabled efficient filtering and subseeting and the string columns were optimal for wordcloud analysis."
  },
  {
    "objectID": "technical-details/data-cleaning/instructions.html#data-engineering",
    "href": "technical-details/data-cleaning/instructions.html#data-engineering",
    "title": "Overview",
    "section": "Data Engineering:",
    "text": "Data Engineering:\nAfter validating the range and distribution of age_at_diagnosis (min of 26 years and max of 89 years), and handling negative values for days_to_last_follow_up by replacing them with the mean, our data engineering process involved extracting more data from columns. Primarily the two columns below were derived:\n\ndiagnosis.behavior: Tumor behavior was derived from the diagnoses.morphology field using the International Classification of Diseases for Oncology, Third Edition (ICD-O-3). Morphology codes follow the format ####/B, where the digit following the slash encodes tumor behavior (e.g., /3 indicates malignant primary disease). For example, morphology code 8500/3 corresponds to infiltrating duct carcinoma with malignant primary behavior. Behavior values were extracted and mapped to ordinal numeric representations following ICD-O-3 guidelines.1\nsurvival_time_days: Survival time was derived using clinical time-to-event variables provided by the Genomic Data Commons (GDC).2 For patients with a recorded death event, survival time was calculated as the difference between demographic.days_to_death and diagnoses.days_to_diagnosis, yielding the number of days survived following cancer diagnosis. For patients without a recorded death event (i.e., alive at last contact), survival time was defined as diagnoses.days_to_last_follow_up, representing the number of days from diagnosis to the most recent clinical follow-up. This approach follows standard survival analysis practice by treating deaths as observed events and living patients as right-censored observations. Missing values in days_to_death were therefore interpreted as censored outcomes rather than zero survival time. No additional adjustments or imputation were applied to survival duration to preserve the temporal integrity of the observed clinical timelines.\n\nFurther data engineering e.g., handling of multiple rows per patient due to multiple treatment types, were handled in feature engineering before machine learning in order to analyse variables in depth e.g., number of treatments. Additional columns are also dropped and some created after exploratory data analysis (EDA) continuing the process of data engineering.\nFor cervical cancer, data cleaning also included extracting the tobacco smoking status and unique ID from the exposure dataset. Unfortunately, the breast cancer exposure file contained only missing values, limiting our analysis. However, examining tobacco exposure in the cervical cancer dataset and not in the breast cancer dataset is epidemiologically justified as cigarette smoking is a recognized co-factor in cervical carcinogenesis while it is not considered a primary risk factor for breast cancer onset or progression, with prior research indicating weak, inconsistent, or indirect associations compared to dominant hormonal, genetic, and reproductive factors3"
  },
  {
    "objectID": "technical-details/data-cleaning/instructions.html#the-missing-values-were-cleaned-through-the-following-steps",
    "href": "technical-details/data-cleaning/instructions.html#the-missing-values-were-cleaned-through-the-following-steps",
    "title": "Overview",
    "section": "The missing values were cleaned through the following steps:",
    "text": "The missing values were cleaned through the following steps:"
  },
  {
    "objectID": "technical-details/data-cleaning/instructions.html#afterwards-missing-data-was-cleaned-as-follows",
    "href": "technical-details/data-cleaning/instructions.html#afterwards-missing-data-was-cleaned-as-follows",
    "title": "Overview",
    "section": "Afterwards, missing data was cleaned as follows",
    "text": "Afterwards, missing data was cleaned as follows"
  },
  {
    "objectID": "technical-details/data-cleaning/main.html#managing-missing-data",
    "href": "technical-details/data-cleaning/main.html#managing-missing-data",
    "title": "Data Cleaning",
    "section": "",
    "text": "#| echo: false\n#| warning: false\n#| tbl-cap: Rows showing a unique patient (cases.submitter_id) and their different treatments for breast cancer\n\n# Import relevant libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.io as pio\npio.renderers.default = \"notebook_connected\"\nimport missingno as msno\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom scipy import stats\nfrom scipy.stats import norm, skew\n\n# Import dataset\nbrca_df_original = pd.read_csv(\"../../data/raw-data/brca/brca-clinical.tsv\", sep=\"\\t\")\n\n# Create a copy of the original dataframe to work on\nbrca_df = brca_df_original.copy()\n\n# Display first few rows of the dataset\nbrca_df.head()\nMissing data: From viewing both datasets, the missing data was represented as ’— and required replacing the placeholder string with numpy nontype in order to handle missing values efficiently.\nThe missing values per columns ranged from 0% to 100%, this was a limitation of the datasets especially due to a lot of demographic columns having a large percentage of missing values, as these columns might have been potential social determinants of survival days depending on the type of cancer,\n#| echo: false\n#| warning: false\n#| tbl-cap: Distribution of missing values in key demographic columns\n\ncols_to_check = [\n    'demographic.year_of_birth',\n    'demographic.age_at_index',\n    'demographic.cause_of_death',\n    'demographic.year_of_death',\n    'demographic.vital_status',\n    'demographic.cause_of_death',\n    'demographic.education_level',\n    'demographic.days_to_death'\n]\nfor col in cols_to_check:\n    missing_percentage = brca_df[col].isnull().mean() * 100\n    print(f\"{col}: {missing_percentage:.2f}% missing values\")\nHowever, the demographic.vital_status column has fewer missing values, which still allowed for some analysis regarding survival status. Despite a large number of missing values in demographic.days_to_death, we reasonable assummed it is because the patient is alive since the missing values corresponded to alive in the vital_status column. In addition, days_to_last_follow_up also has fewer missing values (11% in the brca dataset, and 12% in the cesc dataset), which enabled inferring survival time in feature engineering.\nThe datasets had a lot of columns with missing data. The overall original view of missing data in the brca dataset is showed below:\n#| echo: false\n#| warning: false\n#| tbl-cap: Distribution of missing values in breast cancer dataset\n\n# Replace \"'--\" as NA\nbrca_df_original.replace('\\'--', np.nan, inplace=True)\nbrca_df.replace('\\'--', np.nan, inplace=True)\n\nplt.figure(figsize=(15, 8))\nmsno.matrix(brca_df)\nplt.title(\"Missing Data Matrix - Breast Cancer Dataset\", fontsize=14, fontweight='bold')\nplt.show()\nMost of the missing values were initially dropped through the following logic:\n\nDrop of columns with more than 30% data missing (except days_to_death as it is a key column for analysis). This reduced the number of columns by ~75% (e.g., to 46 columns for brca)\nDrop of columns irrelevant to the task of analysing survival time for the two different types of cancers e.g., data consent - not a predictor of how someone will survive a cancer, year of diagnoses - age at diagnoses captures the effect\nDrop of duplicate rows and rows with greater than 30% of the data missing i.e., 30% of information on that patient missing\n\nThe above resulted in a cleaner dataset as shown below:\n\n\n\nDistribution of missing data after dropping missing values as described above\n\n\nAfterwards, missing data was cleaned as follows\n\nFor most of the columns, the missing values were replaced with the mode/most frequent value e.g., diasease_is_primary diasease as True, site_of_involvement as breast, pathologic n (lymph node component of cancer staging) as N0 (no regional lymph node metastasis) due to heavy imbalance towards specific classes\nOverall stage infered from pathologic n, pathologic t (size and extent of primary tumor), and pathologic m (distant metastasis - whether the cancer has spread to distant organs)\nHandling of missing data in days_to_death was handled in the supervised learning section, this was due to the patients still being alive"
  },
  {
    "objectID": "technical-details/data-cleaning/main.html#data-type-correction-and-formatting",
    "href": "technical-details/data-cleaning/main.html#data-type-correction-and-formatting",
    "title": "Data Cleaning",
    "section": "",
    "text": "Data Types: All columns in the dataset are originally stored as object datatype\nTransformation: Columns were changed to numeric, boolean, and strings as needed in the dataset\n\nNumeric: days_to_death and days_to_last_follow_up were changed to numeric integers. age_at_diagnoses was changed from days to years for easier analysis during exploratory data analysis\nBoolean: Boolean columns were primarily coded as yes/no and these values were changed to True/False respectively\nStrings: Object columns were changed to lowercase strings and leading/trailing whitespace trimmed\n\nImpact of changes: These changes were primarily made with exploratory data analysis in mind and a longer term view towards survival time prediction. Changing age at diagnoses to years enabled better synthesis of multivariate analysis and while preserving days_to_death and days_to_last_follow_up preserved information as the columns are a measure of survival time. Boolean columns enabled efficient filtering and subseeting and the string columns were optimal for wordcloud analysis."
  },
  {
    "objectID": "technical-details/data-cleaning/main.html#data-engineering",
    "href": "technical-details/data-cleaning/main.html#data-engineering",
    "title": "Data Cleaning",
    "section": "",
    "text": "After validating the range and distribution of age_at_diagnosis (min of 26 years and max of 89 years), and handling negative values for days_to_last_follow_up by replacing them with the mean, our data engineering process involved extracting more data from columns. Primarily the two columns below were derived:\n\ndiagnosis.behavior: Tumor behavior was derived from the diagnoses.morphology field using the International Classification of Diseases for Oncology, Third Edition (ICD-O-3). Morphology codes follow the format ####/B, where the digit following the slash encodes tumor behavior (e.g., /3 indicates malignant primary disease). For example, morphology code 8500/3 corresponds to infiltrating duct carcinoma with malignant primary behavior. Behavior values were extracted and mapped to ordinal numeric representations following ICD-O-3 guidelines.1\nsurvival_time_days: Survival time was derived using clinical time-to-event variables provided by the Genomic Data Commons (GDC).2 For patients with a recorded death event, survival time was calculated as the difference between demographic.days_to_death and diagnoses.days_to_diagnosis, yielding the number of days survived following cancer diagnosis. For patients without a recorded death event (i.e., alive at last contact), survival time was defined as diagnoses.days_to_last_follow_up, representing the number of days from diagnosis to the most recent clinical follow-up. This approach follows standard survival analysis practice by treating deaths as observed events and living patients as right-censored observations. Missing values in days_to_death were therefore interpreted as censored outcomes rather than zero survival time. No additional adjustments or imputation were applied to survival duration to preserve the temporal integrity of the observed clinical timelines.\n\nFurther data engineering e.g., handling of multiple rows per patient due to multiple treatment types, were handled in feature engineering before machine learning in order to analyse variables in depth e.g., number of treatments. Additional columns are also dropped and some created after exploratory data analysis (EDA) continuing the process of data engineering.\nFor cervical cancer, data cleaning also included extracting the tobacco smoking status and unique ID from the exposure dataset. Unfortunately, the breast cancer exposure file contained only missing values, limiting our analysis. However, examining tobacco exposure in the cervical cancer dataset and not in the breast cancer dataset is epidemiologically justified as cigarette smoking is a recognized co-factor in cervical carcinogenesis while it is not considered a primary risk factor for breast cancer onset or progression, with prior research indicating weak, inconsistent, or indirect associations compared to dominant hormonal, genetic, and reproductive factors3"
  },
  {
    "objectID": "technical-details/data-cleaning/cesc-cleaning.html",
    "href": "technical-details/data-cleaning/cesc-cleaning.html",
    "title": "EDA for cervical cancer dataset",
    "section": "",
    "text": "# Import relevant libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.io as pio\npio.renderers.default = \"notebook_connected\"\nimport missingno as msno\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom scipy import stats\nfrom scipy.stats import norm, skew\n\n\n# Import dataset\ncesc_df_original = pd.read_csv(\"../../data/raw-data/cesc/cesc-clinical.tsv\", sep=\"\\t\")\n\n# Create a copy of the original dataframe to work on\ncesc_df = cesc_df_original.copy()\n\n# Display first few rows of the dataset\ncesc_df.head()\n\n\n\n\n\n\n\n\nproject.project_id\ncases.case_id\ncases.consent_type\ncases.days_to_consent\ncases.days_to_lost_to_followup\ncases.disease_type\ncases.index_date\ncases.lost_to_followup\ncases.primary_site\ncases.submitter_id\n...\ntreatments.treatment_duration\ntreatments.treatment_effect\ntreatments.treatment_effect_indicator\ntreatments.treatment_frequency\ntreatments.treatment_id\ntreatments.treatment_intent_type\ntreatments.treatment_or_therapy\ntreatments.treatment_outcome\ntreatments.treatment_outcome_duration\ntreatments.treatment_type\n\n\n\n\n0\nTCGA-CESC\n00ad0ffe-2105-4829-a495-1c2aceb5bb31\nInformed Consent\n0\n'--\nSquamous Cell Neoplasms\nDiagnosis\nYes\nCervix uteri\nTCGA-EK-A2R9\n...\n'--\n'--\n'--\n'--\n672b3cf9-bb40-4f6f-a1c9-69ac3383fbd5\n'--\n'--\n'--\n'--\nHysterectomy, NOS\n\n\n1\nTCGA-CESC\n00ad0ffe-2105-4829-a495-1c2aceb5bb31\nInformed Consent\n0\n'--\nSquamous Cell Neoplasms\nDiagnosis\nYes\nCervix uteri\nTCGA-EK-A2R9\n...\n'--\n'--\n'--\n'--\nd4baa31f-8c1f-5333-afcd-836816fd1a2a\nAdjuvant\nunknown\n'--\n'--\nPharmaceutical Therapy, NOS\n\n\n2\nTCGA-CESC\n00ad0ffe-2105-4829-a495-1c2aceb5bb31\nInformed Consent\n0\n'--\nSquamous Cell Neoplasms\nDiagnosis\nYes\nCervix uteri\nTCGA-EK-A2R9\n...\n'--\n'--\n'--\n'--\ne79370ba-36f0-4639-bc8f-119ba2b2457b\nAdjuvant\nunknown\n'--\n'--\nRadiation Therapy, NOS\n\n\n3\nTCGA-CESC\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nInformed Consent\n2108\n'--\nSquamous Cell Neoplasms\nDiagnosis\nYes\nCervix uteri\nTCGA-C5-A2LV\n...\n'--\n'--\n'--\n'--\n277d525e-9674-4954-b427-3e829d469b8f\n'--\n'--\n'--\n'--\nHysterectomy, NOS\n\n\n4\nTCGA-CESC\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nInformed Consent\n2108\n'--\nSquamous Cell Neoplasms\nDiagnosis\nYes\nCervix uteri\nTCGA-C5-A2LV\n...\n'--\n'--\n'--\n'--\n788ff156-d009-46f7-b832-f39b11ed13ac\nAdjuvant\nno\n'--\n'--\nRadiation Therapy, NOS\n\n\n\n\n5 rows × 210 columns\n\n\n\nFrom the first rows, we can see that there are several columns with missing values, represented as ’– . These values will be turned to NA for easier handling\n\n# Replace \"'--\" as NA\ncesc_df_original.replace('\\'--', np.nan, inplace=True)\ncesc_df.replace('\\'--', np.nan, inplace=True)\n\n\nInspect key columns for survival analysis\n\n# List all cols starting with 'demographic'\ndemographic_cols = [col for col in cesc_df.columns if col.startswith('demographic')]\nprint(\"Columns starting with 'demographic':\")\nfor col in demographic_cols:\n    print(f\"  - {col}\")\nprint(f\"\\nTotal demographic columns: {len(demographic_cols)}\")\n\n\nColumns starting with 'demographic':\n  - demographic.age_at_index\n  - demographic.age_is_obfuscated\n  - demographic.cause_of_death\n  - demographic.cause_of_death_source\n  - demographic.country_of_birth\n  - demographic.country_of_residence_at_enrollment\n  - demographic.days_to_birth\n  - demographic.days_to_death\n  - demographic.demographic_id\n  - demographic.education_level\n  - demographic.ethnicity\n  - demographic.gender\n  - demographic.marital_status\n  - demographic.occupation_duration_years\n  - demographic.population_group\n  - demographic.premature_at_birth\n  - demographic.race\n  - demographic.submitter_id\n  - demographic.vital_status\n  - demographic.weeks_gestation_at_birth\n  - demographic.year_of_birth\n  - demographic.year_of_death\n\nTotal demographic columns: 22\n\n\n\n# Check unique values in 'demographic.days_to_death'\ncesc_df[\"demographic.days_to_death\"].unique()\n\narray([nan, '543', '144', '355', '2052', '2859', '348', '469', '1394',\n       '4086', '253', '14', '506', '570', '951', '1245', '861', '2094',\n       '305', '607', '1186', '636', '642', '275', '879', '284', '370',\n       '523', '1118', '1453', '100', '227', '978', '132', '1011', '52',\n       '442', '252', '2520', '955', '166', '1083', '1372', '555', '1065',\n       '157', '414', '74', '908', '266', '471', '837', '3046', '1210',\n       '104', '350', '2888', '633', '492', '494', '829', '477', '638',\n       '582', '715', '1692', '773', '604', '2032', '659', '3097'],\n      dtype=object)\n\n\n\n# Check for percentage of missing values in 'demographic.days_to_death'\nmissing_percentage = cesc_df[\"demographic.days_to_death\"].isnull().mean()\nprint(f\"'Percentage of missing values in 'demographic.days_to_death' {missing_percentage:.2f}\")\n\n'Percentage of missing values in 'demographic.days_to_death' 0.72\n\n\n\n# Check to see if status is 'alive' where days_to_death is missing\nmissing_death_status = cesc_df[cesc_df[\"demographic.days_to_death\"].isnull()][\"demographic.vital_status\"].value_counts()\nmissing_death_status\n\ndemographic.vital_status\nAlive    1103\nName: count, dtype: int64\n\n\nWe can assume that the demographic.days_to_death column is crucial for survival analysis, as it indicates the time until death for each patient. Despite a significant number of missing values in this column, these are for patients who are still alive, as indicated by the demographic.vital_status column. Therefore, we can retain this column for analysis, treating missing values as censored data.\n\n# Drop rows where days_to_death is missing and vital_status is 'Dead'\ncesc_df = cesc_df[~((cesc_df[\"demographic.days_to_death\"].isnull()) & (cesc_df[\"demographic.vital_status\"] == 'Dead'))]\n\n\n# Check for percentage of missing values in diagnoses.days_to_last_follow_up\nmissing_percentage = cesc_df[\"diagnoses.days_to_last_follow_up\"].isnull().mean()\nprint(f\"'Percentage of missing values in 'diagnoses.days_to_last_follow_up' {missing_percentage:.2f}\")\n\n'Percentage of missing values in 'diagnoses.days_to_last_follow_up' 0.12\n\n\n\n# Check the distribution of vital_status when days_to_last_follow_up is missing\nmissing_followup_status = cesc_df[cesc_df[\"diagnoses.days_to_last_follow_up\"].isnull()][\"demographic.vital_status\"].value_counts()\nmissing_followup_status\n\ndemographic.vital_status\nDead     105\nAlive     86\nName: count, dtype: int64\n\n\n\n# Check the percentage of missing values for the following columns:\n# - demographic.year_of_birth\n# - demographic.year_of_death\n# - demographic.vital_status\n# - demographic.cause_of_death\n# - demographic.education_level\ncols_to_check = [\n    'demographic.year_of_birth',\n    'demographic.age_at_index',\n    'demographic.cause_of_death',\n    'demographic.year_of_death',\n    'demographic.vital_status',\n    'demographic.cause_of_death',\n    'demographic.education_level'\n]\nfor col in cols_to_check:\n    missing_percentage = cesc_df[col].isnull().mean() * 100\n    print(f\"{col}: {missing_percentage:.2f}% missing values\")\n\ndemographic.year_of_birth: 100.00% missing values\ndemographic.age_at_index: 0.00% missing values\ndemographic.cause_of_death: 71.86% missing values\ndemographic.year_of_death: 100.00% missing values\ndemographic.vital_status: 0.00% missing values\ndemographic.cause_of_death: 71.86% missing values\ndemographic.education_level: 100.00% missing values\n\n\nA lot of missing values in key demographic columns, especially in cause of death become a limiting factor for analysis.\n\n# Distribution of demographic.vital_status\nvital_status_counts = cesc_df['demographic.vital_status'].value_counts(dropna=False)\nprint(\"\\ndemographic.vital_status distribution:\")\nprint(vital_status_counts)\n\n\ndemographic.vital_status distribution:\ndemographic.vital_status\nAlive    1103\nDead      432\nName: count, dtype: int64\n\n\nHowever, the demographic.vital_status column has fewer missing values, which may still allow for some analysis regarding survival status. Despite large number of missing values in demographic.days_to_death, we can assume it is because the patient is alive since the missing values correspond to alive in the vital_status column. In addition, days_to_last_follow_up in the diagnoses table also has fewer missing values, which may be useful for survival time analysis.\n\n\nCheck for missing values\n\n# Missing data visualization\nplt.figure(figsize=(15, 8))\nmsno.matrix(cesc_df)\nplt.title(\"Missing Data Matrix - cervical cancer Dataset\", fontsize=14, fontweight='bold')\nplt.show()\n\n&lt;Figure size 1500x800 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\n# Drop columns with more than 30% missing values except for demographic.days_to_death and diagnoses.days_to_last_follow_up\n\n# Calculate missing percentage for each column\nmissing_percentages = cesc_df.isnull().mean()\n\n# Identify columns to drop (more than 30% missing, excluding the exceptions)\nexceptions = ['demographic.days_to_death', 'diagnoses.days_to_last_follow_up']\ncolumns_to_drop = []\n\nfor col in cesc_df.columns:\n    if col not in exceptions and missing_percentages[col] &gt; 0.3:\n        columns_to_drop.append(col)\n\nprint(f\"Columns to be dropped due to &gt;30% missing values: {columns_to_drop}\")\n\n# Drop the identified columns\ncesc_df = cesc_df.drop(columns=columns_to_drop)\n\n# Display the shape of the cleaned dataset\ncesc_df.shape\n\nColumns to be dropped due to &gt;30% missing values: ['cases.days_to_lost_to_followup', 'demographic.cause_of_death', 'demographic.cause_of_death_source', 'demographic.country_of_birth', 'demographic.education_level', 'demographic.marital_status', 'demographic.occupation_duration_years', 'demographic.population_group', 'demographic.premature_at_birth', 'demographic.weeks_gestation_at_birth', 'demographic.year_of_birth', 'demographic.year_of_death', 'diagnoses.adrenal_hormone', 'diagnoses.ajcc_clinical_m', 'diagnoses.ajcc_clinical_n', 'diagnoses.ajcc_clinical_stage', 'diagnoses.ajcc_clinical_t', 'diagnoses.ajcc_pathologic_stage', 'diagnoses.ajcc_serum_tumor_markers', 'diagnoses.ajcc_staging_system_edition', 'diagnoses.ann_arbor_b_symptoms', 'diagnoses.ann_arbor_b_symptoms_described', 'diagnoses.ann_arbor_clinical_stage', 'diagnoses.ann_arbor_extranodal_involvement', 'diagnoses.ann_arbor_pathologic_stage', 'diagnoses.best_overall_response', 'diagnoses.burkitt_lymphoma_clinical_variant', 'diagnoses.calgb_risk_group', 'diagnoses.cancer_detection_method', 'diagnoses.child_pugh_classification', 'diagnoses.clark_level', 'diagnoses.cog_liver_stage', 'diagnoses.cog_neuroblastoma_risk_group', 'diagnoses.cog_renal_stage', 'diagnoses.cog_rhabdomyosarcoma_risk_group', 'diagnoses.contiguous_organ_invaded', 'diagnoses.days_to_best_overall_response', 'diagnoses.days_to_last_known_disease_status', 'diagnoses.days_to_recurrence', 'diagnoses.double_expressor_lymphoma', 'diagnoses.double_hit_lymphoma', 'diagnoses.eln_risk_classification', 'diagnoses.enneking_msts_grade', 'diagnoses.enneking_msts_metastasis', 'diagnoses.enneking_msts_stage', 'diagnoses.enneking_msts_tumor_site', 'diagnoses.ensat_clinical_m', 'diagnoses.ensat_pathologic_n', 'diagnoses.ensat_pathologic_stage', 'diagnoses.ensat_pathologic_t', 'diagnoses.esophageal_columnar_dysplasia_degree', 'diagnoses.esophageal_columnar_metaplasia_present', 'diagnoses.fab_morphology_code', 'diagnoses.first_symptom_longest_duration', 'diagnoses.first_symptom_prior_to_diagnosis', 'diagnoses.gastric_esophageal_junction_involvement', 'diagnoses.gleason_grade_group', 'diagnoses.gleason_grade_tertiary', 'diagnoses.gleason_patterns_percent', 'diagnoses.gleason_score', 'diagnoses.goblet_cells_columnar_mucosa_present', 'diagnoses.igcccg_stage', 'diagnoses.inpc_grade', 'diagnoses.inpc_histologic_group', 'diagnoses.inrg_stage', 'diagnoses.inss_stage', 'diagnoses.international_prognostic_index', 'diagnoses.irs_group', 'diagnoses.irs_stage', 'diagnoses.ishak_fibrosis_score', 'diagnoses.iss_stage', 'diagnoses.last_known_disease_status', 'diagnoses.laterality', 'diagnoses.margin_distance', 'diagnoses.margins_involved_site', 'diagnoses.masaoka_stage', 'diagnoses.max_tumor_bulk_site', 'diagnoses.medulloblastoma_molecular_classification', 'diagnoses.melanoma_known_primary', 'diagnoses.metastasis_at_diagnosis', 'diagnoses.metastasis_at_diagnosis_site', 'diagnoses.micropapillary_features', 'diagnoses.mitosis_karyorrhexis_index', 'diagnoses.mitotic_count', 'diagnoses.ovarian_specimen_status', 'diagnoses.ovarian_surface_involvement', 'diagnoses.papillary_renal_cell_type', 'diagnoses.pediatric_kidney_staging', 'diagnoses.peritoneal_fluid_cytological_status', 'diagnoses.pregnant_at_diagnosis', 'diagnoses.primary_disease', 'diagnoses.primary_gleason_grade', 'diagnoses.progression_or_recurrence', 'diagnoses.residual_disease', 'diagnoses.satellite_nodule_present', 'diagnoses.secondary_gleason_grade', 'diagnoses.sites_of_involvement', 'diagnoses.sites_of_involvement_count', 'diagnoses.supratentorial_localization', 'diagnoses.tumor_burden', 'diagnoses.tumor_confined_to_organ_of_origin', 'diagnoses.tumor_depth', 'diagnoses.tumor_focality', 'diagnoses.tumor_grade_category', 'diagnoses.tumor_of_origin', 'diagnoses.tumor_regression_grade', 'diagnoses.uicc_clinical_m', 'diagnoses.uicc_clinical_n', 'diagnoses.uicc_clinical_stage', 'diagnoses.uicc_clinical_t', 'diagnoses.uicc_pathologic_m', 'diagnoses.uicc_pathologic_n', 'diagnoses.uicc_pathologic_stage', 'diagnoses.uicc_pathologic_t', 'diagnoses.uicc_staging_system_edition', 'diagnoses.ulceration_indicator', 'diagnoses.weiss_assessment_findings', 'diagnoses.weiss_assessment_score', 'diagnoses.who_cns_grade', 'diagnoses.who_nte_grade', 'diagnoses.wilms_tumor_histologic_subtype', 'treatments.chemo_concurrent_to_radiation', 'treatments.clinical_trial_indicator', 'treatments.course_number', 'treatments.days_to_treatment_end', 'treatments.days_to_treatment_start', 'treatments.drug_category', 'treatments.embolic_agent', 'treatments.initial_disease_status', 'treatments.lesions_treated_number', 'treatments.margin_distance', 'treatments.margin_status', 'treatments.margins_involved_site', 'treatments.number_of_cycles', 'treatments.number_of_fractions', 'treatments.prescribed_dose', 'treatments.prescribed_dose_units', 'treatments.pretreatment', 'treatments.protocol_identifier', 'treatments.radiosensitizing_agent', 'treatments.reason_treatment_ended', 'treatments.reason_treatment_not_given', 'treatments.regimen_or_line_of_therapy', 'treatments.residual_disease', 'treatments.route_of_administration', 'treatments.therapeutic_agents', 'treatments.therapeutic_level_achieved', 'treatments.therapeutic_levels_achieved', 'treatments.therapeutic_target_level', 'treatments.timepoint_category', 'treatments.treatment_anatomic_site', 'treatments.treatment_anatomic_sites', 'treatments.treatment_arm', 'treatments.treatment_dose', 'treatments.treatment_dose_max', 'treatments.treatment_dose_units', 'treatments.treatment_duration', 'treatments.treatment_effect', 'treatments.treatment_effect_indicator', 'treatments.treatment_frequency', 'treatments.treatment_intent_type', 'treatments.treatment_outcome', 'treatments.treatment_outcome_duration']\n\n\n(1535, 47)\n\n\n\n# Check distribution na values after dropping columns\nplt.figure(figsize=(15, 8))\nmsno.matrix(cesc_df)\nplt.title(\"Missing Data Matrix After Dropping Columns - cesc Clinical Dataset\", fontsize=14, fontweight='bold')\nplt.show()\n\n&lt;Figure size 1500x800 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\n\nCheck for duplicate IDs\n\n# Count unique IDs (cases.submitter_id)\n\nunique_ids = cesc_df['cases.submitter_id'].nunique()\nprint(f\"Number of unique IDs: {unique_ids}\")\n\nNumber of unique IDs: 307\n\n\nThe TGCA cesc dataset contains 1,082 unique patient IDs (cases.submitter_id) but 3554 rows in total. This is because the TCGA Schema is designed to have multiple samples per patient, capturing different aspects of the tumor biology. Each patient may have multiple entries corresponding to different sample types, such as primary tumor, metastatic tumor, or normal tissue adjacent to the tumor. This allows for a more comprehensive analysis of the cancer’s characteristics and progression within the same individual.\nThe tcga schema is hierarchical as follows:\nCase (cesc) -&gt; Diagnosis -&gt; Follow-up -&gt; Treatment -&gt; Biospecimens\nMost cesc patients have: - 1 diagnosis - 1 - 5 follow-up entries - 1 - 3 treatments - 2 - 4 tissue samples (tumor and normal)\n\n\nFilter columns based on task\nColumns that are not relevant to the predictive modeling task will be dropped. These include identifiers, dates, and other metadata that do not contribute to the prediction of breast cancer outcomes such as the following:\n\ncases.consent_type\ncases.days_to_consent\ndemographic.days_to_birth\ndemographic.age_at_index (will preserve diagnosis.age_at_diagnosis instead for age at diagnosis)\ndiagnoses.ajcc_staging_system_edition\ndiagnoses.diagnosis_id (captured in disease_type)\ndiagnoses.icd_10_code (captured in disease_type)\ndiagnoses.year_of_diagnosis (interested in age at diagnosis instead)\ntreatments.treatment_id\n\n\n# Drop irrelevant columns\ncolumns_to_drop = [\n    'cases.consent_type',\n    'cases.days_to_consent',\n    'demographic.days_to_birth',\n    'demographic.age_at_index',\n    'demographic.demographic_id',\n    'diagnoses.diagnosis_id',\n    'diagnoses.icd_10_code',\n    'diagnoses.year_of_diagnosis',\n    'treatments.treatment_id',\n    'demographic.country_of_residence_at_enrollment',\n    'diagnoses.diagnosis_is_primary_disease',\n    'demographic.age_is_obfuscated'\n]\n\n# Drop the existing columns\ncesc_df = cesc_df.drop(columns=columns_to_drop)\n\nprint(f\"Dataset shape after dropping columns: {cesc_df.shape}\")\n\nDataset shape after dropping columns: (1535, 35)\n\n\n\n# Check remaining column names\ncesc_df.columns.tolist()\n\n['project.project_id',\n 'cases.case_id',\n 'cases.disease_type',\n 'cases.index_date',\n 'cases.lost_to_followup',\n 'cases.primary_site',\n 'cases.submitter_id',\n 'demographic.days_to_death',\n 'demographic.ethnicity',\n 'demographic.gender',\n 'demographic.race',\n 'demographic.submitter_id',\n 'demographic.vital_status',\n 'diagnoses.age_at_diagnosis',\n 'diagnoses.ajcc_pathologic_m',\n 'diagnoses.ajcc_pathologic_n',\n 'diagnoses.ajcc_pathologic_t',\n 'diagnoses.classification_of_tumor',\n 'diagnoses.days_to_diagnosis',\n 'diagnoses.days_to_last_follow_up',\n 'diagnoses.figo_stage',\n 'diagnoses.figo_staging_edition_year',\n 'diagnoses.method_of_diagnosis',\n 'diagnoses.morphology',\n 'diagnoses.primary_diagnosis',\n 'diagnoses.prior_malignancy',\n 'diagnoses.prior_treatment',\n 'diagnoses.site_of_resection_or_biopsy',\n 'diagnoses.submitter_id',\n 'diagnoses.synchronous_malignancy',\n 'diagnoses.tissue_or_organ_of_origin',\n 'diagnoses.tumor_grade',\n 'treatments.submitter_id',\n 'treatments.treatment_or_therapy',\n 'treatments.treatment_type']\n\n\n\n# Using msno to visualize missing data in remaining columns\nplt.figure(figsize=(15, 8))\nmsno.matrix(cesc_df)\nplt.title(\"Missing Data Matrix After Dropping irrelevant columns - cesc Clinical Dataset\", fontsize=14, fontweight='bold')\nplt.show()\n\n&lt;Figure size 1500x800 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\n# Check missing value percentages again\n\nfor col in cesc_df.columns:\n    missing_percentage = cesc_df[col].isnull().mean() * 100\n    print(f\"{col}: {missing_percentage:.2f}% missing values\")\n\nproject.project_id: 0.00% missing values\ncases.case_id: 0.00% missing values\ncases.disease_type: 0.00% missing values\ncases.index_date: 0.00% missing values\ncases.lost_to_followup: 27.23% missing values\ncases.primary_site: 0.00% missing values\ncases.submitter_id: 0.00% missing values\ndemographic.days_to_death: 71.86% missing values\ndemographic.ethnicity: 0.00% missing values\ndemographic.gender: 0.00% missing values\ndemographic.race: 0.00% missing values\ndemographic.submitter_id: 0.00% missing values\ndemographic.vital_status: 0.00% missing values\ndiagnoses.age_at_diagnosis: 1.76% missing values\ndiagnoses.ajcc_pathologic_m: 23.52% missing values\ndiagnoses.ajcc_pathologic_n: 22.61% missing values\ndiagnoses.ajcc_pathologic_t: 22.28% missing values\ndiagnoses.classification_of_tumor: 0.00% missing values\ndiagnoses.days_to_diagnosis: 1.04% missing values\ndiagnoses.days_to_last_follow_up: 12.44% missing values\ndiagnoses.figo_stage: 16.22% missing values\ndiagnoses.figo_staging_edition_year: 16.09% missing values\ndiagnoses.method_of_diagnosis: 12.64% missing values\ndiagnoses.morphology: 0.00% missing values\ndiagnoses.primary_diagnosis: 0.00% missing values\ndiagnoses.prior_malignancy: 12.44% missing values\ndiagnoses.prior_treatment: 1.56% missing values\ndiagnoses.site_of_resection_or_biopsy: 0.00% missing values\ndiagnoses.submitter_id: 0.00% missing values\ndiagnoses.synchronous_malignancy: 12.44% missing values\ndiagnoses.tissue_or_organ_of_origin: 0.00% missing values\ndiagnoses.tumor_grade: 13.81% missing values\ntreatments.submitter_id: 0.39% missing values\ntreatments.treatment_or_therapy: 11.40% missing values\ntreatments.treatment_type: 0.39% missing values\n\n\n\n# Drop rows with missing cases.lost_to_followup\ncesc_df = cesc_df.dropna(subset=['cases.lost_to_followup'])\ncesc_df.shape\n\n(1117, 35)\n\n\n\n# Check distribution of rows that have a lot of missing values\ncesc_df[\"na_count\"] = cesc_df.isna().sum(axis=1)\nna_count_distribution = cesc_df['na_count'].value_counts().sort_index()\nprint(\"\\nDistribution of rows by number of missing values:\")\nprint(na_count_distribution)\n\n\nDistribution of rows by number of missing values:\nna_count\n0      52\n1     675\n2     115\n3      51\n4      83\n5      19\n6       6\n8       3\n9       3\n10     31\n11     67\n12      3\n13      3\n14      5\n16      1\nName: count, dtype: int64\n\n\n\n# Delete rows that have 10 or more missing values (representing over 25% of that entity info missing)\ncesc_df = cesc_df[cesc_df['na_count'] &lt; 9].drop(columns=['na_count'])\n\n\n# Delete rows that have missing age_at_diagnosis info since this is a critical variable for our analysis\ncesc_df = cesc_df[cesc_df['diagnoses.age_at_diagnosis'].notna()]\n\n\n# Check missing value percentages again\n\nfor col in cesc_df.columns:\n    missing_percentage = cesc_df[col].isnull().mean() * 100\n    print(f\"{col}: {missing_percentage:.2f}% missing values\")\n\nproject.project_id: 0.00% missing values\ncases.case_id: 0.00% missing values\ncases.disease_type: 0.00% missing values\ncases.index_date: 0.00% missing values\ncases.lost_to_followup: 0.00% missing values\ncases.primary_site: 0.00% missing values\ncases.submitter_id: 0.00% missing values\ndemographic.days_to_death: 91.57% missing values\ndemographic.ethnicity: 0.00% missing values\ndemographic.gender: 0.00% missing values\ndemographic.race: 0.00% missing values\ndemographic.submitter_id: 0.00% missing values\ndemographic.vital_status: 0.00% missing values\ndiagnoses.age_at_diagnosis: 0.00% missing values\ndiagnoses.ajcc_pathologic_m: 12.15% missing values\ndiagnoses.ajcc_pathologic_n: 11.24% missing values\ndiagnoses.ajcc_pathologic_t: 11.24% missing values\ndiagnoses.classification_of_tumor: 0.00% missing values\ndiagnoses.days_to_diagnosis: 0.00% missing values\ndiagnoses.days_to_last_follow_up: 0.30% missing values\ndiagnoses.figo_stage: 4.82% missing values\ndiagnoses.figo_staging_edition_year: 4.62% missing values\ndiagnoses.method_of_diagnosis: 0.30% missing values\ndiagnoses.morphology: 0.00% missing values\ndiagnoses.primary_diagnosis: 0.00% missing values\ndiagnoses.prior_malignancy: 0.30% missing values\ndiagnoses.prior_treatment: 0.30% missing values\ndiagnoses.site_of_resection_or_biopsy: 0.00% missing values\ndiagnoses.submitter_id: 0.00% missing values\ndiagnoses.synchronous_malignancy: 0.30% missing values\ndiagnoses.tissue_or_organ_of_origin: 0.00% missing values\ndiagnoses.tumor_grade: 1.00% missing values\ntreatments.submitter_id: 0.00% missing values\ntreatments.treatment_or_therapy: 12.85% missing values\ntreatments.treatment_type: 0.00% missing values\n\n\n\n# Check the distribution of the method_of_diagnosis since it has a significantly higher missing value percentage\nmethod_of_diagnosis_counts = cesc_df['diagnoses.method_of_diagnosis'].value_counts(dropna=False)\nprint(\"\\ndiagnoses.method_of_diagnosis distribution:\")\nprint(method_of_diagnosis_counts)\n\n\ndiagnoses.method_of_diagnosis distribution:\ndiagnoses.method_of_diagnosis\nBiopsy                              852\nSurgical Resection                   61\nCytology                             54\nDilation and Curettage Procedure     26\nNaN                                   3\nName: count, dtype: int64\n\n\nDue to the heavy imbalance leaning towards Biopsy for the diagnoses.method_of_diagnosis column, we can replace missing values with ‘Biopsy’ to retain more rows for analysis.\n\n# Set pandas options to display all columns\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', None)\n\n\n# Check distribution of diagnoses.ajcc_pathologic_n \najcc_pathologic_stage_counts = cesc_df['diagnoses.ajcc_pathologic_n'].value_counts(dropna=False)\nprint(\"\\ndiagnoses.ajcc_pathologic_n distribution:\")\nprint(ajcc_pathologic_stage_counts)\n\n\ndiagnoses.ajcc_pathologic_n distribution:\ndiagnoses.ajcc_pathologic_n\nN0     452\nNX     265\nN1     167\nNaN    112\nName: count, dtype: int64\n\n\n\n# Check distribution of diagnoses.ajcc_pathologic_m \najcc_pathologic_stage_counts = cesc_df['diagnoses.ajcc_pathologic_m'].value_counts(dropna=False)\nprint(\"\\ndiagnoses.ajcc_pathologic_m distribution:\")\nprint(ajcc_pathologic_stage_counts)\n\n\ndiagnoses.ajcc_pathologic_m distribution:\ndiagnoses.ajcc_pathologic_m\nMX     472\nM0     358\nNaN    121\nM1      45\nName: count, dtype: int64\n\n\n\n# Check distribution of diagnoses.ajcc_pathologic_t \najcc_pathologic_stage_counts = cesc_df['diagnoses.ajcc_pathologic_t'].value_counts(dropna=False)\nprint(\"\\ndiagnoses.ajcc_pathologic_t distribution:\")\nprint(ajcc_pathologic_stage_counts)\n\n\ndiagnoses.ajcc_pathologic_t distribution:\ndiagnoses.ajcc_pathologic_t\nT1b1    246\nT2b     132\nT1b2    115\nNaN     112\nT1b      94\nTX       50\nT2a2     49\nT3b      39\nT2a      35\nT2a1     32\nT4       30\nT2       23\nT3a      13\nT3       12\nTis       6\nT1a1      5\nT1        3\nName: count, dtype: int64\n\n\nThe missing values in the diagnoses.ajcc_pathologic_t, diagnoses.ajcc_pathologic_n, and diagnoses.ajcc_pathologic_m columns will be replaced by the mode of each column respectively due to the high imbalance.\n\n# Check distribution of diagnoses.treatment_or_therapy\ntreatment_or_therapy_counts = cesc_df['treatments.treatment_or_therapy'].value_counts(dropna=False)\nprint(\"\\ntreatments.treatment_or_therapy distribution:\")\nprint(treatment_or_therapy_counts)\n\n\ntreatments.treatment_or_therapy distribution:\ntreatments.treatment_or_therapy\nyes        545\nno         224\nNaN        128\nunknown     99\nName: count, dtype: int64\n\n\n\n# Check distribution od diagnoses.figo_stage\nfigo_stage_counts = cesc_df['diagnoses.figo_stage'].value_counts(dropna=False)\nprint(\"\\ndiagnoses.figo_stage distribution:\")\nprint(figo_stage_counts)\n\n\ndiagnoses.figo_stage distribution:\ndiagnoses.figo_stage\nStage IB1     272\nStage IIB     161\nStage IB2     134\nStage IIIB    117\nStage IB       72\nNaN            48\nStage IIA      34\nStage IVB      33\nStage IIA2     31\nStage IIA1     21\nStage IIIA     19\nStage I        16\nStage II       14\nStage IVA      10\nStage III       6\nStage IA1       5\nStage IA2       3\nName: count, dtype: int64\n\n\n\n# Check the distribution of diagnoses.figo_staging_edition_year\nfigo_staging_edition_year_counts = cesc_df['diagnoses.figo_staging_edition_year'].value_counts(dropna=False)\nprint(\"\\ndiagnoses.figo_staging_edition_year distribution:\")\nprint(figo_staging_edition_year_counts)\n\n\ndiagnoses.figo_staging_edition_year distribution:\ndiagnoses.figo_staging_edition_year\n2009    753\n1995    134\n1988     63\nNaN      46\nName: count, dtype: int64\n\n\n\n# Check the distribution of prior_malignancy\nprior_malignancy_counts = cesc_df['diagnoses.prior_malignancy'].value_counts(dropna=False)\nprint(\"\\ndiagnoses.prior_malignancy distribution:\")\nprint(prior_malignancy_counts)\n\n\ndiagnoses.prior_malignancy distribution:\ndiagnoses.prior_malignancy\nno              962\nyes              20\nnot reported     11\nNaN               3\nName: count, dtype: int64\n\n\n\n# Check distribution of diagnoses.tumor_grade\ntumor_grade_counts = cesc_df['diagnoses.tumor_grade'].value_counts(dropna=False)\nprint(\"\\ndiagnoses.tumor_grade distribution:\")\nprint(tumor_grade_counts)\n\n\ndiagnoses.tumor_grade distribution:\ndiagnoses.tumor_grade\nG2     437\nG3     399\nGX      86\nG1      60\nNaN     10\nG4       4\nName: count, dtype: int64\n\n\n\n\nClean NA values\nReplace the missing values in the following columns based on the assigned strategy: - diagnoses.method_of_diagnosis: ‘Core Biopsy’ (most frequent) - diagnoses.diagnosis_is_primary_disease: ‘True’ (most frequent) - diagnoses.prior_malignancy: ‘False’ (most frequent) - diagnoses.prior_treatment: ‘False’ (most frequent) - diagnoses.sites_of_involvement: ‘Breast’ (most frequent) - diagnoses.synchronous_malignancy: ‘False’ (most frequent) - diagnoses.treatment_or_therapy: True (most frequent) - diagnoses.figo_stage: ‘Stage IB1’ (most frequent) - diagnoses.figo_staging_edition_year: ‘2009’ (most frequent)\nDropping rows with missing diagnoses.ajcc_pathologic_m, diagnoses.ajcc_pathologic_n, diagnoses.ajcc_pathologic_t and tumor_grade since they are a small percentage and there is no clear imbalance to guide imputation.\n\n# Drop rows with missing diagnoses.ajcc_pathologic_m, diagnoses.ajcc_pathologic_n, diagnoses.ajcc_pathologic_t and tumor_grade\ncesc_df = cesc_df.dropna(subset=['diagnoses.ajcc_pathologic_m', 'diagnoses.ajcc_pathologic_n', 'diagnoses.ajcc_pathologic_t', 'diagnoses.tumor_grade'])\n\n\n# Replace missing values based on the strategy above:\n\n# Replace with most frequent values\ncesc_df['diagnoses.method_of_diagnosis'] = cesc_df['diagnoses.method_of_diagnosis'].fillna('Biopsy')\ncesc_df['diagnoses.prior_malignancy'] = cesc_df['diagnoses.prior_malignancy'].fillna('no')\ncesc_df['diagnoses.prior_treatment'] = cesc_df['diagnoses.prior_treatment'].fillna('no')\ncesc_df['diagnoses.synchronous_malignancy'] = cesc_df['diagnoses.synchronous_malignancy'].fillna('no')\ncesc_df['treatments.treatment_or_therapy'] = cesc_df['treatments.treatment_or_therapy'].fillna('yes')\ncesc_df['diagnoses.figo_stage'] = cesc_df['diagnoses.figo_stage'].fillna('Stage IB1')\ncesc_df['diagnoses.figo_staging_edition_year'] = cesc_df['diagnoses.figo_staging_edition_year'].fillna(2009)\n\n\n# Check distribution of treatments.treatment_or_therapy after imputation\ntreatment_or_therapy_counts = cesc_df['treatments.treatment_or_therapy'].value_counts(dropna=False)\nprint(\"\\ntreatments.treatment_or_therapy distribution after imputation:\")\nprint(treatment_or_therapy_counts)\n\n\ntreatments.treatment_or_therapy distribution after imputation:\ntreatments.treatment_or_therapy\nyes        583\nno         216\nunknown     73\nName: count, dtype: int64\n\n\n\n# Percentage of missing values in each column\n\nmissing_percentages = cesc_df.isnull().mean() * 100\nprint(\"\\nPercentage of missing values in each column:\")\nprint(missing_percentages)\n\n\nPercentage of missing values in each column:\nproject.project_id                        0.000000\ncases.case_id                             0.000000\ncases.disease_type                        0.000000\ncases.index_date                          0.000000\ncases.lost_to_followup                    0.000000\ncases.primary_site                        0.000000\ncases.submitter_id                        0.000000\ndemographic.days_to_death                92.889908\ndemographic.ethnicity                     0.000000\ndemographic.gender                        0.000000\ndemographic.race                          0.000000\ndemographic.submitter_id                  0.000000\ndemographic.vital_status                  0.000000\ndiagnoses.age_at_diagnosis                0.000000\ndiagnoses.ajcc_pathologic_m               0.000000\ndiagnoses.ajcc_pathologic_n               0.000000\ndiagnoses.ajcc_pathologic_t               0.000000\ndiagnoses.classification_of_tumor         0.000000\ndiagnoses.days_to_diagnosis               0.000000\ndiagnoses.days_to_last_follow_up          0.000000\ndiagnoses.figo_stage                      0.000000\ndiagnoses.figo_staging_edition_year       0.000000\ndiagnoses.method_of_diagnosis             0.000000\ndiagnoses.morphology                      0.000000\ndiagnoses.primary_diagnosis               0.000000\ndiagnoses.prior_malignancy                0.000000\ndiagnoses.prior_treatment                 0.000000\ndiagnoses.site_of_resection_or_biopsy     0.000000\ndiagnoses.submitter_id                    0.000000\ndiagnoses.synchronous_malignancy          0.000000\ndiagnoses.tissue_or_organ_of_origin       0.000000\ndiagnoses.tumor_grade                     0.000000\ntreatments.submitter_id                   0.000000\ntreatments.treatment_or_therapy           0.000000\ntreatments.treatment_type                 0.000000\ndtype: float64\n\n\n\n\nCheck for consistent data types\n\n# Check column data types\n\ncesc_df.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 872 entries, 3 to 1523\nData columns (total 35 columns):\n #   Column                                 Non-Null Count  Dtype \n---  ------                                 --------------  ----- \n 0   project.project_id                     872 non-null    object\n 1   cases.case_id                          872 non-null    object\n 2   cases.disease_type                     872 non-null    object\n 3   cases.index_date                       872 non-null    object\n 4   cases.lost_to_followup                 872 non-null    object\n 5   cases.primary_site                     872 non-null    object\n 6   cases.submitter_id                     872 non-null    object\n 7   demographic.days_to_death              62 non-null     object\n 8   demographic.ethnicity                  872 non-null    object\n 9   demographic.gender                     872 non-null    object\n 10  demographic.race                       872 non-null    object\n 11  demographic.submitter_id               872 non-null    object\n 12  demographic.vital_status               872 non-null    object\n 13  diagnoses.age_at_diagnosis             872 non-null    object\n 14  diagnoses.ajcc_pathologic_m            872 non-null    object\n 15  diagnoses.ajcc_pathologic_n            872 non-null    object\n 16  diagnoses.ajcc_pathologic_t            872 non-null    object\n 17  diagnoses.classification_of_tumor      872 non-null    object\n 18  diagnoses.days_to_diagnosis            872 non-null    object\n 19  diagnoses.days_to_last_follow_up       872 non-null    object\n 20  diagnoses.figo_stage                   872 non-null    object\n 21  diagnoses.figo_staging_edition_year    872 non-null    object\n 22  diagnoses.method_of_diagnosis          872 non-null    object\n 23  diagnoses.morphology                   872 non-null    object\n 24  diagnoses.primary_diagnosis            872 non-null    object\n 25  diagnoses.prior_malignancy             872 non-null    object\n 26  diagnoses.prior_treatment              872 non-null    object\n 27  diagnoses.site_of_resection_or_biopsy  872 non-null    object\n 28  diagnoses.submitter_id                 872 non-null    object\n 29  diagnoses.synchronous_malignancy       872 non-null    object\n 30  diagnoses.tissue_or_organ_of_origin    872 non-null    object\n 31  diagnoses.tumor_grade                  872 non-null    object\n 32  treatments.submitter_id                872 non-null    object\n 33  treatments.treatment_or_therapy        872 non-null    object\n 34  treatments.treatment_type              872 non-null    object\ndtypes: object(35)\nmemory usage: 245.2+ KB\n\n\n\n# Check the statistical summary of diagnoses.age_at_diagnosis\n\n# Convert to numeric \ncesc_df['diagnoses.age_at_diagnosis'] = pd.to_numeric(cesc_df['diagnoses.age_at_diagnosis'], errors='coerce')\n\n# Statistical summary\nprint(\"Statistical Summary of Age at Diagnosis:\")\nprint(cesc_df['diagnoses.age_at_diagnosis'].describe())\n\nprint(f\"\\nMean: {cesc_df['diagnoses.age_at_diagnosis'].mean():.2f}\")\nprint(f\"Median: {cesc_df['diagnoses.age_at_diagnosis'].median():.2f}\")\nprint(f\"Standard Deviation: {cesc_df['diagnoses.age_at_diagnosis'].std():.2f}\")\nprint(f\"Missing values: {cesc_df['diagnoses.age_at_diagnosis'].isna().sum()}\")\n\nStatistical Summary of Age at Diagnosis:\ncount      872.000000\nmean     17612.810780\nstd       4448.299744\nmin       9186.000000\n25%      14162.000000\n50%      16894.000000\n75%      20286.000000\nmax      29526.000000\nName: diagnoses.age_at_diagnosis, dtype: float64\n\nMean: 17612.81\nMedian: 16894.00\nStandard Deviation: 4448.30\nMissing values: 0\n\n\nThe age at diagnosis column has been converted to numeric but the values are in days. For analysis we will convert these to years by dividing by 365.25 (accounting for leap years) and rounding down\n\n# Convert age at diagnosis from days to years (integer)\ncesc_df['diagnoses.age_at_diagnosis'] = (cesc_df['diagnoses.age_at_diagnosis'] / 365.25).apply(np.floor)\n\n\n# Convert to integer\ncesc_df['diagnoses.age_at_diagnosis'] = pd.to_numeric(\n    cesc_df['diagnoses.age_at_diagnosis'], \n    errors='coerce'\n)\ncesc_df['diagnoses.age_at_diagnosis'].dtype\n\ndtype('float64')\n\n\n\n# Change all object type columns to lowercase\nfor col in cesc_df.select_dtypes(include=['object']).columns:\n    cesc_df[col] = cesc_df[col].astype(str).str.lower().replace('nan', np.nan)\n\n\n# Strip whitespace from string columns\nfor col in cesc_df.select_dtypes(include=['object']).columns:\n    cesc_df[col] = cesc_df[col].str.strip()\n\nChange other columns to boolean as appropriate: - diagnoses.diagnosis_is_primary_disease (from true/false strings) - diagnoses.prior_malignancy (from no/yes strings) - diagnoses.prior_treatment (from No/Yes strings) - diagnoses.synchronous_malignancy (from no/yes strings)\n\n# Convert diagnosis-related columns to boolean\n\n# Convert diagnoses.prior_malignancy (yes/no to boolean)\ncesc_df['diagnoses.prior_malignancy'] = cesc_df['diagnoses.prior_malignancy'].map({'yes': True, 'no': False})\n\n# Convert diagnoses.prior_treatment (yes/no to boolean)\ncesc_df['diagnoses.prior_treatment'] = cesc_df['diagnoses.prior_treatment'].map({'yes': True, 'no': False})\n\n# Convert diagnoses.synchronous_malignancy (yes/no to boolean)\ncesc_df['diagnoses.synchronous_malignancy'] = cesc_df['diagnoses.synchronous_malignancy'].map({'yes': True, 'no': False})\n\n# Check the conversions\nprint(\"Conversion results:\")\nprint(f\"diagnoses.prior_malignancy dtype: {cesc_df['diagnoses.prior_malignancy'].dtype}\")\nprint(f\"diagnoses.prior_treatment dtype: {cesc_df['diagnoses.prior_treatment'].dtype}\")\nprint(f\"diagnoses.synchronous_malignancy dtype: {cesc_df['diagnoses.synchronous_malignancy'].dtype}\")\n\nprint(\"\\nValue counts for each column:\")\nfor col in ['diagnoses.prior_malignancy', \n           'diagnoses.prior_treatment', 'diagnoses.synchronous_malignancy']:\n    print(f\"\\n{col}:\")\n    print(cesc_df[col].value_counts())\n\nConversion results:\ndiagnoses.prior_malignancy dtype: object\ndiagnoses.prior_treatment dtype: bool\ndiagnoses.synchronous_malignancy dtype: object\n\nValue counts for each column:\n\ndiagnoses.prior_malignancy:\ndiagnoses.prior_malignancy\nFalse    854\nTrue      15\nName: count, dtype: int64\n\ndiagnoses.prior_treatment:\ndiagnoses.prior_treatment\nFalse    872\nName: count, dtype: int64\n\ndiagnoses.synchronous_malignancy:\ndiagnoses.synchronous_malignancy\nFalse    869\nName: count, dtype: int64\n\n\n\n\nData Engineering\n\n# Percentage of missing values in each column\nmissing_percentages = cesc_df.isnull().mean() * 100\nprint(\"\\nPercentage of missing values in each column:\")\nprint(missing_percentages)\n\n\nPercentage of missing values in each column:\nproject.project_id                        0.000000\ncases.case_id                             0.000000\ncases.disease_type                        0.000000\ncases.index_date                          0.000000\ncases.lost_to_followup                    0.000000\ncases.primary_site                        0.000000\ncases.submitter_id                        0.000000\ndemographic.days_to_death                92.889908\ndemographic.ethnicity                     0.000000\ndemographic.gender                        0.000000\ndemographic.race                          0.000000\ndemographic.submitter_id                  0.000000\ndemographic.vital_status                  0.000000\ndiagnoses.age_at_diagnosis                0.000000\ndiagnoses.ajcc_pathologic_m               0.000000\ndiagnoses.ajcc_pathologic_n               0.000000\ndiagnoses.ajcc_pathologic_t               0.000000\ndiagnoses.classification_of_tumor         0.000000\ndiagnoses.days_to_diagnosis               0.000000\ndiagnoses.days_to_last_follow_up          0.000000\ndiagnoses.figo_stage                      0.000000\ndiagnoses.figo_staging_edition_year       0.000000\ndiagnoses.method_of_diagnosis             0.000000\ndiagnoses.morphology                      0.000000\ndiagnoses.primary_diagnosis               0.000000\ndiagnoses.prior_malignancy                0.344037\ndiagnoses.prior_treatment                 0.000000\ndiagnoses.site_of_resection_or_biopsy     0.000000\ndiagnoses.submitter_id                    0.000000\ndiagnoses.synchronous_malignancy          0.344037\ndiagnoses.tissue_or_organ_of_origin       0.000000\ndiagnoses.tumor_grade                     0.000000\ntreatments.submitter_id                   0.000000\ntreatments.treatment_or_therapy           0.000000\ntreatments.treatment_type                 0.000000\ndtype: float64\n\n\n\n# Check percentage of missing values in days_to_death when vital_status is 'dead'\nmissing_death_percentage = cesc_df[cesc_df['demographic.vital_status'] == 'dead']['demographic.days_to_death'].isnull().mean()\nprint(f\"Percentage of missing values in 'demographic.days_to_death' when vital_status is 'dead': {missing_death_percentage:.2%}\")    \n\nPercentage of missing values in 'demographic.days_to_death' when vital_status is 'dead': 0.00%\n\n\n\n# Percentage of missing values in days_to_last_follow_up when vital_status is 'alive'\nmissing_followup_percentage = cesc_df[cesc_df['demographic.vital_status'] == 'alive']['diagnoses.days_to_last_follow_up'].isnull().mean()\nprint(f\"Percentage of missing values in 'diagnoses.days_to_last_follow_up' when vital_status is 'alive': {missing_followup_percentage:.2%}\")\n\nPercentage of missing values in 'diagnoses.days_to_last_follow_up' when vital_status is 'alive': 0.00%\n\n\n\n# Create survival time column based on vital status\ndef calculate_survival_time(row):\n    if row['demographic.vital_status'] == 'dead':\n        return row['demographic.days_to_death']\n    elif row['demographic.vital_status'] == 'alive':\n        return row['diagnoses.days_to_last_follow_up']\n    else:\n        return np.nan\n    \ncesc_df['survival_time_days'] = cesc_df.apply(calculate_survival_time, axis=1)\n\n\n# Check percentage of missing values in survival_time_days\nmissing_percentage = cesc_df['survival_time_days'].isnull().mean() * 100\nprint(f\"Percentage of missing values in 'survival_time_days': {missing_percentage:.2f}%\")\n\nPercentage of missing values in 'survival_time_days': 0.00%\n\n\n\n# Drop rows with missing survival_time_days\ncesc_df = cesc_df[cesc_df['survival_time_days'].notna()]\ncesc_df.shape\n\n(872, 36)\n\n\n\n# Drop duplicate rows before feature engineering\ncesc_df = cesc_df.drop_duplicates()\ncesc_df.shape\n\n(872, 36)\n\n\n\n# Extract diagnoses.behavior from diagnoses.morphology column (e.g., 8500/3 -&gt; 3 where 3 is the behavior code)\n\n# Mappings for behavior codes\nbehavior_mapping = {\n    '0': 'benign',\n    '2': 'in situ',\n    '3': 'malignant'\n}\n# Extract behavior code and map to descriptive labels\ncesc_df['diagnoses.behavior'] = cesc_df['diagnoses.morphology'].str.split('/').str[1].map(behavior_mapping)\n# Check the new column\nprint(\"Value counts for diagnoses.behavior:\")\nprint(cesc_df['diagnoses.behavior'].value_counts())\n\nValue counts for diagnoses.behavior:\ndiagnoses.behavior\nmalignant    872\nName: count, dtype: int64\n\n\nNote: There is a heavy class imbalance for diagnoses.behavior as over 95% of the entries are malignant.\n\ncesc_df.head()\n\n\n\n\n\n\n\n\nproject.project_id\ncases.case_id\ncases.disease_type\ncases.index_date\ncases.lost_to_followup\ncases.primary_site\ncases.submitter_id\ndemographic.days_to_death\ndemographic.ethnicity\ndemographic.gender\ndemographic.race\ndemographic.submitter_id\ndemographic.vital_status\ndiagnoses.age_at_diagnosis\ndiagnoses.ajcc_pathologic_m\ndiagnoses.ajcc_pathologic_n\ndiagnoses.ajcc_pathologic_t\ndiagnoses.classification_of_tumor\ndiagnoses.days_to_diagnosis\ndiagnoses.days_to_last_follow_up\ndiagnoses.figo_stage\ndiagnoses.figo_staging_edition_year\ndiagnoses.method_of_diagnosis\ndiagnoses.morphology\ndiagnoses.primary_diagnosis\ndiagnoses.prior_malignancy\ndiagnoses.prior_treatment\ndiagnoses.site_of_resection_or_biopsy\ndiagnoses.submitter_id\ndiagnoses.synchronous_malignancy\ndiagnoses.tissue_or_organ_of_origin\ndiagnoses.tumor_grade\ntreatments.submitter_id\ntreatments.treatment_or_therapy\ntreatments.treatment_type\nsurvival_time_days\ndiagnoses.behavior\n\n\n\n\n3\ntcga-cesc\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nsquamous cell neoplasms\ndiagnosis\nyes\ncervix uteri\ntcga-c5-a2lv\nNaN\nnot hispanic or latino\nfemale\nblack or african american\ntcga-c5-a2lv_demographic\nalive\n36.0\nmx\nn1\nt1b\nprimary\n0\n2234.0\nstage ib\n1995\nbiopsy\n8070/3\nsquamous cell carcinoma, nos\nFalse\nFalse\ncervix uteri\ntcga-c5-a2lv_diagnosis\nFalse\ncervix uteri\ng3\ntcga-c5-a2lv_treatment3\nyes\nhysterectomy, nos\n2234.0\nmalignant\n\n\n4\ntcga-cesc\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nsquamous cell neoplasms\ndiagnosis\nyes\ncervix uteri\ntcga-c5-a2lv\nNaN\nnot hispanic or latino\nfemale\nblack or african american\ntcga-c5-a2lv_demographic\nalive\n36.0\nmx\nn1\nt1b\nprimary\n0\n2234.0\nstage ib\n1995\nbiopsy\n8070/3\nsquamous cell carcinoma, nos\nFalse\nFalse\ncervix uteri\ntcga-c5-a2lv_diagnosis\nFalse\ncervix uteri\ng3\ntcga-c5-a2lv_treatment2\nno\nradiation therapy, nos\n2234.0\nmalignant\n\n\n5\ntcga-cesc\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nsquamous cell neoplasms\ndiagnosis\nyes\ncervix uteri\ntcga-c5-a2lv\nNaN\nnot hispanic or latino\nfemale\nblack or african american\ntcga-c5-a2lv_demographic\nalive\n36.0\nmx\nn1\nt1b\nprimary\n0\n2234.0\nstage ib\n1995\nbiopsy\n8070/3\nsquamous cell carcinoma, nos\nFalse\nFalse\ncervix uteri\ntcga-c5-a2lv_diagnosis\nFalse\ncervix uteri\ng3\ntcga-c5-a2lv_treatment\nno\npharmaceutical therapy, nos\n2234.0\nmalignant\n\n\n11\ntcga-cesc\n03804f9b-df7c-462c-8984-8eb3a5ed4999\nsquamous cell neoplasms\ndiagnosis\nno\ncervix uteri\ntcga-vs-a9v2\nNaN\nnot reported\nfemale\nwhite\ntcga-vs-a9v2_demographic\nalive\n29.0\nmx\nn0\nt1b\nprimary\n0\n555.0\nstage ib1\n2009\nbiopsy\n8070/3\nsquamous cell carcinoma, nos\nFalse\nFalse\ncervix uteri\ntcga-vs-a9v2_diagnosis\nFalse\ncervix uteri\ng2\ntcga-vs-a9v2_treatment3\nyes\nradiation, 3d conformal\n555.0\nmalignant\n\n\n12\ntcga-cesc\n03804f9b-df7c-462c-8984-8eb3a5ed4999\nsquamous cell neoplasms\ndiagnosis\nno\ncervix uteri\ntcga-vs-a9v2\nNaN\nnot reported\nfemale\nwhite\ntcga-vs-a9v2_demographic\nalive\n29.0\nmx\nn0\nt1b\nprimary\n0\n555.0\nstage ib1\n2009\nbiopsy\n8070/3\nsquamous cell carcinoma, nos\nFalse\nFalse\ncervix uteri\ntcga-vs-a9v2_diagnosis\nFalse\ncervix uteri\ng2\ntcga-vs-a9v2_treatment2\nno\npharmaceutical therapy, nos\n555.0\nmalignant\n\n\n\n\n\n\n\n\n# Check distribution of missing values in columns after cleaning and data engineering\nmissing_percentages = cesc_df.isnull().mean() * 100\nprint(\"\\nPercentage of missing values in each column:\")\nprint(missing_percentages)\n\n\nPercentage of missing values in each column:\nproject.project_id                        0.000000\ncases.case_id                             0.000000\ncases.disease_type                        0.000000\ncases.index_date                          0.000000\ncases.lost_to_followup                    0.000000\ncases.primary_site                        0.000000\ncases.submitter_id                        0.000000\ndemographic.days_to_death                92.889908\ndemographic.ethnicity                     0.000000\ndemographic.gender                        0.000000\ndemographic.race                          0.000000\ndemographic.submitter_id                  0.000000\ndemographic.vital_status                  0.000000\ndiagnoses.age_at_diagnosis                0.000000\ndiagnoses.ajcc_pathologic_m               0.000000\ndiagnoses.ajcc_pathologic_n               0.000000\ndiagnoses.ajcc_pathologic_t               0.000000\ndiagnoses.classification_of_tumor         0.000000\ndiagnoses.days_to_diagnosis               0.000000\ndiagnoses.days_to_last_follow_up          0.000000\ndiagnoses.figo_stage                      0.000000\ndiagnoses.figo_staging_edition_year       0.000000\ndiagnoses.method_of_diagnosis             0.000000\ndiagnoses.morphology                      0.000000\ndiagnoses.primary_diagnosis               0.000000\ndiagnoses.prior_malignancy                0.344037\ndiagnoses.prior_treatment                 0.000000\ndiagnoses.site_of_resection_or_biopsy     0.000000\ndiagnoses.submitter_id                    0.000000\ndiagnoses.synchronous_malignancy          0.344037\ndiagnoses.tissue_or_organ_of_origin       0.000000\ndiagnoses.tumor_grade                     0.000000\ntreatments.submitter_id                   0.000000\ntreatments.treatment_or_therapy           0.000000\ntreatments.treatment_type                 0.000000\nsurvival_time_days                        0.000000\ndiagnoses.behavior                        0.000000\ndtype: float64\n\n\n\n# Replace missing prior_malignancy and synchronous_malignancy with False\ncesc_df['diagnoses.prior_malignancy'] = cesc_df['diagnoses.prior_malignancy'].fillna(False)\ncesc_df['diagnoses.synchronous_malignancy'] = cesc_df['diagnoses.synchronous_malignancy'].fillna(False)\n\n\ncesc_df.head(1)\n\n\n\n\n\n\n\n\nproject.project_id\ncases.case_id\ncases.disease_type\ncases.index_date\ncases.lost_to_followup\ncases.primary_site\ncases.submitter_id\ndemographic.days_to_death\ndemographic.ethnicity\ndemographic.gender\ndemographic.race\ndemographic.submitter_id\ndemographic.vital_status\ndiagnoses.age_at_diagnosis\ndiagnoses.ajcc_pathologic_m\ndiagnoses.ajcc_pathologic_n\ndiagnoses.ajcc_pathologic_t\ndiagnoses.classification_of_tumor\ndiagnoses.days_to_diagnosis\ndiagnoses.days_to_last_follow_up\ndiagnoses.figo_stage\ndiagnoses.figo_staging_edition_year\ndiagnoses.method_of_diagnosis\ndiagnoses.morphology\ndiagnoses.primary_diagnosis\ndiagnoses.prior_malignancy\ndiagnoses.prior_treatment\ndiagnoses.site_of_resection_or_biopsy\ndiagnoses.submitter_id\ndiagnoses.synchronous_malignancy\ndiagnoses.tissue_or_organ_of_origin\ndiagnoses.tumor_grade\ntreatments.submitter_id\ntreatments.treatment_or_therapy\ntreatments.treatment_type\nsurvival_time_days\ndiagnoses.behavior\n\n\n\n\n3\ntcga-cesc\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nsquamous cell neoplasms\ndiagnosis\nyes\ncervix uteri\ntcga-c5-a2lv\nNaN\nnot hispanic or latino\nfemale\nblack or african american\ntcga-c5-a2lv_demographic\nalive\n36.0\nmx\nn1\nt1b\nprimary\n0\n2234.0\nstage ib\n1995\nbiopsy\n8070/3\nsquamous cell carcinoma, nos\nFalse\nFalse\ncervix uteri\ntcga-c5-a2lv_diagnosis\nFalse\ncervix uteri\ng3\ntcga-c5-a2lv_treatment3\nyes\nhysterectomy, nos\n2234.0\nmalignant\n\n\n\n\n\n\n\n\n\nCervical cancer exposure data cleaning\n\n# Open cesc exposure tsv data\n\ncesc_exposure_df = pd.read_csv('../../data/raw-data/cesc/exposure.tsv', sep='\\t')\ncesc_exposure_df.head(3)\n\n\n\n\n\n\n\n\nproject.project_id\ncases.case_id\ncases.submitter_id\nexposures.age_at_last_exposure\nexposures.age_at_onset\nexposures.alcohol_days_per_week\nexposures.alcohol_drinks_per_day\nexposures.alcohol_frequency\nexposures.alcohol_history\nexposures.alcohol_intensity\nexposures.alcohol_type\nexposures.asbestos_exposure\nexposures.asbestos_exposure_type\nexposures.chemical_exposure_type\nexposures.cigarettes_per_day\nexposures.coal_dust_exposure\nexposures.environmental_tobacco_smoke_exposure\nexposures.exposure_duration\nexposures.exposure_duration_hrs_per_day\nexposures.exposure_duration_years\nexposures.exposure_id\nexposures.exposure_source\nexposures.exposure_type\nexposures.occupation_duration_years\nexposures.occupation_type\nexposures.pack_years_smoked\nexposures.parent_with_radiation_exposure\nexposures.radon_exposure\nexposures.respirable_crystalline_silica_exposure\nexposures.secondhand_smoke_as_child\nexposures.smoking_frequency\nexposures.submitter_id\nexposures.time_between_waking_and_first_smoke\nexposures.tobacco_smoking_onset_year\nexposures.tobacco_smoking_quit_year\nexposures.tobacco_smoking_status\nexposures.type_of_smoke_exposure\nexposures.type_of_tobacco_used\nexposures.use_per_day\nexposures.years_smoked\n\n\n\n\n0\nTCGA-CESC\n00ad0ffe-2105-4829-a495-1c2aceb5bb31\nTCGA-EK-A2R9\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\nTobacco\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\nNot Reported\n'--\n'--\n'--\n'--\n\n\n1\nTCGA-CESC\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nTCGA-C5-A2LV\n'--\n20\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\nTobacco\n'--\n'--\n16.0\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\nCurrent Smoker\n'--\n'--\n'--\n'--\n\n\n2\nTCGA-CESC\n010a807f-9dc0-4e14-9533-dcf478f3d947\nTCGA-C5-A902\n'--\n14\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\nTobacco\n'--\n'--\n21.0\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\n'--\nCurrent Smoker\n'--\n'--\n'--\n'--\n\n\n\n\n\n\n\n\n# Change every column to lowercase\nfor col in cesc_exposure_df.select_dtypes(include=['object']).columns:\n    cesc_exposure_df[col] = cesc_exposure_df[col].astype(str).str.lower().replace('nan', np.nan)\n\n\n# Strip whitespace from string columns\nfor col in cesc_exposure_df.select_dtypes(include=['object']).columns:\n    cesc_exposure_df[col] = cesc_exposure_df[col].str.strip()\n\n\n# Double check for common cases.submitter_id between clinical and exposure datasets\ncommon_ids = set(cesc_df['cases.submitter_id']).intersection(set(cesc_exposure_df['cases.submitter_id']))\nprint(f\"Number of common cases.submitter_id between clinical and exposure datasets: {len(common_ids)}\")\n\nNumber of common cases.submitter_id between clinical and exposure datasets: 184\n\n\n\n# Replace \"'--\" as NA\ncesc_exposure_df.replace('\\'--', np.nan, inplace=True)\ncesc_exposure_df.replace('\\'--', np.nan, inplace=True)\n\n\n# Check distribution of null values in exposure dataset\nmissing_percentages = cesc_exposure_df.isnull().mean() * 100\nprint(\"\\nPercentage of missing values in each column of exposure dataset:\")\nprint(missing_percentages)\n\n\nPercentage of missing values in each column of exposure dataset:\nproject.project_id                                    0.000000\ncases.case_id                                         0.000000\ncases.submitter_id                                    0.000000\nexposures.age_at_last_exposure                      100.000000\nexposures.age_at_onset                               72.312704\nexposures.alcohol_days_per_week                     100.000000\nexposures.alcohol_drinks_per_day                    100.000000\nexposures.alcohol_frequency                         100.000000\nexposures.alcohol_history                           100.000000\nexposures.alcohol_intensity                         100.000000\nexposures.alcohol_type                              100.000000\nexposures.asbestos_exposure                         100.000000\nexposures.asbestos_exposure_type                    100.000000\nexposures.chemical_exposure_type                    100.000000\nexposures.cigarettes_per_day                        100.000000\nexposures.coal_dust_exposure                        100.000000\nexposures.environmental_tobacco_smoke_exposure      100.000000\nexposures.exposure_duration                         100.000000\nexposures.exposure_duration_hrs_per_day             100.000000\nexposures.exposure_duration_years                   100.000000\nexposures.exposure_id                               100.000000\nexposures.exposure_source                           100.000000\nexposures.exposure_type                               0.000000\nexposures.occupation_duration_years                 100.000000\nexposures.occupation_type                           100.000000\nexposures.pack_years_smoked                          69.706840\nexposures.parent_with_radiation_exposure            100.000000\nexposures.radon_exposure                            100.000000\nexposures.respirable_crystalline_silica_exposure    100.000000\nexposures.secondhand_smoke_as_child                 100.000000\nexposures.smoking_frequency                         100.000000\nexposures.submitter_id                              100.000000\nexposures.time_between_waking_and_first_smoke       100.000000\nexposures.tobacco_smoking_onset_year                100.000000\nexposures.tobacco_smoking_quit_year                  85.993485\nexposures.tobacco_smoking_status                      0.000000\nexposures.type_of_smoke_exposure                    100.000000\nexposures.type_of_tobacco_used                      100.000000\nexposures.use_per_day                               100.000000\nexposures.years_smoked                              100.000000\ndtype: float64\n\n\n\n# Check exposures.tobacco_smoking_status column since they are the only ones with low missing values\nsmoking_status_counts = cesc_exposure_df['exposures.tobacco_smoking_status'].value_counts(dropna=False)\nprint(\"\\nexposures.tobacco_smoking_status distribution:\")\nprint(smoking_status_counts)\n\n\nexposures.tobacco_smoking_status distribution:\nexposures.tobacco_smoking_status\nlifelong non-smoker                                146\ncurrent smoker                                      64\ncurrent reformed smoker for &lt; or = 15 yrs           40\nnot reported                                        32\nunknown                                             12\ncurrent reformed smoker for &gt; 15 yrs                 9\ncurrent reformed smoker, duration not specified      4\nName: count, dtype: int64\n\n\n\n# Join clinical and exposure datasets on cases.submitter_id preserving only exposures.tobacco_smoking_status from exposure dataset\ncesc_merged_df = pd.merge(\n    cesc_df,\n    cesc_exposure_df[['cases.submitter_id', 'exposures.tobacco_smoking_status']],\n    on='cases.submitter_id',\n    how='left'\n)\n\n\ncesc_exposure_df[\"exposures.tobacco_smoking_status\"].head(5)\n\n0                                 not reported\n1                               current smoker\n2                               current smoker\n3                          lifelong non-smoker\n4    current reformed smoker for &lt; or = 15 yrs\nName: exposures.tobacco_smoking_status, dtype: object\n\n\n\ncesc_merged_df.head(1)\n\n\n\n\n\n\n\n\nproject.project_id\ncases.case_id\ncases.disease_type\ncases.index_date\ncases.lost_to_followup\ncases.primary_site\ncases.submitter_id\ndemographic.days_to_death\ndemographic.ethnicity\ndemographic.gender\ndemographic.race\ndemographic.submitter_id\ndemographic.vital_status\ndiagnoses.age_at_diagnosis\ndiagnoses.ajcc_pathologic_m\ndiagnoses.ajcc_pathologic_n\ndiagnoses.ajcc_pathologic_t\ndiagnoses.classification_of_tumor\ndiagnoses.days_to_diagnosis\ndiagnoses.days_to_last_follow_up\ndiagnoses.figo_stage\ndiagnoses.figo_staging_edition_year\ndiagnoses.method_of_diagnosis\ndiagnoses.morphology\ndiagnoses.primary_diagnosis\ndiagnoses.prior_malignancy\ndiagnoses.prior_treatment\ndiagnoses.site_of_resection_or_biopsy\ndiagnoses.submitter_id\ndiagnoses.synchronous_malignancy\ndiagnoses.tissue_or_organ_of_origin\ndiagnoses.tumor_grade\ntreatments.submitter_id\ntreatments.treatment_or_therapy\ntreatments.treatment_type\nsurvival_time_days\ndiagnoses.behavior\nexposures.tobacco_smoking_status\n\n\n\n\n0\ntcga-cesc\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nsquamous cell neoplasms\ndiagnosis\nyes\ncervix uteri\ntcga-c5-a2lv\nNaN\nnot hispanic or latino\nfemale\nblack or african american\ntcga-c5-a2lv_demographic\nalive\n36.0\nmx\nn1\nt1b\nprimary\n0\n2234.0\nstage ib\n1995\nbiopsy\n8070/3\nsquamous cell carcinoma, nos\nFalse\nFalse\ncervix uteri\ntcga-c5-a2lv_diagnosis\nFalse\ncervix uteri\ng3\ntcga-c5-a2lv_treatment3\nyes\nhysterectomy, nos\n2234.0\nmalignant\ncurrent smoker\n\n\n\n\n\n\n\n\n# View percentage of missing values in columns after merging\nmissing_percentages = cesc_merged_df.isnull().mean() * 100\nprint(\"\\nPercentage of missing values in each column after merging:\")\nprint(missing_percentages)\n\n\nPercentage of missing values in each column after merging:\nproject.project_id                        0.000000\ncases.case_id                             0.000000\ncases.disease_type                        0.000000\ncases.index_date                          0.000000\ncases.lost_to_followup                    0.000000\ncases.primary_site                        0.000000\ncases.submitter_id                        0.000000\ndemographic.days_to_death                92.889908\ndemographic.ethnicity                     0.000000\ndemographic.gender                        0.000000\ndemographic.race                          0.000000\ndemographic.submitter_id                  0.000000\ndemographic.vital_status                  0.000000\ndiagnoses.age_at_diagnosis                0.000000\ndiagnoses.ajcc_pathologic_m               0.000000\ndiagnoses.ajcc_pathologic_n               0.000000\ndiagnoses.ajcc_pathologic_t               0.000000\ndiagnoses.classification_of_tumor         0.000000\ndiagnoses.days_to_diagnosis               0.000000\ndiagnoses.days_to_last_follow_up          0.000000\ndiagnoses.figo_stage                      0.000000\ndiagnoses.figo_staging_edition_year       0.000000\ndiagnoses.method_of_diagnosis             0.000000\ndiagnoses.morphology                      0.000000\ndiagnoses.primary_diagnosis               0.000000\ndiagnoses.prior_malignancy                0.000000\ndiagnoses.prior_treatment                 0.000000\ndiagnoses.site_of_resection_or_biopsy     0.000000\ndiagnoses.submitter_id                    0.000000\ndiagnoses.synchronous_malignancy          0.000000\ndiagnoses.tissue_or_organ_of_origin       0.000000\ndiagnoses.tumor_grade                     0.000000\ntreatments.submitter_id                   0.000000\ntreatments.treatment_or_therapy           0.000000\ntreatments.treatment_type                 0.000000\nsurvival_time_days                        0.000000\ndiagnoses.behavior                        0.000000\nexposures.tobacco_smoking_status          0.000000\ndtype: float64\n\n\n\n\nSave processed dataset\n\n# Save cleaned dataset to a new TSV file\ncesc_merged_df.to_csv(\"../../data/processed-data/cesc/cesc-clinical-processed.tsv\", sep=\"\\t\", index=False)"
  },
  {
    "objectID": "technical-details/data-cleaning/brca-cleaning.html",
    "href": "technical-details/data-cleaning/brca-cleaning.html",
    "title": "EDA for breast cancer dataset",
    "section": "",
    "text": "# Import relevant libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.io as pio\npio.renderers.default = \"notebook_connected\"\nimport missingno as msno\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom scipy import stats\nfrom scipy.stats import norm, skew\n\n\n# Import dataset\nbrca_df_original = pd.read_csv(\"../../data/raw-data/brca/brca-clinical.tsv\", sep=\"\\t\")\n\n# Create a copy of the original dataframe to work on\nbrca_df = brca_df_original.copy()\n\n# Display first few rows of the dataset\nbrca_df.head()\n\n\n\n\n\n\n\n\nproject.project_id\ncases.case_id\ncases.consent_type\ncases.days_to_consent\ncases.days_to_lost_to_followup\ncases.disease_type\ncases.index_date\ncases.lost_to_followup\ncases.primary_site\ncases.submitter_id\n...\ntreatments.treatment_duration\ntreatments.treatment_effect\ntreatments.treatment_effect_indicator\ntreatments.treatment_frequency\ntreatments.treatment_id\ntreatments.treatment_intent_type\ntreatments.treatment_or_therapy\ntreatments.treatment_outcome\ntreatments.treatment_outcome_duration\ntreatments.treatment_type\n\n\n\n\n0\nTCGA-BRCA\n001cef41-ff86-4d3f-a140-a647ac4b10a1\nInformed Consent\n-34\n'--\nDuctal and Lobular Neoplasms\nDiagnosis\n'--\nBreast\nTCGA-E2-A1IU\n...\n'--\n'--\n'--\n'--\n1b884f21-eb24-467f-aba2-208af17070b9\nAdjuvant\nno\n'--\n'--\nRadiation Therapy, NOS\n\n\n1\nTCGA-BRCA\n001cef41-ff86-4d3f-a140-a647ac4b10a1\nInformed Consent\n-34\n'--\nDuctal and Lobular Neoplasms\nDiagnosis\n'--\nBreast\nTCGA-E2-A1IU\n...\n'--\n'--\n'--\n'--\n27868bc3-23c8-5e85-a0e2-314e6cdf9b2a\nAdjuvant\nyes\nTreatment Ongoing\n'--\nHormone Therapy\n\n\n2\nTCGA-BRCA\n001cef41-ff86-4d3f-a140-a647ac4b10a1\nInformed Consent\n-34\n'--\nDuctal and Lobular Neoplasms\nDiagnosis\n'--\nBreast\nTCGA-E2-A1IU\n...\n'--\n'--\n'--\n'--\naedf144c-6b7b-4d76-a3cb-4271aef10f1d\nFirst-Line Therapy\nyes\n'--\n'--\nSurgery, NOS\n\n\n3\nTCGA-BRCA\n0045349c-69d9-4306-a403-c9c1fa836644\nInformed Consent\n76\n'--\nAdenomas and Adenocarcinomas\nDiagnosis\n'--\nBreast\nTCGA-A1-A0SB\n...\n'--\n'--\n'--\n'--\n0a534cae-de91-5e77-a3e7-b52d46bd3966\nFirst-Line Therapy\nyes\n'--\n'--\nSurgery, NOS\n\n\n4\nTCGA-BRCA\n00807dae-9f4a-4fd1-aac2-82eb11bf2afb\nInformed Consent\n19\n'--\nAdnexal and Skin Appendage Neoplasms\nDiagnosis\nNo\nBreast\nTCGA-A2-A04W\n...\n'--\n'--\n'--\n'--\n024faa94-ec57-4d14-b919-62dcab409958\nAdjuvant\nyes\nTreatment Ongoing\n'--\nBisphosphonate Therapy\n\n\n\n\n5 rows × 210 columns\n\n\n\n\n# Check the shape of the dataset\nbrca_df.shape\n\n(5546, 210)\n\n\nFrom the first rows, we can see that there are several columns with missing values, represented as ’– . These values will be turned to NA for easier handling\n\n# Replace \"'--\" as NA\nbrca_df_original.replace('\\'--', np.nan, inplace=True)\nbrca_df.replace('\\'--', np.nan, inplace=True)\n\n\nInspect key columns for survival analysis\n\n# List all cols starting with 'demographic'\ndemographic_cols = [col for col in brca_df.columns if col.startswith('demographic')]\nprint(\"Columns starting with 'demographic':\")\nfor col in demographic_cols:\n    print(f\"  - {col}\")\nprint(f\"\\nTotal demographic columns: {len(demographic_cols)}\")\n\n\nColumns starting with 'demographic':\n  - demographic.age_at_index\n  - demographic.age_is_obfuscated\n  - demographic.cause_of_death\n  - demographic.cause_of_death_source\n  - demographic.country_of_birth\n  - demographic.country_of_residence_at_enrollment\n  - demographic.days_to_birth\n  - demographic.days_to_death\n  - demographic.demographic_id\n  - demographic.education_level\n  - demographic.ethnicity\n  - demographic.gender\n  - demographic.marital_status\n  - demographic.occupation_duration_years\n  - demographic.population_group\n  - demographic.premature_at_birth\n  - demographic.race\n  - demographic.submitter_id\n  - demographic.vital_status\n  - demographic.weeks_gestation_at_birth\n  - demographic.year_of_birth\n  - demographic.year_of_death\n\nTotal demographic columns: 22\n\n\n\n# Check unique values in 'demographic.days_to_death'\nbrca_df[\"demographic.days_to_death\"].unique()\n\narray([nan, '991', '571', '2534', '1793', '538', '320', '2483', '1812',\n       '255', '3926', '723', '1673', '2373', '3941', '2573', '1034',\n       '7455', '584', '2965', '1649', '266', '3945', '785', '1563', '426',\n       '1275', '2911', '224', '3409', '158', '4456', '239', '616', '302',\n       '322', '1009', '227', '1993', '365', '2009', '362', '116', '2798',\n       '3126', '904', '2273', '1272', '860', '2097', '2763', '3462',\n       '3959', '573', '1439', '2469', '921', '336', '3873', '1781',\n       '2361', '295', '1900', '1920', '786', '468', '1127', '959', '1556',\n       '883', '2192', '749', '943', '879', '2417', '1430', '1508', '0',\n       '1388', '2127', '2520', '30', '614', '1884', '1468', '3063',\n       '1152', '976', '678', '1365', '2551', '1694', '811', '1286', '639',\n       '967', '1032', '385', '1072', '912', '825', '1174', '792', '3472',\n       '1642', '6593', '6456', '1688', '1104', '3262', '4267', '612',\n       '548', '2348', '172', '1411', '160', '2854', '577', '348', '563',\n       '446', '1699', '1692', '1004', '1048', '1759', '2866', '1093',\n       '2712', '1324', '754', '3669', '524', '377', '1', '558', '821',\n       '2296', '3461', '2207', '1927', '1142', '2636', '197'],\n      dtype=object)\n\n\n\n# Check for percentage of missing values in 'demographic.days_to_death'\nmissing_percentage = brca_df[\"demographic.days_to_death\"].isnull().mean()\nprint(f\"'Percentage of missing values in 'demographic.days_to_death' {missing_percentage:.2f}\")\n\n'Percentage of missing values in 'demographic.days_to_death' 0.85\n\n\n\n# Check to see if status is 'alive' where days_to_death is missing\nmissing_death_status = brca_df[brca_df[\"demographic.days_to_death\"].isnull()][\"demographic.vital_status\"].value_counts()\nmissing_death_status\n\ndemographic.vital_status\nAlive    4697\nDead        3\nName: count, dtype: int64\n\n\nWe can assume that the demographic.days_to_death column is crucial for survival analysis, as it indicates the time until death for each patient. Despite a significant number of missing values in this column, these are for patients who are still alive, as indicated by the demographic.vital_status column. Therefore, we can retain this column for analysis, treating missing values as censored data.\n\n# Drop rows where days_to_death is missing and vital_status is 'Dead'\nbrca_df = brca_df[~((brca_df[\"demographic.days_to_death\"].isnull()) & (brca_df[\"demographic.vital_status\"] == 'Dead'))]\n\n\n# Check for percentage of missing values in diagnoses.days_to_last_follow_up\nmissing_percentage = brca_df[\"diagnoses.days_to_last_follow_up\"].isnull().mean()\nprint(f\"'Percentage of missing values in 'diagnoses.days_to_last_follow_up' {missing_percentage:.2f}\")\n\n'Percentage of missing values in 'diagnoses.days_to_last_follow_up' 0.11\n\n\n\n# Check the distribution of vital_status when days_to_last_follow_up is missing\nmissing_followup_status = brca_df[brca_df[\"diagnoses.days_to_last_follow_up\"].isnull()][\"demographic.vital_status\"].value_counts()\nmissing_followup_status\n\ndemographic.vital_status\nAlive    337\nDead     260\nName: count, dtype: int64\n\n\n\n# Check the percentage of missing values for the following columns:\n# - demographic.year_of_birth\n# - demographic.year_of_death\n# - demographic.vital_status\n# - demographic.cause_of_death\n# - demographic.education_level\ncols_to_check = [\n    'demographic.year_of_birth',\n    'demographic.age_at_index',\n    'demographic.cause_of_death',\n    'demographic.year_of_death',\n    'demographic.vital_status',\n    'demographic.cause_of_death',\n    'demographic.education_level',\n    'demographic.days_to_death'\n]\nfor col in cols_to_check:\n    missing_percentage = brca_df[col].isnull().mean() * 100\n    print(f\"{col}: {missing_percentage:.2f}% missing values\")\n\ndemographic.year_of_birth: 99.96% missing values\ndemographic.age_at_index: 0.02% missing values\ndemographic.cause_of_death: 100.00% missing values\ndemographic.year_of_death: 100.00% missing values\ndemographic.vital_status: 0.02% missing values\ndemographic.cause_of_death: 100.00% missing values\ndemographic.education_level: 100.00% missing values\ndemographic.days_to_death: 84.76% missing values\n\n\nA lot of missing values in key demographic columns, especially in cause of death become a limiting factor for analysis.\n\n# Distribution of demographic.vital_status\nvital_status_counts = brca_df['demographic.vital_status'].value_counts(dropna=False)\nprint(\"\\ndemographic.vital_status distribution:\")\nprint(vital_status_counts)\n\n\ndemographic.vital_status distribution:\ndemographic.vital_status\nAlive    4697\nDead      845\nNaN         1\nName: count, dtype: int64\n\n\nHowever, the demographic.vital_status column has fewer missing values, which may still allow for some analysis regarding survival status. Despite large number of missing values in demographic.days_to_death, we can assume it is because the patient is alive since the missing values correspond to alive in the vital_status column. In addition, days_to_last_follow_up in the diagnoses table also has fewer missing values, which may be useful for survival time analysis.\n\n\nCheck for missing values\n\n# Missing data visualization\nplt.figure(figsize=(15, 8))\nmsno.matrix(brca_df)\nplt.title(\"Missing Data Matrix - Breast Cancer Dataset\", fontsize=14, fontweight='bold')\nplt.show()\n\n&lt;Figure size 1500x800 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\n# Drop columns with more than 30% missing values except for demographic.days_to_death and diagnoses.days_to_last_follow_up\n\n# Calculate missing percentage for each column\nmissing_percentages = brca_df.isnull().mean()\n\n# Identify columns to drop (more than 30% missing, excluding the exceptions)\nexceptions = ['demographic.days_to_death', 'diagnoses.days_to_last_follow_up']\ncolumns_to_drop = []\n\nfor col in brca_df.columns:\n    if col not in exceptions and missing_percentages[col] &gt; 0.3:\n        columns_to_drop.append(col)\n\nprint(f\"Columns to be dropped due to &gt;30% missing values: {columns_to_drop}\")\n\n# Drop the identified columns\nbrca_df = brca_df.drop(columns=columns_to_drop)\n\n# Display the shape of the cleaned dataset\nbrca_df.shape\n\nColumns to be dropped due to &gt;30% missing values: ['cases.days_to_lost_to_followup', 'cases.lost_to_followup', 'demographic.cause_of_death', 'demographic.cause_of_death_source', 'demographic.country_of_birth', 'demographic.country_of_residence_at_enrollment', 'demographic.education_level', 'demographic.marital_status', 'demographic.occupation_duration_years', 'demographic.population_group', 'demographic.premature_at_birth', 'demographic.weeks_gestation_at_birth', 'demographic.year_of_birth', 'demographic.year_of_death', 'diagnoses.adrenal_hormone', 'diagnoses.ajcc_clinical_m', 'diagnoses.ajcc_clinical_n', 'diagnoses.ajcc_clinical_stage', 'diagnoses.ajcc_clinical_t', 'diagnoses.ajcc_serum_tumor_markers', 'diagnoses.ann_arbor_b_symptoms', 'diagnoses.ann_arbor_b_symptoms_described', 'diagnoses.ann_arbor_clinical_stage', 'diagnoses.ann_arbor_extranodal_involvement', 'diagnoses.ann_arbor_pathologic_stage', 'diagnoses.best_overall_response', 'diagnoses.burkitt_lymphoma_clinical_variant', 'diagnoses.calgb_risk_group', 'diagnoses.cancer_detection_method', 'diagnoses.child_pugh_classification', 'diagnoses.clark_level', 'diagnoses.cog_liver_stage', 'diagnoses.cog_neuroblastoma_risk_group', 'diagnoses.cog_renal_stage', 'diagnoses.cog_rhabdomyosarcoma_risk_group', 'diagnoses.contiguous_organ_invaded', 'diagnoses.days_to_best_overall_response', 'diagnoses.days_to_last_known_disease_status', 'diagnoses.days_to_recurrence', 'diagnoses.double_expressor_lymphoma', 'diagnoses.double_hit_lymphoma', 'diagnoses.eln_risk_classification', 'diagnoses.enneking_msts_grade', 'diagnoses.enneking_msts_metastasis', 'diagnoses.enneking_msts_stage', 'diagnoses.enneking_msts_tumor_site', 'diagnoses.ensat_clinical_m', 'diagnoses.ensat_pathologic_n', 'diagnoses.ensat_pathologic_stage', 'diagnoses.ensat_pathologic_t', 'diagnoses.esophageal_columnar_dysplasia_degree', 'diagnoses.esophageal_columnar_metaplasia_present', 'diagnoses.fab_morphology_code', 'diagnoses.figo_stage', 'diagnoses.figo_staging_edition_year', 'diagnoses.first_symptom_longest_duration', 'diagnoses.first_symptom_prior_to_diagnosis', 'diagnoses.gastric_esophageal_junction_involvement', 'diagnoses.gleason_grade_group', 'diagnoses.gleason_grade_tertiary', 'diagnoses.gleason_patterns_percent', 'diagnoses.gleason_score', 'diagnoses.goblet_cells_columnar_mucosa_present', 'diagnoses.igcccg_stage', 'diagnoses.inpc_grade', 'diagnoses.inpc_histologic_group', 'diagnoses.inrg_stage', 'diagnoses.inss_stage', 'diagnoses.international_prognostic_index', 'diagnoses.irs_group', 'diagnoses.irs_stage', 'diagnoses.ishak_fibrosis_score', 'diagnoses.iss_stage', 'diagnoses.last_known_disease_status', 'diagnoses.margin_distance', 'diagnoses.margins_involved_site', 'diagnoses.masaoka_stage', 'diagnoses.max_tumor_bulk_site', 'diagnoses.medulloblastoma_molecular_classification', 'diagnoses.melanoma_known_primary', 'diagnoses.metastasis_at_diagnosis', 'diagnoses.metastasis_at_diagnosis_site', 'diagnoses.micropapillary_features', 'diagnoses.mitosis_karyorrhexis_index', 'diagnoses.mitotic_count', 'diagnoses.ovarian_specimen_status', 'diagnoses.ovarian_surface_involvement', 'diagnoses.papillary_renal_cell_type', 'diagnoses.pediatric_kidney_staging', 'diagnoses.peritoneal_fluid_cytological_status', 'diagnoses.pregnant_at_diagnosis', 'diagnoses.primary_disease', 'diagnoses.primary_gleason_grade', 'diagnoses.progression_or_recurrence', 'diagnoses.residual_disease', 'diagnoses.satellite_nodule_present', 'diagnoses.secondary_gleason_grade', 'diagnoses.sites_of_involvement_count', 'diagnoses.supratentorial_localization', 'diagnoses.tumor_burden', 'diagnoses.tumor_confined_to_organ_of_origin', 'diagnoses.tumor_depth', 'diagnoses.tumor_focality', 'diagnoses.tumor_grade', 'diagnoses.tumor_grade_category', 'diagnoses.tumor_of_origin', 'diagnoses.tumor_regression_grade', 'diagnoses.uicc_clinical_m', 'diagnoses.uicc_clinical_n', 'diagnoses.uicc_clinical_stage', 'diagnoses.uicc_clinical_t', 'diagnoses.uicc_pathologic_m', 'diagnoses.uicc_pathologic_n', 'diagnoses.uicc_pathologic_stage', 'diagnoses.uicc_pathologic_t', 'diagnoses.uicc_staging_system_edition', 'diagnoses.ulceration_indicator', 'diagnoses.weiss_assessment_findings', 'diagnoses.weiss_assessment_score', 'diagnoses.who_cns_grade', 'diagnoses.who_nte_grade', 'diagnoses.wilms_tumor_histologic_subtype', 'treatments.chemo_concurrent_to_radiation', 'treatments.clinical_trial_indicator', 'treatments.course_number', 'treatments.days_to_treatment_end', 'treatments.days_to_treatment_start', 'treatments.drug_category', 'treatments.embolic_agent', 'treatments.initial_disease_status', 'treatments.lesions_treated_number', 'treatments.margin_distance', 'treatments.margin_status', 'treatments.margins_involved_site', 'treatments.number_of_cycles', 'treatments.number_of_fractions', 'treatments.prescribed_dose', 'treatments.prescribed_dose_units', 'treatments.pretreatment', 'treatments.protocol_identifier', 'treatments.radiosensitizing_agent', 'treatments.reason_treatment_ended', 'treatments.reason_treatment_not_given', 'treatments.regimen_or_line_of_therapy', 'treatments.residual_disease', 'treatments.route_of_administration', 'treatments.therapeutic_agents', 'treatments.therapeutic_level_achieved', 'treatments.therapeutic_levels_achieved', 'treatments.therapeutic_target_level', 'treatments.timepoint_category', 'treatments.treatment_anatomic_site', 'treatments.treatment_anatomic_sites', 'treatments.treatment_arm', 'treatments.treatment_dose', 'treatments.treatment_dose_max', 'treatments.treatment_dose_units', 'treatments.treatment_duration', 'treatments.treatment_effect', 'treatments.treatment_effect_indicator', 'treatments.treatment_frequency', 'treatments.treatment_intent_type', 'treatments.treatment_outcome', 'treatments.treatment_outcome_duration']\n\n\n(5543, 46)\n\n\n\n# Check distribution na values after dropping columns\nplt.figure(figsize=(15, 8))\nmsno.matrix(brca_df)\nplt.title(\"Missing Data Matrix After Dropping Columns - BRCA Clinical Dataset\", fontsize=14, fontweight='bold')\nplt.show()\n\n&lt;Figure size 1500x800 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\n\nCheck for duplicate IDs\n\n# Count unique IDs (cases.submitter_id)\n\nunique_ids = brca_df['cases.submitter_id'].nunique()\nprint(f\"Number of unique IDs: {unique_ids}\")\n\nNumber of unique IDs: 1097\n\n\nThe TGCA BRCA dataset contains 1,082 unique patient IDs (cases.submitter_id) but 3554 rows in total. This is because the TCGA Schema is designed to have multiple samples per patient, capturing different aspects of the tumor biology. Each patient may have multiple entries corresponding to different sample types, such as primary tumor, metastatic tumor, or normal tissue adjacent to the tumor. This allows for a more comprehensive analysis of the cancer’s characteristics and progression within the same individual.\nThe tcga schema is hierarchical as follows:\nCase (BRCA) -&gt; Diagnosis -&gt; Follow-up -&gt; Treatment -&gt; Biospecimens\nMost BRCA patients have: - 1 diagnosis - 1 - 5 follow-up entries - 1 - 3 treatments - 2 - 4 tissue samples (tumor and normal)\n\n# Drop completely duplicate rows\nbrca_df = brca_df.drop_duplicates()\n\n\n\nFilter columns based on task\nColumns that are not relevant to the predictive modeling task will be dropped. These include identifiers, dates, and other metadata that do not contribute to the prediction of breast cancer outcomes such as the following:\n\ncases.consent_type\ncases.days_to_consent\ndemographic.days_to_birth\ndemographic.age_at_index (will preserve diagnosis.age_at_diagnosis instead for age at diagnosis)\ndiagnoses.ajcc_staging_system_edition\ndiagnoses.diagnosis_id (captured in disease_type)\ndiagnoses.icd_10_code (captured in disease_type)\ndiagnoses.year_of_diagnosis (interested in age at diagnosis instead)\ntreatments.treatment_id\n\n\n# Drop irrelevant columns\ncolumns_to_drop = [\n    'cases.consent_type',\n    'cases.days_to_consent',\n    'demographic.days_to_birth',\n    'demographic.age_at_index',\n    'demographic.demographic_id',\n    'diagnoses.ajcc_staging_system_edition',\n    'diagnoses.diagnosis_id',\n    'diagnoses.icd_10_code',\n    'diagnoses.year_of_diagnosis',\n    'treatments.treatment_id'\n]\n\n# Drop the existing columns\nbrca_df = brca_df.drop(columns=columns_to_drop)\n\nprint(f\"Dataset shape after dropping columns: {brca_df.shape}\")\n\nDataset shape after dropping columns: (5543, 36)\n\n\n\n# Using msno to visualize missing data in remaining columns\nplt.figure(figsize=(15, 8))\nmsno.matrix(brca_df)\nplt.title(\"Missing Data Matrix After Dropping irrelevant columns - BRCA Clinical Dataset\", fontsize=14, fontweight='bold')\nplt.show()\n\n&lt;Figure size 1500x800 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\n# Check missing value percentages again\n\nfor col in brca_df.columns:\n    missing_percentage = brca_df[col].isnull().mean() * 100\n    print(f\"{col}: {missing_percentage:.2f}% missing values\")\n\nproject.project_id: 0.00% missing values\ncases.case_id: 0.00% missing values\ncases.disease_type: 0.00% missing values\ncases.index_date: 0.05% missing values\ncases.primary_site: 0.00% missing values\ncases.submitter_id: 0.00% missing values\ndemographic.age_is_obfuscated: 0.05% missing values\ndemographic.days_to_death: 84.76% missing values\ndemographic.ethnicity: 0.02% missing values\ndemographic.gender: 0.02% missing values\ndemographic.race: 0.02% missing values\ndemographic.submitter_id: 0.02% missing values\ndemographic.vital_status: 0.02% missing values\ndiagnoses.age_at_diagnosis: 3.50% missing values\ndiagnoses.ajcc_pathologic_m: 9.44% missing values\ndiagnoses.ajcc_pathologic_n: 9.44% missing values\ndiagnoses.ajcc_pathologic_stage: 10.25% missing values\ndiagnoses.ajcc_pathologic_t: 9.40% missing values\ndiagnoses.classification_of_tumor: 0.02% missing values\ndiagnoses.days_to_diagnosis: 2.62% missing values\ndiagnoses.days_to_last_follow_up: 10.79% missing values\ndiagnoses.diagnosis_is_primary_disease: 0.05% missing values\ndiagnoses.laterality: 8.44% missing values\ndiagnoses.method_of_diagnosis: 17.54% missing values\ndiagnoses.morphology: 0.02% missing values\ndiagnoses.primary_diagnosis: 0.02% missing values\ndiagnoses.prior_malignancy: 10.79% missing values\ndiagnoses.prior_treatment: 3.63% missing values\ndiagnoses.site_of_resection_or_biopsy: 0.02% missing values\ndiagnoses.sites_of_involvement: 10.82% missing values\ndiagnoses.submitter_id: 0.02% missing values\ndiagnoses.synchronous_malignancy: 10.79% missing values\ndiagnoses.tissue_or_organ_of_origin: 0.02% missing values\ntreatments.submitter_id: 0.67% missing values\ntreatments.treatment_or_therapy: 0.67% missing values\ntreatments.treatment_type: 0.67% missing values\n\n\n\n# Check distribution of rows that have a lot of missing values\nbrca_df[\"na_count\"] = brca_df.isna().sum(axis=1)\nna_count_distribution = brca_df['na_count'].value_counts().sort_index()\nprint(\"\\nDistribution of rows by number of missing values:\")\nprint(na_count_distribution)\n\n\nDistribution of rows by number of missing values:\nna_count\n0      543\n1     3981\n2      415\n3        4\n7       20\n8       15\n9       37\n10     218\n11     172\n12      27\n13      51\n14      56\n15       1\n16       1\n17       1\n31       1\nName: count, dtype: int64\n\n\n\n# Delete rows that have 9 or more missing values (representing over 30% of that entity info missing)\nbrca_df = brca_df[brca_df['na_count'] &lt; 9].drop(columns=['na_count'])\n\n\n# Delete rows that have missing age_at_diagnosis info since this is a critical variable for our analysis\nbrca_df = brca_df[brca_df['diagnoses.age_at_diagnosis'].notna()]\n\n\n# Check missing value percentages again\n\nfor col in brca_df.columns:\n    missing_percentage = brca_df[col].isnull().mean() * 100\n    print(f\"{col}: {missing_percentage:.2f}% missing values\")\n\nproject.project_id: 0.00% missing values\ncases.case_id: 0.00% missing values\ncases.disease_type: 0.00% missing values\ncases.index_date: 0.04% missing values\ncases.primary_site: 0.00% missing values\ncases.submitter_id: 0.00% missing values\ndemographic.age_is_obfuscated: 0.04% missing values\ndemographic.days_to_death: 88.11% missing values\ndemographic.ethnicity: 0.00% missing values\ndemographic.gender: 0.00% missing values\ndemographic.race: 0.00% missing values\ndemographic.submitter_id: 0.00% missing values\ndemographic.vital_status: 0.00% missing values\ndiagnoses.age_at_diagnosis: 0.00% missing values\ndiagnoses.ajcc_pathologic_m: 0.00% missing values\ndiagnoses.ajcc_pathologic_n: 0.00% missing values\ndiagnoses.ajcc_pathologic_stage: 0.89% missing values\ndiagnoses.ajcc_pathologic_t: 0.06% missing values\ndiagnoses.classification_of_tumor: 0.00% missing values\ndiagnoses.days_to_diagnosis: 0.00% missing values\ndiagnoses.days_to_last_follow_up: 0.49% missing values\ndiagnoses.diagnosis_is_primary_disease: 0.04% missing values\ndiagnoses.laterality: 0.10% missing values\ndiagnoses.method_of_diagnosis: 8.09% missing values\ndiagnoses.morphology: 0.00% missing values\ndiagnoses.primary_diagnosis: 0.00% missing values\ndiagnoses.prior_malignancy: 0.49% missing values\ndiagnoses.prior_treatment: 0.49% missing values\ndiagnoses.site_of_resection_or_biopsy: 0.00% missing values\ndiagnoses.sites_of_involvement: 0.53% missing values\ndiagnoses.submitter_id: 0.00% missing values\ndiagnoses.synchronous_malignancy: 0.49% missing values\ndiagnoses.tissue_or_organ_of_origin: 0.00% missing values\ntreatments.submitter_id: 0.00% missing values\ntreatments.treatment_or_therapy: 0.00% missing values\ntreatments.treatment_type: 0.00% missing values\n\n\n\n# Using msno to visualize missing data in remaining columns\nplt.figure(figsize=(15, 8))\nmsno.matrix(brca_df)\nplt.title(\"Missing Data Matrix After Dropping irrelevant columns - BRCA Clinical Dataset\", fontsize=14, fontweight='bold')\nplt.show()\n\n&lt;Figure size 1500x800 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\n# Check the distribution of the method_of_diagnosis since it has a significantly higher missing value percentage\nmethod_of_diagnosis_counts = brca_df['diagnoses.method_of_diagnosis'].value_counts(dropna=False)\nprint(\"\\ndiagnoses.method_of_diagnosis distribution:\")\nprint(method_of_diagnosis_counts)\n\n\ndiagnoses.method_of_diagnosis distribution:\ndiagnoses.method_of_diagnosis\nCore Biopsy                 2932\nSurgical Resection           797\nNaN                          398\nFine Needle Aspiration       380\nExcisional Biopsy            143\nCytology                     124\nBiopsy                        67\nIncisional Biopsy             66\nUltrasound Guided Biopsy       7\nUnknown                        6\nName: count, dtype: int64\n\n\nDue to the heavy imbalance leaning towards Core Biopsy for the diagnoses.method_of_diagnosis column, we can replace missing values with ‘Core Biopsy’ to retain more rows for analysis.\n\n# Distribution of cases.index_date\nindex_date_counts = brca_df['cases.index_date'].value_counts(dropna=False)\nprint(\"\\ncases.index_date distribution:\")\nprint(index_date_counts)\n\n\ncases.index_date distribution:\ncases.index_date\nDiagnosis    4918\nNaN             2\nName: count, dtype: int64\n\n\nDue to the heavy imbalance leaning towards Diagnosis for the cases.index_date column, we can replace missing values with ‘Diagnosis’ to retain more rows for analysis.\n\n# Set pandas options to display all columns\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', None)\n\n\n# Check rows that have missing age_is_obfuscated \nbrca_df[brca_df['demographic.age_is_obfuscated'].isna()].head()\n\n\n\n\n\n\n\n\nproject.project_id\ncases.case_id\ncases.disease_type\ncases.index_date\ncases.primary_site\ncases.submitter_id\ndemographic.age_is_obfuscated\ndemographic.days_to_death\ndemographic.ethnicity\ndemographic.gender\ndemographic.race\ndemographic.submitter_id\ndemographic.vital_status\ndiagnoses.age_at_diagnosis\ndiagnoses.ajcc_pathologic_m\ndiagnoses.ajcc_pathologic_n\ndiagnoses.ajcc_pathologic_stage\ndiagnoses.ajcc_pathologic_t\ndiagnoses.classification_of_tumor\ndiagnoses.days_to_diagnosis\ndiagnoses.days_to_last_follow_up\ndiagnoses.diagnosis_is_primary_disease\ndiagnoses.laterality\ndiagnoses.method_of_diagnosis\ndiagnoses.morphology\ndiagnoses.primary_diagnosis\ndiagnoses.prior_malignancy\ndiagnoses.prior_treatment\ndiagnoses.site_of_resection_or_biopsy\ndiagnoses.sites_of_involvement\ndiagnoses.submitter_id\ndiagnoses.synchronous_malignancy\ndiagnoses.tissue_or_organ_of_origin\ntreatments.submitter_id\ntreatments.treatment_or_therapy\ntreatments.treatment_type\n\n\n\n\n4368\nTCGA-BRCA\ncb9f5e50-f49d-4899-8895-9367afcc1015\nDuctal and Lobular Neoplasms\nNaN\nBreast\nTCGA-A7-A0DC\nNaN\nNaN\nnot hispanic or latino\nfemale\nwhite\nTCGA-A7-A0DC_demographic\nAlive\n23294\nM0\nN0 (i-)\nStage IA\nT1c\nnot reported\n0\n906.0\nNaN\nNaN\nNaN\n8500/3\nInfiltrating duct carcinoma, NOS\nno\nNo\nBreast, NOS\nNaN\nTCGA-A7-A0DC_diagnosis\nNo\nBreast, NOS\nTCGA-A7-A0DC_treatment_1\nyes\nPharmaceutical Therapy, NOS\n\n\n4369\nTCGA-BRCA\ncb9f5e50-f49d-4899-8895-9367afcc1015\nDuctal and Lobular Neoplasms\nNaN\nBreast\nTCGA-A7-A0DC\nNaN\nNaN\nnot hispanic or latino\nfemale\nwhite\nTCGA-A7-A0DC_demographic\nAlive\n23294\nM0\nN0 (i-)\nStage IA\nT1c\nnot reported\n0\n906.0\nNaN\nNaN\nNaN\n8500/3\nInfiltrating duct carcinoma, NOS\nno\nNo\nBreast, NOS\nNaN\nTCGA-A7-A0DC_diagnosis\nNo\nBreast, NOS\nTCGA-A7-A0DC_treatment\nyes\nRadiation Therapy, NOS\n\n\n\n\n\n\n\nIt seems that when age is obfuscated is NaN, age_at_diagnosis exists, therefore we can replace these with False\n\n# Check distribution of diagnoses.ajcc_pathologic_n \najcc_pathologic_stage_counts = brca_df['diagnoses.ajcc_pathologic_n'].value_counts(dropna=False)\nprint(\"\\ndiagnoses.ajcc_pathologic_n distribution:\")\nprint(ajcc_pathologic_stage_counts)\n\n\ndiagnoses.ajcc_pathologic_n distribution:\ndiagnoses.ajcc_pathologic_n\nN0           1289\nN1a           839\nN0 (i-)       682\nN1            579\nN2a           352\nN2            267\nN3a           247\nN1mi          178\nN0 (i+)       138\nN3            130\nN1b           104\nNX             77\nN3b            16\nN3c            13\nN1c             6\nN0 (mol+)       3\nName: count, dtype: int64\n\n\n\n# Check distribution of diagnoses.ajcc_pathologic_m \najcc_pathologic_stage_counts = brca_df['diagnoses.ajcc_pathologic_m'].value_counts(dropna=False)\nprint(\"\\ndiagnoses.ajcc_pathologic_m distribution:\")\nprint(ajcc_pathologic_stage_counts)\n\n\ndiagnoses.ajcc_pathologic_m distribution:\ndiagnoses.ajcc_pathologic_m\nM0          4095\nMX           703\nM1            87\ncM0 (i+)      35\nName: count, dtype: int64\n\n\n\n# Check distribution of diagnoses.ajcc_pathologic_t \najcc_pathologic_stage_counts = brca_df['diagnoses.ajcc_pathologic_t'].value_counts(dropna=False)\nprint(\"\\ndiagnoses.ajcc_pathologic_t distribution:\")\nprint(ajcc_pathologic_stage_counts)\n\n\ndiagnoses.ajcc_pathologic_t distribution:\ndiagnoses.ajcc_pathologic_t\nT2            2908\nT1c            941\nT3             649\nT1             178\nT4b             94\nT1b             76\nT4              31\nT4d             12\nTX               9\nTis (DCIS)       6\nT3a              4\nT2a              4\nTis              3\nNaN              3\nT1a              1\nT2b              1\nName: count, dtype: int64\n\n\n\n# Check distribution of diagnoses.ajcc_pathologic_stage \najcc_pathologic_stage_counts = brca_df['diagnoses.ajcc_pathologic_stage'].value_counts(dropna=False)\nprint(\"\\ndiagnoses.ajcc_pathologic_stage distribution:\")\nprint(ajcc_pathologic_stage_counts)\n\n\ndiagnoses.ajcc_pathologic_stage distribution:\ndiagnoses.ajcc_pathologic_stage\nStage IIA     1532\nStage IIB     1227\nStage IIIA     787\nStage IIIC     364\nStage I        341\nStage IA       338\nStage IIIB      89\nStage IV        77\nNaN             44\nStage X         42\nStage IB        33\nStage II        25\nStage III       12\nStage 0          6\nStage 0is        3\nName: count, dtype: int64\n\n\nThe missing values in the diagnoses.ajcc_pathologic_t, diagnoses.ajcc_pathologic_n, and diagnoses.ajcc_pathologic_m columns will be replaced by the mode of each column respectively and the state (diagnoses.ajcc_pathologic_stage) will be derived from these three columns using the AJCC staging guidelines.\n\n# Check rows with missing diagnoses.ajcc_pathologic_stage\nbrca_df[brca_df['diagnoses.ajcc_pathologic_stage'].isna()].head()\n\n\n\n\n\n\n\n\nproject.project_id\ncases.case_id\ncases.disease_type\ncases.index_date\ncases.primary_site\ncases.submitter_id\ndemographic.age_is_obfuscated\ndemographic.days_to_death\ndemographic.ethnicity\ndemographic.gender\ndemographic.race\ndemographic.submitter_id\ndemographic.vital_status\ndiagnoses.age_at_diagnosis\ndiagnoses.ajcc_pathologic_m\ndiagnoses.ajcc_pathologic_n\ndiagnoses.ajcc_pathologic_stage\ndiagnoses.ajcc_pathologic_t\ndiagnoses.classification_of_tumor\ndiagnoses.days_to_diagnosis\ndiagnoses.days_to_last_follow_up\ndiagnoses.diagnosis_is_primary_disease\ndiagnoses.laterality\ndiagnoses.method_of_diagnosis\ndiagnoses.morphology\ndiagnoses.primary_diagnosis\ndiagnoses.prior_malignancy\ndiagnoses.prior_treatment\ndiagnoses.site_of_resection_or_biopsy\ndiagnoses.sites_of_involvement\ndiagnoses.submitter_id\ndiagnoses.synchronous_malignancy\ndiagnoses.tissue_or_organ_of_origin\ntreatments.submitter_id\ntreatments.treatment_or_therapy\ntreatments.treatment_type\n\n\n\n\n276\nTCGA-BRCA\n0adf59c6-581a-475d-a2f4-40aa40060b5b\nDuctal and Lobular Neoplasms\nDiagnosis\nBreast\nTCGA-A8-A09T\nfalse\nNaN\nnot reported\nfemale\nnot reported\nTCGA-A8-A09T_demographic\nAlive\n25110\nMX\nN0\nNaN\nT1c\nprimary\n0\n579.0\ntrue\nLeft\nNaN\n8520/3\nLobular carcinoma, NOS\nno\nNo\nBreast, NOS\nBreast, NOS\nTCGA-A8-A09T_diagnosis\nNo\nBreast, NOS\nTCGA-A8-A09T_treatment2\nyes\nHormone Therapy\n\n\n277\nTCGA-BRCA\n0adf59c6-581a-475d-a2f4-40aa40060b5b\nDuctal and Lobular Neoplasms\nDiagnosis\nBreast\nTCGA-A8-A09T\nfalse\nNaN\nnot reported\nfemale\nnot reported\nTCGA-A8-A09T_demographic\nAlive\n25110\nMX\nN0\nNaN\nT1c\nprimary\n0\n579.0\ntrue\nLeft\nNaN\n8520/3\nLobular carcinoma, NOS\nno\nNo\nBreast, NOS\nBreast, NOS\nTCGA-A8-A09T_diagnosis\nNo\nBreast, NOS\nTCGA-A8-A09T_treatment3\nyes\nSurgery, NOS\n\n\n278\nTCGA-BRCA\n0adf59c6-581a-475d-a2f4-40aa40060b5b\nDuctal and Lobular Neoplasms\nDiagnosis\nBreast\nTCGA-A8-A09T\nfalse\nNaN\nnot reported\nfemale\nnot reported\nTCGA-A8-A09T_demographic\nAlive\n25110\nMX\nN0\nNaN\nT1c\nprimary\n0\n579.0\ntrue\nLeft\nNaN\n8520/3\nLobular carcinoma, NOS\nno\nNo\nBreast, NOS\nBreast, NOS\nTCGA-A8-A09T_diagnosis\nNo\nBreast, NOS\nTCGA-A8-A09T_treatment\nyes\nRadiation, External Beam\n\n\n508\nTCGA-BRCA\n178b2c48-c07d-422e-ae17-8bcfd996ad51\nDuctal and Lobular Neoplasms\nDiagnosis\nBreast\nTCGA-B6-A0X1\nfalse\n7455\nnot hispanic or latino\nfemale\nwhite\nTCGA-B6-A0X1_demographic\nDead\n17624\nM1\nN1\nNaN\nT2\nprimary\n0\n7455.0\ntrue\nLeft\nFine Needle Aspiration\n8500/3\nInfiltrating duct carcinoma, NOS\nno\nNo\nBreast, NOS\nBreast, NOS\nTCGA-B6-A0X1_diagnosis\nNo\nBreast, NOS\nTCGA-B6-A0X1_treatment3\nyes\nSurgery, NOS\n\n\n509\nTCGA-BRCA\n178b2c48-c07d-422e-ae17-8bcfd996ad51\nDuctal and Lobular Neoplasms\nDiagnosis\nBreast\nTCGA-B6-A0X1\nfalse\n7455\nnot hispanic or latino\nfemale\nwhite\nTCGA-B6-A0X1_demographic\nDead\n17624\nM1\nN1\nNaN\nT2\nprimary\n0\n7455.0\ntrue\nLeft\nFine Needle Aspiration\n8500/3\nInfiltrating duct carcinoma, NOS\nno\nNo\nBreast, NOS\nBreast, NOS\nTCGA-B6-A0X1_diagnosis\nNo\nBreast, NOS\nTCGA-B6-A0X1_treatment\nyes\nPharmaceutical Therapy, NOS\n\n\n\n\n\n\n\n\n# Percentage of missing values in each column\nmissing_percentages = brca_df.isnull().mean() * 100\nprint(\"\\nPercentage of missing values in each column:\")\nprint(missing_percentages)\n\n\nPercentage of missing values in each column:\nproject.project_id                         0.000000\ncases.case_id                              0.000000\ncases.disease_type                         0.000000\ncases.index_date                           0.040650\ncases.primary_site                         0.000000\ncases.submitter_id                         0.000000\ndemographic.age_is_obfuscated              0.040650\ndemographic.days_to_death                 88.109756\ndemographic.ethnicity                      0.000000\ndemographic.gender                         0.000000\ndemographic.race                           0.000000\ndemographic.submitter_id                   0.000000\ndemographic.vital_status                   0.000000\ndiagnoses.age_at_diagnosis                 0.000000\ndiagnoses.ajcc_pathologic_m                0.000000\ndiagnoses.ajcc_pathologic_n                0.000000\ndiagnoses.ajcc_pathologic_stage            0.894309\ndiagnoses.ajcc_pathologic_t                0.060976\ndiagnoses.classification_of_tumor          0.000000\ndiagnoses.days_to_diagnosis                0.000000\ndiagnoses.days_to_last_follow_up           0.487805\ndiagnoses.diagnosis_is_primary_disease     0.040650\ndiagnoses.laterality                       0.101626\ndiagnoses.method_of_diagnosis              8.089431\ndiagnoses.morphology                       0.000000\ndiagnoses.primary_diagnosis                0.000000\ndiagnoses.prior_malignancy                 0.487805\ndiagnoses.prior_treatment                  0.487805\ndiagnoses.site_of_resection_or_biopsy      0.000000\ndiagnoses.sites_of_involvement             0.528455\ndiagnoses.submitter_id                     0.000000\ndiagnoses.synchronous_malignancy           0.487805\ndiagnoses.tissue_or_organ_of_origin        0.000000\ntreatments.submitter_id                    0.000000\ntreatments.treatment_or_therapy            0.000000\ntreatments.treatment_type                  0.000000\ndtype: float64\n\n\n\n# Check distribution of diagnoses.treatment_or_therapy\ntreatment_or_therapy_counts = brca_df['treatments.treatment_or_therapy'].value_counts(dropna=False)\nprint(\"\\ntreatments.treatment_or_therapy distribution:\")\nprint(treatment_or_therapy_counts)\n\n\ntreatments.treatment_or_therapy distribution:\ntreatments.treatment_or_therapy\nyes        4289\nno          559\nunknown      72\nName: count, dtype: int64\n\n\n\n\nClean NA values\nReplace the missing values in the following columns based on the assigned strategy: - cases.index_date: ‘Diagnosis’ (most frequent) - diagnoses.method_of_diagnosis: ‘Core Biopsy’ (most frequent) - demographic.age_is_obfuscated: ‘False’ (age is still present despite na) - diagnoses.ajcc_pathologic_n: ‘N0’ (most frequent) - diagnoses.ajcc_pathologic_m: ‘M0’ (most frequent) - diagnoses.ajcc_pathologic_t: ‘T2’ (most frequent) - diagnoses.ajcc_pathologic_stage: infered from other ajcc_pathologic columns according to the following mapping: - T1, N0, M0 -&gt; Stage I - T2, N0, M0 -&gt; Stage II - T3, N0, M0 -&gt; Stage III - T4, N0, M0 -&gt; Stage IV - T1, N1, M0 -&gt; Stage II - T2, N1, M0 -&gt; Stage III - T3, N1, M0 -&gt; Stage III - T4, N1, M0 -&gt; Stage IV - diagnoses.diagnosis_is_primary_disease: ‘True’ (most frequent) - diagnoses.laterality : ‘Left’ (most frequent) - diagnoses.prior_malignancy: ‘False’ (most frequent) - diagnoses.prior_treatment: ‘False’ (most frequent) - diagnoses.sites_of_involvement: ‘Breast’ (most frequent) - diagnoses.synchronous_malignancy: ‘False’ (most frequent) - diagnoses.treatment_or_therapy: True (most frequent)\n\n# Replace missing values based on the strategy above:\n\n# Replace with most frequent values\nbrca_df['cases.index_date'] = brca_df['cases.index_date'].fillna('diagnosis')\nbrca_df['diagnoses.method_of_diagnosis'] = brca_df['diagnoses.method_of_diagnosis'].fillna('core biopsy')\nbrca_df['demographic.age_is_obfuscated'] = brca_df['demographic.age_is_obfuscated'].fillna('false')\nbrca_df['diagnoses.ajcc_pathologic_n'] = brca_df['diagnoses.ajcc_pathologic_n'].fillna('n0')\nbrca_df['diagnoses.ajcc_pathologic_m'] = brca_df['diagnoses.ajcc_pathologic_m'].fillna('m0')\nbrca_df['diagnoses.ajcc_pathologic_t'] = brca_df['diagnoses.ajcc_pathologic_t'].fillna('t2')\nbrca_df['diagnoses.diagnosis_is_primary_disease'] = brca_df['diagnoses.diagnosis_is_primary_disease'].fillna('true')\nbrca_df['diagnoses.laterality'] = brca_df['diagnoses.laterality'].fillna('left')\nbrca_df['diagnoses.prior_malignancy'] = brca_df['diagnoses.prior_malignancy'].fillna('no')\nbrca_df['diagnoses.prior_treatment'] = brca_df['diagnoses.prior_treatment'].fillna('no')\nbrca_df['diagnoses.sites_of_involvement'] = brca_df['diagnoses.sites_of_involvement'].fillna('breast')\nbrca_df['diagnoses.synchronous_malignancy'] = brca_df['diagnoses.synchronous_malignancy'].fillna('no')\nbrca_df['treatments.treatment_or_therapy'] = brca_df['treatments.treatment_or_therapy'].fillna('True')\n\n# Define AJCC staging mapping\ndef get_ajcc_stage(t, n, m):\n    \"\"\"Map T, N, M values to AJCC stage\"\"\"\n    # Extract numeric/classification parts (remove 'T', 'N', 'M' prefixes)\n    t_val = t.lower().replace('t', '') if pd.notna(t) else '2'\n    n_val = n.lower().replace('n', '') if pd.notna(n) else '0'\n    m_val = m.lower().replace('m', '') if pd.notna(m) else '0'\n    \n    # Stage mapping logic\n    if m_val != '0':\n        return 'stage iv'  # Any distant metastasis is Stage IV\n    elif t_val == '1' and n_val == '0':\n        return 'stage i'\n    elif (t_val == '2' and n_val == '0') or (t_val == '1' and n_val == '1'):\n        return 'stage ii'\n    elif (t_val == '3' and n_val == '0') or (t_val == '2' and n_val == '1') or (t_val == '3' and n_val == '1'):\n        return 'stage iii'\n    elif t_val == '4':\n        return 'stage iv'\n    else:\n        return 'stage ii'  # Default fallback\n\n# Apply staging logic to fill missing values\nfor idx, row in brca_df.iterrows():\n    if pd.isna(row['diagnoses.ajcc_pathologic_stage']):\n        stage = get_ajcc_stage(\n            row['diagnoses.ajcc_pathologic_t'],\n            row['diagnoses.ajcc_pathologic_n'], \n            row['diagnoses.ajcc_pathologic_m']\n        )\n        brca_df.at[idx, 'diagnoses.ajcc_pathologic_stage'] = stage\n\n\n# Check missing values after replacement\nprint(\"Missing values after replacement:\")\nfor col in brca_df.columns:\n    missing_count = brca_df[col].isnull().sum()\n    if missing_count &gt; 0:\n        print(f\"{col}: {missing_count} missing values\")\n\nprint(f\"\\nTotal missing values across all columns: {brca_df.isnull().sum().sum()}\")\n\nMissing values after replacement:\ndemographic.days_to_death: 4335 missing values\ndiagnoses.days_to_last_follow_up: 24 missing values\n\nTotal missing values across all columns: 4359\n\n\n\n\nCheck for consistent data types\n\n# Check column data types\n\nbrca_df.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 4920 entries, 0 to 5545\nData columns (total 36 columns):\n #   Column                                  Non-Null Count  Dtype \n---  ------                                  --------------  ----- \n 0   project.project_id                      4920 non-null   object\n 1   cases.case_id                           4920 non-null   object\n 2   cases.disease_type                      4920 non-null   object\n 3   cases.index_date                        4920 non-null   object\n 4   cases.primary_site                      4920 non-null   object\n 5   cases.submitter_id                      4920 non-null   object\n 6   demographic.age_is_obfuscated           4920 non-null   object\n 7   demographic.days_to_death               585 non-null    object\n 8   demographic.ethnicity                   4920 non-null   object\n 9   demographic.gender                      4920 non-null   object\n 10  demographic.race                        4920 non-null   object\n 11  demographic.submitter_id                4920 non-null   object\n 12  demographic.vital_status                4920 non-null   object\n 13  diagnoses.age_at_diagnosis              4920 non-null   object\n 14  diagnoses.ajcc_pathologic_m             4920 non-null   object\n 15  diagnoses.ajcc_pathologic_n             4920 non-null   object\n 16  diagnoses.ajcc_pathologic_stage         4920 non-null   object\n 17  diagnoses.ajcc_pathologic_t             4920 non-null   object\n 18  diagnoses.classification_of_tumor       4920 non-null   object\n 19  diagnoses.days_to_diagnosis             4920 non-null   object\n 20  diagnoses.days_to_last_follow_up        4896 non-null   object\n 21  diagnoses.diagnosis_is_primary_disease  4920 non-null   object\n 22  diagnoses.laterality                    4920 non-null   object\n 23  diagnoses.method_of_diagnosis           4920 non-null   object\n 24  diagnoses.morphology                    4920 non-null   object\n 25  diagnoses.primary_diagnosis             4920 non-null   object\n 26  diagnoses.prior_malignancy              4920 non-null   object\n 27  diagnoses.prior_treatment               4920 non-null   object\n 28  diagnoses.site_of_resection_or_biopsy   4920 non-null   object\n 29  diagnoses.sites_of_involvement          4920 non-null   object\n 30  diagnoses.submitter_id                  4920 non-null   object\n 31  diagnoses.synchronous_malignancy        4920 non-null   object\n 32  diagnoses.tissue_or_organ_of_origin     4920 non-null   object\n 33  treatments.submitter_id                 4920 non-null   object\n 34  treatments.treatment_or_therapy         4920 non-null   object\n 35  treatments.treatment_type               4920 non-null   object\ndtypes: object(36)\nmemory usage: 1.5+ MB\n\n\n\n# Check the statistical summary of diagnoses.age_at_diagnosis\n\n# Convert to numeric \nbrca_df['diagnoses.age_at_diagnosis'] = pd.to_numeric(brca_df['diagnoses.age_at_diagnosis'], errors='coerce')\n\n# Statistical summary\nprint(\"Statistical Summary of Age at Diagnosis:\")\nprint(brca_df['diagnoses.age_at_diagnosis'].describe())\n\nprint(f\"\\nMean: {brca_df['diagnoses.age_at_diagnosis'].mean():.2f}\")\nprint(f\"Median: {brca_df['diagnoses.age_at_diagnosis'].median():.2f}\")\nprint(f\"Standard Deviation: {brca_df['diagnoses.age_at_diagnosis'].std():.2f}\")\nprint(f\"Missing values: {brca_df['diagnoses.age_at_diagnosis'].isna().sum()}\")\n\nStatistical Summary of Age at Diagnosis:\ncount     4920.000000\nmean     20899.613618\nstd       4578.709865\nmin       9706.000000\n25%      17561.500000\n50%      20708.500000\n75%      23699.750000\nmax      32872.000000\nName: diagnoses.age_at_diagnosis, dtype: float64\n\nMean: 20899.61\nMedian: 20708.50\nStandard Deviation: 4578.71\nMissing values: 0\n\n\nThe age at diagnosis column has been converted to numeric but the values are in days. For analysis we will convert these to years by dividing by 365.25 (accounting for leap years) and rounding down\n\n# Convert age at diagnosis from days to years (integer)\nbrca_df['diagnoses.age_at_diagnosis'] = (brca_df['diagnoses.age_at_diagnosis'] / 365.25).apply(np.floor)\n\n\n# Check the statistical summary of diagnoses.age_at_diagnosis\n\n# Convert to numeric \nbrca_df['diagnoses.age_at_diagnosis'] = pd.to_numeric(brca_df['diagnoses.age_at_diagnosis'], errors='coerce')\n\n# Statistical summary\nprint(\"Statistical Summary of Age at Diagnosis:\")\nprint(brca_df['diagnoses.age_at_diagnosis'].describe())\n\nprint(f\"\\nMean: {brca_df['diagnoses.age_at_diagnosis'].mean():.2f}\")\nprint(f\"Median: {brca_df['diagnoses.age_at_diagnosis'].median():.2f}\")\nprint(f\"Standard Deviation: {brca_df['diagnoses.age_at_diagnosis'].std():.2f}\")\nprint(f\"Missing values: {brca_df['diagnoses.age_at_diagnosis'].isna().sum()}\")\n\nStatistical Summary of Age at Diagnosis:\ncount    4920.000000\nmean       56.710569\nstd        12.529500\nmin        26.000000\n25%        48.000000\n50%        56.000000\n75%        64.000000\nmax        89.000000\nName: diagnoses.age_at_diagnosis, dtype: float64\n\nMean: 56.71\nMedian: 56.00\nStandard Deviation: 12.53\nMissing values: 0\n\n\n\n# Convert to integer\nbrca_df['diagnoses.age_at_diagnosis'] = pd.to_numeric(\n    brca_df['diagnoses.age_at_diagnosis'], \n    errors='coerce'\n)\nbrca_df['diagnoses.age_at_diagnosis'].dtype\n\ndtype('float64')\n\n\n\n# Change all object type columns to lowercase\nfor col in brca_df.select_dtypes(include=['object']).columns:\n    brca_df[col] = brca_df[col].astype(str).str.lower().replace('nan', np.nan)\n\n\n# strip whitespace from string columns\nfor col in brca_df.select_dtypes(include=['object']).columns:\n    brca_df[col] = brca_df[col].str.strip()\n\n\n# Change demographic.age_is_obfuscated to boolean\nbrca_df['demographic.age_is_obfuscated'] = brca_df['demographic.age_is_obfuscated'].map({'false': False, 'true': True})\n\n# Check the conversion\nprint(brca_df['demographic.age_is_obfuscated'].value_counts())\n\ndemographic.age_is_obfuscated\nFalse    4862\nTrue       58\nName: count, dtype: int64\n\n\n\n# Convert treatments.treatment_or_therapy to boolean from yes/no\nbrca_df['treatments.treatment_or_therapy'] = brca_df['treatments.treatment_or_therapy'].map({'yes': True, 'no': False}) \n# Check the conversion\nprint(brca_df['treatments.treatment_or_therapy'].value_counts())\n\ntreatments.treatment_or_therapy\nTrue     4289\nFalse     559\nName: count, dtype: int64\n\n\nChange other columns to boolean as appropriate: - diagnoses.diagnosis_is_primary_disease (from true/false strings) - diagnoses.prior_malignancy (from no/yes strings) - diagnoses.prior_treatment (from No/Yes strings) - diagnoses.synchronous_malignancy (from no/yes strings)\n\n# Convert diagnosis-related columns to boolean\n\n# Convert diagnoses.diagnosis_is_primary_disease (true/false to boolean)\nbrca_df['diagnoses.diagnosis_is_primary_disease'] = brca_df['diagnoses.diagnosis_is_primary_disease'].map({'true': True, 'false': False})\n\n# Convert diagnoses.prior_malignancy (yes/no to boolean)\nbrca_df['diagnoses.prior_malignancy'] = brca_df['diagnoses.prior_malignancy'].map({'yes': True, 'no': False})\n\n# Convert diagnoses.prior_treatment (yes/no to boolean)\nbrca_df['diagnoses.prior_treatment'] = brca_df['diagnoses.prior_treatment'].map({'yes': True, 'no': False})\n\n# Convert diagnoses.synchronous_malignancy (yes/no to boolean)\nbrca_df['diagnoses.synchronous_malignancy'] = brca_df['diagnoses.synchronous_malignancy'].map({'yes': True, 'no': False})\n\n# Check the conversions\nprint(\"Conversion results:\")\nprint(f\"diagnoses.diagnosis_is_primary_disease dtype: {brca_df['diagnoses.diagnosis_is_primary_disease'].dtype}\")\nprint(f\"diagnoses.prior_malignancy dtype: {brca_df['diagnoses.prior_malignancy'].dtype}\")\nprint(f\"diagnoses.prior_treatment dtype: {brca_df['diagnoses.prior_treatment'].dtype}\")\nprint(f\"diagnoses.synchronous_malignancy dtype: {brca_df['diagnoses.synchronous_malignancy'].dtype}\")\n\nprint(\"\\nValue counts for each column:\")\nfor col in ['diagnoses.diagnosis_is_primary_disease', 'diagnoses.prior_malignancy', \n           'diagnoses.prior_treatment', 'diagnoses.synchronous_malignancy']:\n    print(f\"\\n{col}:\")\n    print(brca_df[col].value_counts())\n\nConversion results:\ndiagnoses.diagnosis_is_primary_disease dtype: bool\ndiagnoses.prior_malignancy dtype: object\ndiagnoses.prior_treatment dtype: object\ndiagnoses.synchronous_malignancy dtype: object\n\nValue counts for each column:\n\ndiagnoses.diagnosis_is_primary_disease:\ndiagnoses.diagnosis_is_primary_disease\nTrue     4896\nFalse      24\nName: count, dtype: int64\n\ndiagnoses.prior_malignancy:\ndiagnoses.prior_malignancy\nFalse    4738\nTrue      133\nName: count, dtype: int64\n\ndiagnoses.prior_treatment:\ndiagnoses.prior_treatment\nFalse    4862\nTrue       48\nName: count, dtype: int64\n\ndiagnoses.synchronous_malignancy:\ndiagnoses.synchronous_malignancy\nFalse    4763\nTrue      108\nName: count, dtype: int64\n\n\n\n\nData Engineering\n\n# Percentage of missing values in each column\nmissing_percentages = brca_df.isnull().mean() * 100\nprint(\"\\nPercentage of missing values in each column:\")\nprint(missing_percentages)\n\n\nPercentage of missing values in each column:\nproject.project_id                         0.000000\ncases.case_id                              0.000000\ncases.disease_type                         0.000000\ncases.index_date                           0.000000\ncases.primary_site                         0.000000\ncases.submitter_id                         0.000000\ndemographic.age_is_obfuscated              0.000000\ndemographic.days_to_death                 88.109756\ndemographic.ethnicity                      0.000000\ndemographic.gender                         0.000000\ndemographic.race                           0.000000\ndemographic.submitter_id                   0.000000\ndemographic.vital_status                   0.000000\ndiagnoses.age_at_diagnosis                 0.000000\ndiagnoses.ajcc_pathologic_m                0.000000\ndiagnoses.ajcc_pathologic_n                0.000000\ndiagnoses.ajcc_pathologic_stage            0.000000\ndiagnoses.ajcc_pathologic_t                0.000000\ndiagnoses.classification_of_tumor          0.000000\ndiagnoses.days_to_diagnosis                0.000000\ndiagnoses.days_to_last_follow_up           0.487805\ndiagnoses.diagnosis_is_primary_disease     0.000000\ndiagnoses.laterality                       0.000000\ndiagnoses.method_of_diagnosis              0.000000\ndiagnoses.morphology                       0.000000\ndiagnoses.primary_diagnosis                0.000000\ndiagnoses.prior_malignancy                 0.995935\ndiagnoses.prior_treatment                  0.203252\ndiagnoses.site_of_resection_or_biopsy      0.000000\ndiagnoses.sites_of_involvement             0.000000\ndiagnoses.submitter_id                     0.000000\ndiagnoses.synchronous_malignancy           0.995935\ndiagnoses.tissue_or_organ_of_origin        0.000000\ntreatments.submitter_id                    0.000000\ntreatments.treatment_or_therapy            1.463415\ntreatments.treatment_type                  0.000000\ndtype: float64\n\n\n\n# Check percentage of missing values in days_to_death when vital_status is 'dead'\nmissing_death_percentage = brca_df[brca_df['demographic.vital_status'] == 'dead']['demographic.days_to_death'].isnull().mean()\nprint(f\"Percentage of missing values in 'demographic.days_to_death' when vital_status is 'dead': {missing_death_percentage:.2%}\")    \n\nPercentage of missing values in 'demographic.days_to_death' when vital_status is 'dead': 0.00%\n\n\n\n# Percentage of missing values in days_to_last_follow_up when vital_status is 'alive'\nmissing_followup_percentage = brca_df[brca_df['demographic.vital_status'] == 'alive']['diagnoses.days_to_last_follow_up'].isnull().mean()\nprint(f\"Percentage of missing values in 'diagnoses.days_to_last_follow_up' when vital_status is 'alive': {missing_followup_percentage:.2%}\")\n\nPercentage of missing values in 'diagnoses.days_to_last_follow_up' when vital_status is 'alive': 0.55%\n\n\n\n# Change days_to_last_follow_up to numeric\nbrca_df['diagnoses.days_to_last_follow_up'] = pd.to_numeric(\n    brca_df['diagnoses.days_to_last_follow_up'], \n    errors='coerce'\n)\n\n\n# Check distribution of days_to_last_follow_up\nbrca_df['diagnoses.days_to_last_follow_up'].describe()\n\ncount    4896.000000\nmean     1323.354575\nstd      1176.067445\nmin        -7.000000\n25%       525.000000\n50%       972.000000\n75%      1876.000000\nmax      8605.000000\nName: diagnoses.days_to_last_follow_up, dtype: float64\n\n\n\n# Replace days to last follow up values less than 0 to with mean\nbrca_df.loc[brca_df['diagnoses.days_to_last_follow_up'] &lt; 0, 'diagnoses.days_to_last_follow_up'] = np.nan\nmean_followup = brca_df['diagnoses.days_to_last_follow_up'].mean()\nbrca_df['diagnoses.days_to_last_follow_up'].fillna(mean_followup, inplace=True)\n\n\n# Create survival time column based on vital status\ndef calculate_survival_time(row):\n    if row['demographic.vital_status'] == 'dead':\n        return row['demographic.days_to_death']\n    elif row['demographic.vital_status'] == 'alive':\n        return row['diagnoses.days_to_last_follow_up']\n    else:\n        return np.nan\n    \nbrca_df['survival_time_days'] = brca_df.apply(calculate_survival_time, axis=1)\n\n\n# Check percentage of missing values in survival_time_days\nmissing_percentage = brca_df['survival_time_days'].isnull().mean() * 100\nprint(f\"Percentage of missing values in 'survival_time_days': {missing_percentage:.2f}%\")\n\nPercentage of missing values in 'survival_time_days': 0.00%\n\n\n\n# Drop rows with missing survival_time_days\nbrca_df = brca_df[brca_df['survival_time_days'].notna()]\nbrca_df.shape\n\n(4920, 37)\n\n\n\n# Drop duplicate rows before feature engineering\nbrca_df = brca_df.drop_duplicates()\nbrca_df.shape\n\n(4920, 37)\n\n\n\n# Extract diagnoses.behavior from diagnoses.morphology column (e.g., 8500/3 -&gt; 3 where 3 is the behavior code)\n\n# Mappings for behavior codes\nbehavior_mapping = {\n    '0': 'benign',\n    '2': 'in situ',\n    '3': 'malignant'\n}\n# Extract behavior code and map to descriptive labels\nbrca_df['diagnoses.behavior'] = brca_df['diagnoses.morphology'].str.split('/').str[1].map(behavior_mapping)\n# Check the new column\nprint(\"Value counts for diagnoses.behavior:\")\nprint(brca_df['diagnoses.behavior'].value_counts())\n\nValue counts for diagnoses.behavior:\ndiagnoses.behavior\nmalignant    4905\nin situ         6\nName: count, dtype: int64\n\n\nNote: There is a heavy class imbalance for diagnoses.behavior as over 95% of the entries are malignant.\n\nbrca_df.head()\n\n\n\n\n\n\n\n\nproject.project_id\ncases.case_id\ncases.disease_type\ncases.index_date\ncases.primary_site\ncases.submitter_id\ndemographic.age_is_obfuscated\ndemographic.days_to_death\ndemographic.ethnicity\ndemographic.gender\ndemographic.race\ndemographic.submitter_id\ndemographic.vital_status\ndiagnoses.age_at_diagnosis\ndiagnoses.ajcc_pathologic_m\ndiagnoses.ajcc_pathologic_n\ndiagnoses.ajcc_pathologic_stage\ndiagnoses.ajcc_pathologic_t\ndiagnoses.classification_of_tumor\ndiagnoses.days_to_diagnosis\ndiagnoses.days_to_last_follow_up\ndiagnoses.diagnosis_is_primary_disease\ndiagnoses.laterality\ndiagnoses.method_of_diagnosis\ndiagnoses.morphology\ndiagnoses.primary_diagnosis\ndiagnoses.prior_malignancy\ndiagnoses.prior_treatment\ndiagnoses.site_of_resection_or_biopsy\ndiagnoses.sites_of_involvement\ndiagnoses.submitter_id\ndiagnoses.synchronous_malignancy\ndiagnoses.tissue_or_organ_of_origin\ntreatments.submitter_id\ntreatments.treatment_or_therapy\ntreatments.treatment_type\nsurvival_time_days\ndiagnoses.behavior\n\n\n\n\n0\ntcga-brca\n001cef41-ff86-4d3f-a140-a647ac4b10a1\nductal and lobular neoplasms\ndiagnosis\nbreast\ntcga-e2-a1iu\nFalse\nNaN\nnot hispanic or latino\nfemale\nwhite\ntcga-e2-a1iu_demographic\nalive\n60.0\nm0\nn0 (mol+)\nstage ia\nt1c\nprimary\n0\n337.0\nTrue\nright\nsurgical resection\n8500/3\ninfiltrating duct carcinoma, nos\nFalse\nFalse\nbreast, nos\nbreast, right upper outer\ntcga-e2-a1iu_diagnosis\nFalse\nbreast, nos\ntcga-e2-a1iu_treatment2\nFalse\nradiation therapy, nos\n337.0\nmalignant\n\n\n1\ntcga-brca\n001cef41-ff86-4d3f-a140-a647ac4b10a1\nductal and lobular neoplasms\ndiagnosis\nbreast\ntcga-e2-a1iu\nFalse\nNaN\nnot hispanic or latino\nfemale\nwhite\ntcga-e2-a1iu_demographic\nalive\n60.0\nm0\nn0 (mol+)\nstage ia\nt1c\nprimary\n0\n337.0\nTrue\nright\nsurgical resection\n8500/3\ninfiltrating duct carcinoma, nos\nFalse\nFalse\nbreast, nos\nbreast, right upper outer\ntcga-e2-a1iu_diagnosis\nFalse\nbreast, nos\ntcga-e2-a1iu_treatment\nTrue\nhormone therapy\n337.0\nmalignant\n\n\n2\ntcga-brca\n001cef41-ff86-4d3f-a140-a647ac4b10a1\nductal and lobular neoplasms\ndiagnosis\nbreast\ntcga-e2-a1iu\nFalse\nNaN\nnot hispanic or latino\nfemale\nwhite\ntcga-e2-a1iu_demographic\nalive\n60.0\nm0\nn0 (mol+)\nstage ia\nt1c\nprimary\n0\n337.0\nTrue\nright\nsurgical resection\n8500/3\ninfiltrating duct carcinoma, nos\nFalse\nFalse\nbreast, nos\nbreast, right upper outer\ntcga-e2-a1iu_diagnosis\nFalse\nbreast, nos\ntcga-e2-a1iu_treatment3\nTrue\nsurgery, nos\n337.0\nmalignant\n\n\n3\ntcga-brca\n0045349c-69d9-4306-a403-c9c1fa836644\nadenomas and adenocarcinomas\ndiagnosis\nbreast\ntcga-a1-a0sb\nFalse\nNaN\nnot hispanic or latino\nfemale\nwhite\ntcga-a1-a0sb_demographic\nalive\n70.0\nm0\nn0\nstage i\nt1c\nprimary\n0\n259.0\nTrue\nleft\nfine needle aspiration\n8200/3\nadenoid cystic carcinoma\nFalse\nFalse\nbreast, nos\nbreast, nos\ntcga-a1-a0sb_diagnosis\nFalse\nbreast, nos\ntcga-a1-a0sb_treatment\nTrue\nsurgery, nos\n259.0\nmalignant\n\n\n4\ntcga-brca\n00807dae-9f4a-4fd1-aac2-82eb11bf2afb\nadnexal and skin appendage neoplasms\ndiagnosis\nbreast\ntcga-a2-a04w\nFalse\nNaN\nnot hispanic or latino\nfemale\nwhite\ntcga-a2-a04w_demographic\nalive\n50.0\nm0\nn1mi\nstage iib\nt2\nprimary\n0\n3102.0\nTrue\nright\ncore biopsy\n8401/3\napocrine adenocarcinoma\nFalse\nFalse\nbreast, nos\nbreast, right upper outer\ntcga-a2-a04w_diagnosis\nFalse\nbreast, nos\ntcga-a2-a04w_treatment5\nTrue\nbisphosphonate therapy\n3102.0\nmalignant\n\n\n\n\n\n\n\n\n# Check distribution of missing values in columns after cleaning and data engineering\nmissing_percentages = brca_df.isnull().mean() * 100\nprint(\"\\nPercentage of missing values in each column:\")\nprint(missing_percentages)\n\n\nPercentage of missing values in each column:\nproject.project_id                         0.000000\ncases.case_id                              0.000000\ncases.disease_type                         0.000000\ncases.index_date                           0.000000\ncases.primary_site                         0.000000\ncases.submitter_id                         0.000000\ndemographic.age_is_obfuscated              0.000000\ndemographic.days_to_death                 88.109756\ndemographic.ethnicity                      0.000000\ndemographic.gender                         0.000000\ndemographic.race                           0.000000\ndemographic.submitter_id                   0.000000\ndemographic.vital_status                   0.000000\ndiagnoses.age_at_diagnosis                 0.000000\ndiagnoses.ajcc_pathologic_m                0.000000\ndiagnoses.ajcc_pathologic_n                0.000000\ndiagnoses.ajcc_pathologic_stage            0.000000\ndiagnoses.ajcc_pathologic_t                0.000000\ndiagnoses.classification_of_tumor          0.000000\ndiagnoses.days_to_diagnosis                0.000000\ndiagnoses.days_to_last_follow_up           0.000000\ndiagnoses.diagnosis_is_primary_disease     0.000000\ndiagnoses.laterality                       0.000000\ndiagnoses.method_of_diagnosis              0.000000\ndiagnoses.morphology                       0.000000\ndiagnoses.primary_diagnosis                0.000000\ndiagnoses.prior_malignancy                 0.995935\ndiagnoses.prior_treatment                  0.203252\ndiagnoses.site_of_resection_or_biopsy      0.000000\ndiagnoses.sites_of_involvement             0.000000\ndiagnoses.submitter_id                     0.000000\ndiagnoses.synchronous_malignancy           0.995935\ndiagnoses.tissue_or_organ_of_origin        0.000000\ntreatments.submitter_id                    0.000000\ntreatments.treatment_or_therapy            1.463415\ntreatments.treatment_type                  0.000000\nsurvival_time_days                         0.000000\ndiagnoses.behavior                         0.182927\ndtype: float64\n\n\n\n# Replace missing values in diagnoses.prior_malignancy, diagnoses.prior_treatment, diagnoses.synchronous_malignancy with False, treatments.treat_or_therapy with True\nbrca_df['diagnoses.prior_malignancy'] = brca_df['diagnoses.prior_malignancy'].fillna(False)\nbrca_df['diagnoses.prior_treatment'] = brca_df['diagnoses.prior_treatment'].fillna(False)\nbrca_df['diagnoses.synchronous_malignancy'] = brca_df['diagnoses.synchronous_malignancy'].fillna(False)\nbrca_df['treatments.treatment_or_therapy'] = brca_df['treatments.treatment_or_therapy'].fillna(True)\n\n\n\nSave processed dataset\n\n# Save cleaned dataset to a new TSV file\nbrca_df.to_csv(\"../../data/processed-data/brca/brca-clinical-processed.tsv\", sep=\"\\t\", index=False)"
  },
  {
    "objectID": "technical-details/data-cleaning/overview.html",
    "href": "technical-details/data-cleaning/overview.html",
    "title": "Overview",
    "section": "",
    "text": "Our data cleaning methods were comparable for both the cervical (cesc) and breast (brca) cancer datasets due to the dataset having similar columns due to both diseases being cancer. The clinical breast cancer dataset originally has 5546 rows and 210 columns representing 1098 patients. The clinical cervical cancer dataset originally has 1535 rows and 210 columns representing 307 patients.\nOur data cleaning was focused on three key areas:\nVisualizations below will be centered on the brca dataset due to the larger number of samples. However, the similar process for cleaning the cesc dataset can be found here along with the data cleaning code for the brca dataset."
  },
  {
    "objectID": "technical-details/data-cleaning/overview.html#managing-missing-data",
    "href": "technical-details/data-cleaning/overview.html#managing-missing-data",
    "title": "Overview",
    "section": "Managing Missing Data:",
    "text": "Managing Missing Data:\n\n\n\n\n\n\nRows showing a unique patient (cases.submitter_id) and their different treatments for breast cancer\n\n\n\nproject.project_id\ncases.case_id\ncases.consent_type\ncases.days_to_consent\ncases.days_to_lost_to_followup\ncases.disease_type\ncases.index_date\ncases.lost_to_followup\ncases.primary_site\ncases.submitter_id\n...\ntreatments.treatment_duration\ntreatments.treatment_effect\ntreatments.treatment_effect_indicator\ntreatments.treatment_frequency\ntreatments.treatment_id\ntreatments.treatment_intent_type\ntreatments.treatment_or_therapy\ntreatments.treatment_outcome\ntreatments.treatment_outcome_duration\ntreatments.treatment_type\n\n\n\n\n0\nTCGA-BRCA\n001cef41-ff86-4d3f-a140-a647ac4b10a1\nInformed Consent\n-34\n'--\nDuctal and Lobular Neoplasms\nDiagnosis\n'--\nBreast\nTCGA-E2-A1IU\n...\n'--\n'--\n'--\n'--\n1b884f21-eb24-467f-aba2-208af17070b9\nAdjuvant\nno\n'--\n'--\nRadiation Therapy, NOS\n\n\n1\nTCGA-BRCA\n001cef41-ff86-4d3f-a140-a647ac4b10a1\nInformed Consent\n-34\n'--\nDuctal and Lobular Neoplasms\nDiagnosis\n'--\nBreast\nTCGA-E2-A1IU\n...\n'--\n'--\n'--\n'--\n27868bc3-23c8-5e85-a0e2-314e6cdf9b2a\nAdjuvant\nyes\nTreatment Ongoing\n'--\nHormone Therapy\n\n\n2\nTCGA-BRCA\n001cef41-ff86-4d3f-a140-a647ac4b10a1\nInformed Consent\n-34\n'--\nDuctal and Lobular Neoplasms\nDiagnosis\n'--\nBreast\nTCGA-E2-A1IU\n...\n'--\n'--\n'--\n'--\naedf144c-6b7b-4d76-a3cb-4271aef10f1d\nFirst-Line Therapy\nyes\n'--\n'--\nSurgery, NOS\n\n\n3\nTCGA-BRCA\n0045349c-69d9-4306-a403-c9c1fa836644\nInformed Consent\n76\n'--\nAdenomas and Adenocarcinomas\nDiagnosis\n'--\nBreast\nTCGA-A1-A0SB\n...\n'--\n'--\n'--\n'--\n0a534cae-de91-5e77-a3e7-b52d46bd3966\nFirst-Line Therapy\nyes\n'--\n'--\nSurgery, NOS\n\n\n4\nTCGA-BRCA\n00807dae-9f4a-4fd1-aac2-82eb11bf2afb\nInformed Consent\n19\n'--\nAdnexal and Skin Appendage Neoplasms\nDiagnosis\nNo\nBreast\nTCGA-A2-A04W\n...\n'--\n'--\n'--\n'--\n024faa94-ec57-4d14-b919-62dcab409958\nAdjuvant\nyes\nTreatment Ongoing\n'--\nBisphosphonate Therapy\n\n\n\n\n5 rows × 210 columns\n\n\n\nMissing data: From viewing both datasets, the missing data was represented as ’— and required replacing the placeholder string with numpy nontype in order to handle missing values efficiently.\nThe missing values per columns ranged from 0% to 100%, this was a limitation of the datasets especially due to a lot of demographic columns having a large percentage of missing values, as these columns might have been potential social determinants of survival days depending on the type of cancer,\n\n\ndemographic.year_of_birth: 0.00% missing values\ndemographic.age_at_index: 0.00% missing values\ndemographic.cause_of_death: 0.00% missing values\ndemographic.year_of_death: 0.00% missing values\ndemographic.vital_status: 0.00% missing values\ndemographic.cause_of_death: 0.00% missing values\ndemographic.education_level: 0.00% missing values\ndemographic.days_to_death: 0.00% missing values\n\n\nHowever, the demographic.vital_status column has fewer missing values, which still allowed for some analysis regarding survival status. Despite a large number of missing values in demographic.days_to_death, we reasonable assummed it is because the patient is alive since the missing values corresponded to alive in the vital_status column. In addition, days_to_last_follow_up also has fewer missing values (11% in the brca dataset, and 12% in the cesc dataset), which enabled inferring survival time in feature engineering.\nThe datasets had a lot of columns with missing data. The overall original view of missing data in the brca dataset is showed below:\n\n\n&lt;Figure size 1440x768 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\nMost of the missing values were initially dropped through the following logic:\n\nDrop of columns with more than 30% data missing (except days_to_death as it is a key column for analysis). This reduced the number of columns by ~75% (e.g., to 46 columns for brca)\nDrop of columns irrelevant to the task of analysing survival time for the two different types of cancers e.g., data consent - not a predictor of how someone will survive a cancer, year of diagnoses - age at diagnoses captures the effect\nDrop of duplicate rows and rows with greater than 30% of the data missing i.e., 30% of information on that patient missing\n\nThe above resulted in a cleaner dataset as shown below:\n\n\n\nDistribution of missing data after dropping missing values as described above\n\n\nAfterwards, missing data was cleaned as follows\n\nFor most of the columns, the missing values were replaced with the mode/most frequent value e.g., diasease_is_primary diasease as True, site_of_involvement as breast, pathologic n (lymph node component of cancer staging) as N0 (no regional lymph node metastasis) due to heavy imbalance towards specific classes\nOverall stage infered from pathologic n, pathologic t (size and extent of primary tumor), and pathologic m (distant metastasis - whether the cancer has spread to distant organs)\nHandling of missing data in days_to_death was handled in the supervised learning section, this was due to the patients still being alive"
  },
  {
    "objectID": "technical-details/data-cleaning/overview.html#data-type-correction-and-formatting",
    "href": "technical-details/data-cleaning/overview.html#data-type-correction-and-formatting",
    "title": "Overview",
    "section": "Data Type Correction and Formatting:",
    "text": "Data Type Correction and Formatting:\n\nData Types: All columns in the dataset are originally stored as object datatype\nTransformation: Columns were changed to numeric, boolean, and strings as needed in the dataset\n\nNumeric: days_to_death and days_to_last_follow_up were changed to numeric integers. age_at_diagnoses was changed from days to years for easier analysis during exploratory data analysis\nBoolean: Boolean columns were primarily coded as yes/no and these values were changed to True/False respectively\nStrings: Object columns were changed to lowercase strings and leading/trailing whitespace trimmed\n\nImpact of changes: These changes were primarily made with exploratory data analysis in mind and a longer term view towards survival time prediction. Changing age at diagnoses to years enabled better synthesis of multivariate analysis and while preserving days_to_death and days_to_last_follow_up preserved information as the columns are a measure of survival time. Boolean columns enabled efficient filtering and subseeting and the string columns were optimal for wordcloud analysis."
  },
  {
    "objectID": "technical-details/data-cleaning/overview.html#data-engineering",
    "href": "technical-details/data-cleaning/overview.html#data-engineering",
    "title": "Overview",
    "section": "Data Engineering:",
    "text": "Data Engineering:\nAfter validating the range and distribution of age_at_diagnosis (min of 26 years and max of 89 years), and handling negative values for days_to_last_follow_up by replacing them with the mean, our data engineering process involved extracting more data from columns. Primarily the two columns below were derived:\n\ndiagnosis.behavior: Tumor behavior was derived from the diagnoses.morphology field using the International Classification of Diseases for Oncology, Third Edition (ICD-O-3). Morphology codes follow the format ####/B, where the digit following the slash encodes tumor behavior (e.g., /3 indicates malignant primary disease). For example, morphology code 8500/3 corresponds to infiltrating duct carcinoma with malignant primary behavior. Behavior values were extracted and mapped to ordinal numeric representations following ICD-O-3 guidelines.1\nsurvival_time_days: Survival time was derived using clinical time-to-event variables provided by the Genomic Data Commons (GDC).2 For patients with a recorded death event, survival time was calculated as the difference between demographic.days_to_death and diagnoses.days_to_diagnosis, yielding the number of days survived following cancer diagnosis. For patients without a recorded death event (i.e., alive at last contact), survival time was defined as diagnoses.days_to_last_follow_up, representing the number of days from diagnosis to the most recent clinical follow-up. This approach follows standard survival analysis practice by treating deaths as observed events and living patients as right-censored observations. Missing values in days_to_death were therefore interpreted as censored outcomes rather than zero survival time. No additional adjustments or imputation were applied to survival duration to preserve the temporal integrity of the observed clinical timelines.\n\nFurther data engineering e.g., handling of multiple rows per patient due to multiple treatment types, were handled in feature engineering before machine learning in order to analyse variables in depth e.g., number of treatments. Additional columns are also dropped and some created after exploratory data analysis (EDA) continuing the process of data engineering.\nFor cervical cancer, data cleaning also included extracting the tobacco smoking status and unique ID from the exposure dataset. Unfortunately, the breast cancer exposure file contained only missing values, limiting our analysis. However, examining tobacco exposure in the cervical cancer dataset and not in the breast cancer dataset is epidemiologically justified as cigarette smoking is a recognized co-factor in cervical carcinogenesis while it is not considered a primary risk factor for breast cancer onset or progression, with prior research indicating weak, inconsistent, or indirect associations compared to dominant hormonal, genetic, and reproductive factors3"
  },
  {
    "objectID": "technical-details/eda/main.html#breast-brca-dataset-eda",
    "href": "technical-details/eda/main.html#breast-brca-dataset-eda",
    "title": "Exploratory Data Analysis",
    "section": "Breast (BRCA) Dataset EDA",
    "text": "Breast (BRCA) Dataset EDA\n\n\nBRCA Dataset Overview:\nShape: (4920, 38)\n\nColumns: ['project.project_id', 'cases.case_id', 'cases.disease_type', 'cases.index_date', 'cases.primary_site', 'cases.submitter_id', 'demographic.age_is_obfuscated', 'demographic.days_to_death', 'demographic.ethnicity', 'demographic.gender', 'demographic.race', 'demographic.submitter_id', 'demographic.vital_status', 'diagnoses.age_at_diagnosis', 'diagnoses.ajcc_pathologic_m', 'diagnoses.ajcc_pathologic_n', 'diagnoses.ajcc_pathologic_stage', 'diagnoses.ajcc_pathologic_t', 'diagnoses.classification_of_tumor', 'diagnoses.days_to_diagnosis', 'diagnoses.days_to_last_follow_up', 'diagnoses.diagnosis_is_primary_disease', 'diagnoses.laterality', 'diagnoses.method_of_diagnosis', 'diagnoses.morphology', 'diagnoses.primary_diagnosis', 'diagnoses.prior_malignancy', 'diagnoses.prior_treatment', 'diagnoses.site_of_resection_or_biopsy', 'diagnoses.sites_of_involvement', 'diagnoses.submitter_id', 'diagnoses.synchronous_malignancy', 'diagnoses.tissue_or_organ_of_origin', 'treatments.submitter_id', 'treatments.treatment_or_therapy', 'treatments.treatment_type', 'survival_time_days', 'diagnoses.behavior']\n\n\n\nUnivariate Analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnivariate Analysis Findings - Categorical - The breast cancer dataset is heavily imbalanced towards alive in the vital_status column, this makes sense as breast cancer has a high survival rate compared to many other cancers. - The behavior of the tumor is completely dominated by malignant tumors and for most patients, this is their first known malignant cancer diagnosis - Over 70% of the patients are white followed by almost 20% black/African American, this is reflective of the US population where breast cancer is most prevalent - As expected, most patients receive treatment with a majority receiving chemotherapy followed by surgery, and hormone therapy. - Last but not least, the disease type is ductal and lobular neoplasms and there is no difference in laterality (which breast)\n\n\n(4920, 38)\n\n\n\n\n\n\n\n\n\n\n\nUnivariate Analysis Findings - Numerical - The average age at diagnoses is 56 years old with a minimum age of 26 and a maximum age of 89 years old. - The average survival time is 1324 days from diagnoses and ranges from 0 days to 8605 days\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBivariate Analysis Findings - The survival time is slightly higher for dead patients compared to alive patients, this is likely due to many alive patients being recently diagnosed and have not had enough time to accumulate survival days. - Older patients tend to have lower survival times compared to younger patients, this is expected as older patients tend to have more comorbidities and a weaker immune system. - Patients who received immunotherapy tend to have higher survival times compared to other treatment types, this is likely due to immunotherapy being a more aggressive treatment option. The next type of treatment that shows higher survival times is chemotherapy. - Patients who opted for treatment tend to have higher survival times compared to those who did not receive treatment, this is expected as treatment is designed to improve patient outcomes. - There is lower survical times for patients with stage iiib as it is one of the more severe stages of breast cancer before metastasis (stage iv). Stage i and ib have the highest survival times as they are the least severe stages.\n\n\n\n\n\n\n\n\n\nMultivariate Analysis Findings - Generally, older patients tend to have lower survival times across all stages of breast cancer, with latter stages (stage iiib, iiic, iv)showing more pronounced decreases in survival time.\n- Younger patients generally have higher survival times, especially if the diagnoses is at an early stage (stage i, ib, ii). - Stage x is when the tumor could not be assessed, the patients tend to have a higher survival time - Overall, getting diagnoses at an earlier stage is associated with better survival outcomes, regardless of age. - Treatment or no treatment, there is no difference in survival times for older patients (&gt;70 years old). However, for younger patients (&lt; 70 years old), those who received treatment tend to have higher survival times compared to those who did not receive treatment.\n\n\n\n\n\n\n\n\n\nText Analysis Findings - Text Analysis Findings reveal not difference in breast side and a slightly higher frequency for the upper outer region.\n\n\nCorrelation between Age at Diagnosis and Survival Time: -0.1989\n\n\n\nThere is a negative correlation between age at diagnoses and survival time days, indicating that as age at diagnoses increases, survival time days tends to decrease. This suggests that older patients may have poorer survival outcomes compared to younger patients.\n\n\ncesc_df.head(1)\n\n\n\n\n\n\n\n\nproject.project_id\ncases.case_id\ncases.disease_type\ncases.index_date\ncases.lost_to_followup\ncases.primary_site\ncases.submitter_id\ndemographic.days_to_death\ndemographic.ethnicity\ndemographic.gender\ndemographic.race\ndemographic.submitter_id\ndemographic.vital_status\ndiagnoses.age_at_diagnosis\ndiagnoses.ajcc_pathologic_m\ndiagnoses.ajcc_pathologic_n\ndiagnoses.ajcc_pathologic_t\ndiagnoses.classification_of_tumor\ndiagnoses.days_to_diagnosis\ndiagnoses.days_to_last_follow_up\ndiagnoses.figo_stage\ndiagnoses.figo_staging_edition_year\ndiagnoses.method_of_diagnosis\ndiagnoses.morphology\ndiagnoses.primary_diagnosis\ndiagnoses.prior_malignancy\ndiagnoses.prior_treatment\ndiagnoses.site_of_resection_or_biopsy\ndiagnoses.submitter_id\ndiagnoses.synchronous_malignancy\ndiagnoses.tissue_or_organ_of_origin\ndiagnoses.tumor_grade\ntreatments.submitter_id\ntreatments.treatment_or_therapy\ntreatments.treatment_type\nsurvival_time_days\ndiagnoses.behavior\nexposures.tobacco_smoking_status\n\n\n\n\n0\ntcga-cesc\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nsquamous cell neoplasms\ndiagnosis\nyes\ncervix uteri\ntcga-c5-a2lv\nNaN\nnot hispanic or latino\nfemale\nblack or african american\ntcga-c5-a2lv_demographic\nalive\n36.0\nmx\nn1\nt1b\nprimary\n0\n2234.0\nstage ib\n1995\nbiopsy\n8070/3\nsquamous cell carcinoma, nos\nFalse\nFalse\ncervix uteri\ntcga-c5-a2lv_diagnosis\nFalse\ncervix uteri\ng3\ntcga-c5-a2lv_treatment3\nyes\nhysterectomy, nos\n2234.0\nmalignant\ncurrent smoker"
  },
  {
    "objectID": "technical-details/eda/main.html#cervical-cancer-cesc-dataset-eda",
    "href": "technical-details/eda/main.html#cervical-cancer-cesc-dataset-eda",
    "title": "Exploratory Data Analysis",
    "section": "Cervical Cancer (CESC) Dataset EDA",
    "text": "Cervical Cancer (CESC) Dataset EDA\nBelow are the focus of the EDA,\n\nUnivariate Analysis (Single Feature)\n\nFrequency Counts: For categorical features (e.g., vital_status, figo_stage, tumor_grade, treatment_type, diagnoses.behavior), visualize frequency distribution (bar charts).\nAge Distribution: Analyze the range and spread of age at diagnoses data (histograms, box plots).\nSurvival time distribution See the spread of survival_time_days (histograms, box plots).\nRace distribution\n\n\n\nBivariate Analysis (Two Features)\n\nvital_status vs. survival_time_days: Explore how survival time varies by vital_status, infer average survival_time_days (box plot or scatter plot).\nage_at_diagnoses vs. average survival_time_days: Analyze differences in average survival time by age_at_diagnoses .\ntreatment_type vs. survival_time_days: Check how treatment_type and survival_time_days are related.\ntreatment_type vs. vital_status: Check treatment_type s offered by vital_status.\nfigo_stage vs. survival_time_days: Explore how survival time varies by ajcc_pathological_stage.\nSurvival_time_days vs. race: Analyze survival time across different races.\nTumor_grade vs. survival_time_days: Explore how survival time varies by tumor_grade.\nDiagnoses behavior vs survival_time_days: Explore how survival time varies by diagnoses behavior.\n\n\n\nMultivariate Analysis (Multiple Features)\n\nTumor_stage vs. age_at_diagnoses vs. survival_time_days : Analyze how survival time varies across different stages and age groups (3D scatter plot or heatmap).\ntreatment_type vs. age_at_diagnoses vs. survival_time_days: Explore trends across treatment types, age groups, and survival times (grouped bar plots).\nfigo_stage vs. age_at_diagnoses vs. survival_time_days: Check if stage impacts survival time at different age groups.\ndiagnoses.behavior vs. age_at_diagnoses vs. survival_time_days: Compare survival times across diagnoses behavior and age groups.\n\n\n\nCorrelations and Associations\n\nCorrelation Matrix: Compute correlations between numerical features (e.g., age_at_diagnoses and survival_time_Days) to find relationships."
  },
  {
    "objectID": "technical-details/eda/main.html#cervical-cesc-dataset-eda",
    "href": "technical-details/eda/main.html#cervical-cesc-dataset-eda",
    "title": "Exploratory Data Analysis",
    "section": "Cervical (CESC) Dataset EDA",
    "text": "Cervical (CESC) Dataset EDA\nDue to slightly different columns in the CESC dataset, the EDA will be adjusted accordingly.\n\n\nCESC Dataset Overview:\nShape: (872, 38)\n\nColumns: ['project.project_id', 'cases.case_id', 'cases.disease_type', 'cases.index_date', 'cases.lost_to_followup', 'cases.primary_site', 'cases.submitter_id', 'demographic.days_to_death', 'demographic.ethnicity', 'demographic.gender', 'demographic.race', 'demographic.submitter_id', 'demographic.vital_status', 'diagnoses.age_at_diagnosis', 'diagnoses.ajcc_pathologic_m', 'diagnoses.ajcc_pathologic_n', 'diagnoses.ajcc_pathologic_t', 'diagnoses.classification_of_tumor', 'diagnoses.days_to_diagnosis', 'diagnoses.days_to_last_follow_up', 'diagnoses.figo_stage', 'diagnoses.figo_staging_edition_year', 'diagnoses.method_of_diagnosis', 'diagnoses.morphology', 'diagnoses.primary_diagnosis', 'diagnoses.prior_malignancy', 'diagnoses.prior_treatment', 'diagnoses.site_of_resection_or_biopsy', 'diagnoses.submitter_id', 'diagnoses.synchronous_malignancy', 'diagnoses.tissue_or_organ_of_origin', 'diagnoses.tumor_grade', 'treatments.submitter_id', 'treatments.treatment_or_therapy', 'treatments.treatment_type', 'survival_time_days', 'diagnoses.behavior', 'exposures.tobacco_smoking_status']\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnivariate Analysis Findings - Categorical - The cervical cancer dataset is heavily imbalanced towards alive in the vital_status column, this makes sense as cervical cancer also has a high survival rate compared to many other cancers. - The tumor grade is mostly dominated by grade ii and grade iii tumors, with very few patients having grade i tumors. - The stage is domniated by ib1 followed by iib and ib2, which are some of the less severe stages of cervical cancer. - Almost 70% of the patients are white followed by an approximately equal distribution of the rest of the other races, which is not reflective of the US population - As expected, most patients receive treatment with a majority receiving pharmaceutical therapy followed by radiation therapy. - Last but not least, the disease type is squamous cell neoplasm. All of the patients have malignant tumors and no prior malignant cancer diagnoses.\n\n\n\n\n\n\n\n\n\nUnivariate Analysis Findings - Numerical - The average age at diagnoses is 48 years old with a minimum age of 25 and a maximum age of 80 years old. - The average survival time is 1036 days from diagnoses and ranges from 2 days to 6408 days\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBivariate Analysis Findings - The survival time is slightly higher for alive patients which is expected as alive patients have had more time to accumulate survival days, unlike breast cancer where many alive patients are recently diagnosed. - Older patients tend to have higher survival times compared to younger patients, this is unexpected as older patients tend to have more comorbidities and a weaker immune system. - Patients who received radiation combination therapy tend to have higher survival times compared to other treatment types, this is likely due to combination therapy being a more aggressive treatment option. The next type of treatment that shows higher survival times is pharmaceutical therapy. - There is no difference in survival times for patients who opted for treatment compared to those who did not receive treatment, which is unexpected as treatment is designed to improve patient outcomes. - There is lower survical times for patients with stage iiib, which is one of the more severe stages of cervical cancer before metastasis (stage iv). Stage ib has the highest survival times as it is one of the least severe stages. - Stage ia2, ia1 have small sample size which might indicate need for earlier testing to catch cancer at these stages. There is no data for stage iii which might also suggest a need to shift in diagnoses to earlier stages.\n\n\n\n\n\n\n\n\n\nMultivariate Analysis Findings - Generally, earlier stages show higher survival times across all age groups. - The heatmap plot interpretation is obfuscated by missing data at stages but also younger patients will have lower survival times due to less time to accumulate survival days.\n\n\nCorrelation between Age at Diagnosis and Survival Time: 0.1390\n\n\nThere is a positive correlation between age at diagnoses and survival time days, indicating that as age at diagnoses increases, survival time days tends to increase. This suggests that older patients may have better survival outcomes compared to younger patients but this is unexpected, potentially due to less survival days accumulated by younger patients.\n\ncesc_df.head(1)\n\n\n\n\n\n\n\n\nproject.project_id\ncases.case_id\ncases.disease_type\ncases.index_date\ncases.lost_to_followup\ncases.primary_site\ncases.submitter_id\ndemographic.days_to_death\ndemographic.ethnicity\ndemographic.gender\ndemographic.race\ndemographic.submitter_id\ndemographic.vital_status\ndiagnoses.age_at_diagnosis\ndiagnoses.ajcc_pathologic_m\ndiagnoses.ajcc_pathologic_n\ndiagnoses.ajcc_pathologic_t\ndiagnoses.classification_of_tumor\ndiagnoses.days_to_diagnosis\ndiagnoses.days_to_last_follow_up\ndiagnoses.figo_stage\ndiagnoses.figo_staging_edition_year\ndiagnoses.method_of_diagnosis\ndiagnoses.morphology\ndiagnoses.primary_diagnosis\ndiagnoses.prior_malignancy\ndiagnoses.prior_treatment\ndiagnoses.site_of_resection_or_biopsy\ndiagnoses.submitter_id\ndiagnoses.synchronous_malignancy\ndiagnoses.tissue_or_organ_of_origin\ndiagnoses.tumor_grade\ntreatments.submitter_id\ntreatments.treatment_or_therapy\ntreatments.treatment_type\nsurvival_time_days\ndiagnoses.behavior\nexposures.tobacco_smoking_status\nage_group\n\n\n\n\n0\ntcga-cesc\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nsquamous cell neoplasms\ndiagnosis\nyes\ncervix uteri\ntcga-c5-a2lv\nNaN\nnot hispanic or latino\nfemale\nblack or african american\ntcga-c5-a2lv_demographic\nalive\n36.0\nmx\nn1\nt1b\nprimary\n0\n2234.0\nstage ib\n1995\nbiopsy\n8070/3\nsquamous cell carcinoma, nos\nFalse\nFalse\ncervix uteri\ntcga-c5-a2lv_diagnosis\nFalse\ncervix uteri\ng3\ntcga-c5-a2lv_treatment3\nyes\nhysterectomy, nos\n2234.0\nmalignant\ncurrent smoker\n&lt;40\n\n\n\n\n\n\n\n\n\nSmoking Status Distribution in CESC Dataset:\nexposures.tobacco_smoking_status\nlifelong non-smoker                                553\ncurrent smoker                                     142\ncurrent reformed smoker for &lt; or = 15 yrs           94\nnot reported                                        29\nunknown                                             23\ncurrent reformed smoker for &gt; 15 yrs                20\ncurrent reformed smoker, duration not specified     11\nName: count, dtype: int64\n\nTotal patients with smoking data: 872\n\n\n\n\n\n\n\n\n\n\n============================================================\nSMOKING EXPOSURE SURVIVAL ANALYSIS SUMMARY\n============================================================\n\nInsufficient data for statistical comparison between never smokers and current smokers\n\n============================================================\n\n\nThere is a heavy imbalance towards lifelong non-smoker in the tobacco smoking status column which might indicate underreporting or misclassification of smoking status among cervical cancer patients. This results suggests that smoking status may not be a reliable indicator of cervical cancer risk in this dataset. From survival time by smoking status, lifelong non-smokers and unknowen tend to have higher survival times compared to current smokers and former smokers. However, there is insufficient data to draw definitive conclusions about the impact of smoking status on survival time in cervical cancer patients."
  },
  {
    "objectID": "technical-details/eda/main1.html",
    "href": "technical-details/eda/main1.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Note: You should remove these instructions once you have read and understood them. They should not be included in your final submission.\nRemember: Exactly what do you put on this page will be specific you your project and data. Some things might “make more sense” on one page rather than another, depending on your workflow. Organize your project in a logical way that makes the most sense to you.\n\n\nHere’s one suggested structure for organizing your technical pages. You can adjust this as needed:\nAudience:Remember that these are written for a technical audience. Assume they have completed the DSAN program, but would appreciate refreshers of the important concepts.\n\nIntroduction and Motivation: Briefly outline your plan. What are you doing on this page, and why? Provide context and explain the goals of your analysis.\nOverview of Methods: Give a concise explanation of the methods used. For example, if using K-Means clustering, describe what it is, how it works, the inputs and outputs, and key hyperparameters.\nCode: Include the code you used to implement your workflow.\nSummary and Interpretation of Results: Summarize your findings, interpret the results, and discuss their technical implications.\n\n\n\n\nThe following is a list of some of the things you should address on this page. This list is not exhaustive, and you should use your judgment to decide what is most relevant to your project.\nThe EDA (Exploratory Data Analysis) tab in your portfolio serves as a crucial foundation for your project. It provides a thorough overview of the dataset, highlights patterns, identifies potential issues, and prepares the data for further analysis. Follow these instructions to document your EDA effectively:\nThe goal of EDA is to gain a deeper understanding of the dataset and its relevance to your project’s objectives. It involves summarizing key data characteristics, identifying patterns, anomalies, and preparing for future analysis phases.\nHere are suggestions for things to include on this page\nUnivariate Analysis:\n\nNumerical Variables:\n\nProvide summary statistics (mean, median, standard deviation).\nVisualize distributions using histograms or density plots.\n\nCategorical Variables:\n\nPresent frequency counts and visualize distributions using bar charts or pie charts.\n\nKey Insights:\n\nHighlight any notable trends or patterns observed.\n\n\nBivariate and Multivariate Analysis:\n\nCorrelation Analysis:\n\nAnalyze relationships between numerical variables using a correlation matrix.\nVisualize with heatmaps or pair plots and discuss any strong correlations.\n\nCrosstabulations:\n\nFor categorical variables, use crosstabs to explore relationships and visualize them with grouped bar plots.\n\nFeature Pairings:\n\nAnalyze relationships between key variables, particularly those related to your target.\nVisualize with scatter plots, box plots, or violin plots.\n\n\nData Distribution and Normalization:\n\nSkewness and Kurtosis:\nAnalyze and discuss the distribution of variables.\nApply transformations (e.g., log transformation) if needed for skewed data.\nNormalization:\nApply normalization or scaling techniques (e.g., min-max scaling, z-score).\nDocument and visualize the impact of normalization.\n\nStatistical Insights:\n\nConduct basic statistical tests (e.g., T-tests, ANOVA, chi-square) to explore relationships between variables.\nSummarize the statistical results and their implications for your analysis.\n\nData Visualization and Storytelling:\n\nVisual Summary:\nPresent key insights using charts and visualizations (e.g., Matplotlib, Seaborn, Plotly).\nEnsure all visualizations are well-labeled and easy to interpret.\nInteractive Visualizations (Optional):\nInclude interactive elements (e.g., Plotly, Bokeh) to allow users to explore the data further.\n\nConclusions and Next Steps:\n\nSummary of EDA Findings:\nHighlight the main takeaways from the EDA process (key trends, patterns, data quality issues).\nImplications for Modeling:\nDiscuss how your EDA informs the next steps in your project (e.g., feature selection, data transformations).\nOutline any further data cleaning or preparation required before moving into modeling."
  },
  {
    "objectID": "technical-details/eda/main1.html#suggested-page-structure",
    "href": "technical-details/eda/main1.html#suggested-page-structure",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Here’s one suggested structure for organizing your technical pages. You can adjust this as needed:\nAudience:Remember that these are written for a technical audience. Assume they have completed the DSAN program, but would appreciate refreshers of the important concepts.\n\nIntroduction and Motivation: Briefly outline your plan. What are you doing on this page, and why? Provide context and explain the goals of your analysis.\nOverview of Methods: Give a concise explanation of the methods used. For example, if using K-Means clustering, describe what it is, how it works, the inputs and outputs, and key hyperparameters.\nCode: Include the code you used to implement your workflow.\nSummary and Interpretation of Results: Summarize your findings, interpret the results, and discuss their technical implications."
  },
  {
    "objectID": "technical-details/eda/main1.html#what-to-address",
    "href": "technical-details/eda/main1.html#what-to-address",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "The following is a list of some of the things you should address on this page. This list is not exhaustive, and you should use your judgment to decide what is most relevant to your project.\nThe EDA (Exploratory Data Analysis) tab in your portfolio serves as a crucial foundation for your project. It provides a thorough overview of the dataset, highlights patterns, identifies potential issues, and prepares the data for further analysis. Follow these instructions to document your EDA effectively:\nThe goal of EDA is to gain a deeper understanding of the dataset and its relevance to your project’s objectives. It involves summarizing key data characteristics, identifying patterns, anomalies, and preparing for future analysis phases.\nHere are suggestions for things to include on this page\nUnivariate Analysis:\n\nNumerical Variables:\n\nProvide summary statistics (mean, median, standard deviation).\nVisualize distributions using histograms or density plots.\n\nCategorical Variables:\n\nPresent frequency counts and visualize distributions using bar charts or pie charts.\n\nKey Insights:\n\nHighlight any notable trends or patterns observed.\n\n\nBivariate and Multivariate Analysis:\n\nCorrelation Analysis:\n\nAnalyze relationships between numerical variables using a correlation matrix.\nVisualize with heatmaps or pair plots and discuss any strong correlations.\n\nCrosstabulations:\n\nFor categorical variables, use crosstabs to explore relationships and visualize them with grouped bar plots.\n\nFeature Pairings:\n\nAnalyze relationships between key variables, particularly those related to your target.\nVisualize with scatter plots, box plots, or violin plots.\n\n\nData Distribution and Normalization:\n\nSkewness and Kurtosis:\nAnalyze and discuss the distribution of variables.\nApply transformations (e.g., log transformation) if needed for skewed data.\nNormalization:\nApply normalization or scaling techniques (e.g., min-max scaling, z-score).\nDocument and visualize the impact of normalization.\n\nStatistical Insights:\n\nConduct basic statistical tests (e.g., T-tests, ANOVA, chi-square) to explore relationships between variables.\nSummarize the statistical results and their implications for your analysis.\n\nData Visualization and Storytelling:\n\nVisual Summary:\nPresent key insights using charts and visualizations (e.g., Matplotlib, Seaborn, Plotly).\nEnsure all visualizations are well-labeled and easy to interpret.\nInteractive Visualizations (Optional):\nInclude interactive elements (e.g., Plotly, Bokeh) to allow users to explore the data further.\n\nConclusions and Next Steps:\n\nSummary of EDA Findings:\nHighlight the main takeaways from the EDA process (key trends, patterns, data quality issues).\nImplications for Modeling:\nDiscuss how your EDA informs the next steps in your project (e.g., feature selection, data transformations).\nOutline any further data cleaning or preparation required before moving into modeling."
  },
  {
    "objectID": "technical-details/eda/main.html#motivation-and-objectives",
    "href": "technical-details/eda/main.html#motivation-and-objectives",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Exploratory Data Analysis (EDA) serves as the critical foundation for understanding the complex clinical landscape of cancer patient data before building predictive models. Our analysis focuses on two major cancer types affecting women: Breast Invasive Carcinoma (BRCA) and Cervical Squamous Cell Carcinoma (CESC) from The Cancer Genome Atlas (TCGA).\n\n\nCancer datasets present unique analytical challenges that make thorough exploration crucial:\n\nMulti-dimensional Clinical Complexity: Cancer progression involves intricate relationships between patient demographics, tumor characteristics, staging systems (AJCC, FIGO), treatment modalities, and survival outcomes that require systematic investigation.\nData Quality Assessment: Clinical data often contains missing values, inconsistencies, and outliers due to variations in data collection protocols, patient follow-up patterns, and reporting standards across institutions.\nFeature Engineering Insights: Understanding distributions and relationships helps identify opportunities for creating meaningful derived features (e.g., ordinal encoding of cancer stages, treatment response indicators).\nModel Selection Guidance: EDA reveals whether relationships are linear or non-linear, helping inform appropriate algorithm choices for subsequent supervised and unsupervised learning tasks.\n\n\n\n\nOur EDA is designed to answer key questions that will inform our modeling strategy:\n\nSurvival Patterns: How do survival times vary between BRCA and CESC patients? What are the distributional characteristics of our regression target?\nStaging Relationships: How do different staging systems (AJCC pathologic staging, FIGO staging for cervical cancer) relate to patient outcomes?\nTreatment Impact: What treatment patterns exist, and how do they correlate with survival outcomes?\nFeature Relationships: Which clinical variables show the strongest associations with survival time and each other?\nData Completeness: Where are the gaps in our data, and how might they impact model performance?\n\n\n\n\nThrough systematic exploration, we aim to: - Identify the most informative features for survival prediction - Understand data preprocessing requirements - Detect potential confounding variables or selection biases - Establish baseline expectations for model performance - Generate hypotheses about cancer survival mechanisms for validation in supervised learning"
  },
  {
    "objectID": "technical-details/eda/main.html#why-eda-is-essential-for-cancer-data",
    "href": "technical-details/eda/main.html#why-eda-is-essential-for-cancer-data",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Cancer datasets present unique analytical challenges that make thorough exploration crucial:\n\nMulti-dimensional Clinical Complexity: Cancer progression involves intricate relationships between patient demographics, tumor characteristics, staging systems (AJCC, FIGO), treatment modalities, and survival outcomes that required systematic investigation.\nData Quality Assessment: EDA was also a process enabling us to assess the effectiveness of our data cleaning stage.\nFeature Engineering Insights: Understanding distributions and relationships helped identify opportunities for creating meaningful derived features (e.g., ordinal encoding of cancer stages, treatments offered).\nModel Selection Guidance: EDA revealed whether relationships are linear or non-linear, helping inform appropriate algorithm choices for subsequent supervised and unsupervised learning tasks."
  },
  {
    "objectID": "technical-details/eda/main.html#research-questions-driving-our-analysis",
    "href": "technical-details/eda/main.html#research-questions-driving-our-analysis",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Our EDA is designed to answer key questions that will inform our modeling strategy:\n\nSurvival Patterns: How do survival times vary between BRCA and CESC patients? What are the distributional characteristics of our regression target?\nStaging Relationships: How do different staging systems (AJCC pathologic staging, FIGO staging for cervical cancer) relate to patient outcomes?\nTreatment Impact: What treatment patterns exist, and how do they correlate with survival outcomes?\nFeature Relationships: Which clinical variables show the strongest associations with survival time and each other?\nData Completeness: Where are the gaps in our data, and how might they impact model performance?"
  },
  {
    "objectID": "technical-details/eda/main.html#expected-outcomes",
    "href": "technical-details/eda/main.html#expected-outcomes",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Through systematic exploration, we aimed to:\n\nIdentify the most informative features for survival prediction\nDetect potential confounding variables or selection biases\nEstablish baseline expectations for model performance\nGenerate hypotheses about cancer survival mechanisms for validation in supervised learning"
  },
  {
    "objectID": "technical-details/eda/main.html#univariate-analysis-single-feature",
    "href": "technical-details/eda/main.html#univariate-analysis-single-feature",
    "title": "Exploratory Data Analysis",
    "section": "Univariate Analysis (Single Feature)",
    "text": "Univariate Analysis (Single Feature)\n\nFrequency Counts: For categorical features (e.g., vital_status, ajcc_pathological_stage, classification_of_tumor, treatment_type, laterality, diagnoses.behavior), visualize frequency distribution (bar charts).\nAge Distribution: Analyze the range and spread of age at diagnoses data (histograms, box plots).\nSurvival time distribution See the spread of survival_time_days (histograms, box plots).\nRace distribution\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnivariate Analysis Findings - Categorical - The breast cancer dataset is heavily imbalanced towards alive in the vital_status column, this makes sense as breast cancer has a high survival rate compared to many other cancers. - The behavior of the tumor is completely dominated by malignant tumors and for most patients, this is their first known malignant cancer diagnosis - Over 70% of the patients are white followed by almost 20% black/African American, this is reflective of the US population where breast cancer is most prevalent - As expected, most patients receive treatment with a majority receiving chemotherapy followed by surgery, and hormone therapy. - Last but not least, the disease type is ductal and lobular neoplasms and there is no difference in laterality (which breast)\n\n\n\n\n\n\n\n\n\nUnivariate Analysis Findings - Numerical - The average age at diagnoses is 56 years old with a minimum age of 26 and a maximum age of 89 years old. - The average survival time is 1324 days from diagnoses and ranges from 0 days to 8605 days"
  },
  {
    "objectID": "technical-details/eda/main.html#bivariate-analysis-two-features",
    "href": "technical-details/eda/main.html#bivariate-analysis-two-features",
    "title": "Exploratory Data Analysis",
    "section": "Bivariate Analysis (Two Features)",
    "text": "Bivariate Analysis (Two Features)\n\nvital_status vs. survival_time_days: Explore how survival time varies by vital_status, infer average survival_time_days (box plot or scatter plot).\nage_at_diagnoses vs. average survival_time_days: Analyze differences in average survival time by age_at_diagnoses .\ntreatment_type vs. survival_time_days: Check how treatment_type and survival_time_days are related.\ntreatment_type vs. vital_status: Check treatment_type s offered by vital_status.\najcc_pathological_stage vs. survival_time_days: Explore how survival time varies by ajcc_pathological_stage.\nSurvival_time_days vs. race: Analyze survival time across different races.\nDiagnoses behavior vs survival_time_days: Explore how survival time varies by diagnoses behavior.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBivariate Analysis Findings - The survival time is slightly higher for dead patients compared to alive patients, this is likely due to many alive patients being recently diagnosed and have not had enough time to accumulate survival days. - Older patients tend to have lower survival times compared to younger patients, this is expected as older patients tend to have more comorbidities and a weaker immune system. - Patients who received immunotherapy tend to have higher survival times compared to other treatment types, this is likely due to immunotherapy being a more aggressive treatment option. The next type of treatment that shows higher survival times is chemotherapy. - Patients who opted for treatment tend to have higher survival times compared to those who did not receive treatment, this is expected as treatment is designed to improve patient outcomes. - There is lower survical times for patients with stage iiib as it is one of the more severe stages of breast cancer before metastasis (stage iv). Stage i and ib have the highest survival times as they are the least severe stages."
  },
  {
    "objectID": "technical-details/eda/main.html#multivariate-analysis-multiple-features",
    "href": "technical-details/eda/main.html#multivariate-analysis-multiple-features",
    "title": "Exploratory Data Analysis",
    "section": "Multivariate Analysis (Multiple Features)",
    "text": "Multivariate Analysis (Multiple Features)\n\najcc_pathological_stage vs. age_at_diagnoses vs. survival_time_days : Analyze how survival time varies across different stages and age groups (3D scatter plot or heatmap).\ntreatment_type vs. age_at_diagnoses vs. survival_time_days: Explore trends across treatment types, age groups, and survival times (grouped bar plots).\nlaterality vs. age_at_diagnoses vs. survival_time_days: Check if tumor laterality impacts survival time at different age groups.\ndiagnoses.behavior vs. age_at_diagnoses vs. survival_time_days: Compare survival times across diagnoses behavior and age groups.\n\n\n\n\n\n\n\n\n\n\nMultivariate Analysis Findings - Generally, older patients tend to have lower survival times across all stages of breast cancer, with latter stages (stage iiib, iiic, iv)showing more pronounced decreases in survival time.\n- Younger patients generally have higher survival times, especially if the diagnoses is at an early stage (stage i, ib, ii). - Stage x is when the tumor could not be assessed, the patients tend to have a higher survival time - Overall, getting diagnoses at an earlier stage is associated with better survival outcomes, regardless of age. - Treatment or no treatment, there is no difference in survival times for older patients (&gt;70 years old). However, for younger patients (&lt; 70 years old), those who received treatment tend to have higher survival times compared to those who did not receive treatment."
  },
  {
    "objectID": "technical-details/eda/main.html#text-analysis",
    "href": "technical-details/eda/main.html#text-analysis",
    "title": "Exploratory Data Analysis",
    "section": "Text Analysis",
    "text": "Text Analysis\n\nSites of involvement: Word cloud or frequency distribution of common sites mentioned.\n\n\n\n\n\n\n\n\n\n\nText Analysis Findings - Text Analysis Findings reveal not difference in breast side and a slightly higher frequency for the upper outer region."
  },
  {
    "objectID": "technical-details/eda/main.html#correlations-and-associations",
    "href": "technical-details/eda/main.html#correlations-and-associations",
    "title": "Exploratory Data Analysis",
    "section": "Correlations and Associations",
    "text": "Correlations and Associations\n\nCorrelation Matrix: Compute correlations between numerical features (e.g., age_at_diagnoses and survival_time_Days) to find relationships.\n\n\n\nCorrelation between Age at Diagnosis and Survival Time: -0.1989\n\n\n\nThere is a negative correlation between age at diagnoses and survival time days, indicating that as age at diagnoses increases, survival time days tends to decrease. This suggests that older patients may have poorer survival outcomes compared to younger patients.\n\n\ncesc_df.head(1)\n\n\n\n\n\n\n\n\nproject.project_id\ncases.case_id\ncases.disease_type\ncases.index_date\ncases.lost_to_followup\ncases.primary_site\ncases.submitter_id\ndemographic.days_to_death\ndemographic.ethnicity\ndemographic.gender\ndemographic.race\ndemographic.submitter_id\ndemographic.vital_status\ndiagnoses.age_at_diagnosis\ndiagnoses.ajcc_pathologic_m\ndiagnoses.ajcc_pathologic_n\ndiagnoses.ajcc_pathologic_t\ndiagnoses.classification_of_tumor\ndiagnoses.days_to_diagnosis\ndiagnoses.days_to_last_follow_up\ndiagnoses.figo_stage\ndiagnoses.figo_staging_edition_year\ndiagnoses.method_of_diagnosis\ndiagnoses.morphology\ndiagnoses.primary_diagnosis\ndiagnoses.prior_malignancy\ndiagnoses.prior_treatment\ndiagnoses.site_of_resection_or_biopsy\ndiagnoses.submitter_id\ndiagnoses.synchronous_malignancy\ndiagnoses.tissue_or_organ_of_origin\ndiagnoses.tumor_grade\ntreatments.submitter_id\ntreatments.treatment_or_therapy\ntreatments.treatment_type\nsurvival_time_days\ndiagnoses.behavior\nexposures.tobacco_smoking_status\n\n\n\n\n0\ntcga-cesc\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nsquamous cell neoplasms\ndiagnosis\nyes\ncervix uteri\ntcga-c5-a2lv\nNaN\nnot hispanic or latino\nfemale\nblack or african american\ntcga-c5-a2lv_demographic\nalive\n36.0\nmx\nn1\nt1b\nprimary\n0\n2234.0\nstage ib\n1995\nbiopsy\n8070/3\nsquamous cell carcinoma, nos\nFalse\nFalse\ncervix uteri\ntcga-c5-a2lv_diagnosis\nFalse\ncervix uteri\ng3\ntcga-c5-a2lv_treatment3\nyes\nhysterectomy, nos\n2234.0\nmalignant\ncurrent smoker"
  },
  {
    "objectID": "technical-details/eda/main.html#univariate-analysis-single-feature-1",
    "href": "technical-details/eda/main.html#univariate-analysis-single-feature-1",
    "title": "Exploratory Data Analysis",
    "section": "Univariate Analysis (Single Feature)",
    "text": "Univariate Analysis (Single Feature)\n\nFrequency Counts: For categorical features (e.g., vital_status, figo_stage, tumor_grade, treatment_type, diagnoses.behavior), visualize frequency distribution (bar charts).\nAge Distribution: Analyze the range and spread of age at diagnoses data (histograms, box plots).\nSurvival time distribution See the spread of survival_time_days (histograms, box plots).\nRace distribution\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnivariate Analysis Findings - Categorical - The cervical cancer dataset is heavily imbalanced towards alive in the vital_status column, this makes sense as cervical cancer also has a high survival rate compared to many other cancers. - The tumor grade is mostly dominated by grade ii and grade iii tumors, with very few patients having grade i tumors. - The stage is domniated by ib1 followed by iib and ib2, which are some of the less severe stages of cervical cancer. - Almost 70% of the patients are white followed by an approximately equal distribution of the rest of the other races, which is not reflective of the US population - As expected, most patients receive treatment with a majority receiving pharmaceutical therapy followed by radiation therapy. - Last but not least, the disease type is squamous cell neoplasm. All of the patients have malignant tumors and no prior malignant cancer diagnoses.\n\n\n\n\n\n\n\n\n\nUnivariate Analysis Findings - Numerical - The average age at diagnoses is 48 years old with a minimum age of 25 and a maximum age of 80 years old. - The average survival time is 1036 days from diagnoses and ranges from 2 days to 6408 days"
  },
  {
    "objectID": "technical-details/eda/main.html#bivariate-analysis-two-features-1",
    "href": "technical-details/eda/main.html#bivariate-analysis-two-features-1",
    "title": "Exploratory Data Analysis",
    "section": "Bivariate Analysis (Two Features)",
    "text": "Bivariate Analysis (Two Features)\n\nvital_status vs. survival_time_days: Explore how survival time varies by vital_status, infer average survival_time_days (box plot or scatter plot).\nage_at_diagnoses vs. average survival_time_days: Analyze differences in average survival time by age_at_diagnoses .\ntreatment_type vs. survival_time_days: Check how treatment_type and survival_time_days are related.\ntreatment_type vs. vital_status: Check treatment_type s offered by vital_status.\nfigo_stage vs. survival_time_days: Explore how survival time varies by ajcc_pathological_stage.\nSurvival_time_days vs. race: Analyze survival time across different races.\nTumor_grade vs. survival_time_days: Explore how survival time varies by tumor_grade.\nDiagnoses behavior vs survival_time_days: Explore how survival time varies by diagnoses behavior.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBivariate Analysis Findings - The survival time is slightly higher for alive patients which is expected as alive patients have had more time to accumulate survival days, unlike breast cancer where many alive patients are recently diagnosed. - Older patients tend to have higher survival times compared to younger patients, this is unexpected as older patients tend to have more comorbidities and a weaker immune system. - Patients who received radiation combination therapy tend to have higher survival times compared to other treatment types, this is likely due to combination therapy being a more aggressive treatment option. The next type of treatment that shows higher survival times is pharmaceutical therapy. - There is no difference in survival times for patients who opted for treatment compared to those who did not receive treatment, which is unexpected as treatment is designed to improve patient outcomes. - There is lower survical times for patients with stage iiib, which is one of the more severe stages of cervical cancer before metastasis (stage iv). Stage ib has the highest survival times as it is one of the least severe stages. - Stage ia2, ia1 have small sample size which might indicate need for earlier testing to catch cancer at these stages. There is no data for stage iii which might also suggest a need to shift in diagnoses to earlier stages."
  },
  {
    "objectID": "technical-details/eda/main.html#multivariate-analysis-multiple-features-1",
    "href": "technical-details/eda/main.html#multivariate-analysis-multiple-features-1",
    "title": "Exploratory Data Analysis",
    "section": "Multivariate Analysis (Multiple Features)",
    "text": "Multivariate Analysis (Multiple Features)\n\nTumor_stage vs. age_at_diagnoses vs. survival_time_days : Analyze how survival time varies across different stages and age groups (3D scatter plot or heatmap).\ntreatment_type vs. age_at_diagnoses vs. survival_time_days: Explore trends across treatment types, age groups, and survival times (grouped bar plots).\nfigo_stage vs. age_at_diagnoses vs. survival_time_days: Check if stage impacts survival time at different age groups.\ndiagnoses.behavior vs. age_at_diagnoses vs. survival_time_days: Compare survival times across diagnoses behavior and age groups.\n\n\n\n\n\n\n\n\n\n\nMultivariate Analysis Findings - Generally, earlier stages show higher survival times across all age groups. - The heatmap plot interpretation is obfuscated by missing data at stages but also younger patients will have lower survival times due to less time to accumulate survival days."
  },
  {
    "objectID": "technical-details/eda/main.html#correlations-and-associations-1",
    "href": "technical-details/eda/main.html#correlations-and-associations-1",
    "title": "Exploratory Data Analysis",
    "section": "Correlations and Associations",
    "text": "Correlations and Associations\n\nCorrelation Matrix: Compute correlations between numerical features (e.g., age_at_diagnoses and survival_time_Days) to find relationships.\n\n\n\nCorrelation between Age at Diagnosis and Survival Time: 0.1390\n\n\nThere is a positive correlation between age at diagnoses and survival time days, indicating that as age at diagnoses increases, survival time days tends to increase. This suggests that older patients may have better survival outcomes compared to younger patients but this is unexpected, potentially due to less survival days accumulated by younger patients."
  },
  {
    "objectID": "technical-details/eda/main.html#smoking-exposure-effect-on-survival-time-for-cesc-patients",
    "href": "technical-details/eda/main.html#smoking-exposure-effect-on-survival-time-for-cesc-patients",
    "title": "Exploratory Data Analysis",
    "section": "Smoking Exposure Effect on survival time for CESC patients",
    "text": "Smoking Exposure Effect on survival time for CESC patients\n\nsmoking_exposure vs. survival_time_days: Analyze how smoking exposure impacts survival time (box plots or histograms).\n\n\n\nSmoking Status Distribution in CESC Dataset:\nexposures.tobacco_smoking_status\nlifelong non-smoker                                553\ncurrent smoker                                     142\ncurrent reformed smoker for &lt; or = 15 yrs           94\nnot reported                                        29\nunknown                                             23\ncurrent reformed smoker for &gt; 15 yrs                20\ncurrent reformed smoker, duration not specified     11\nName: count, dtype: int64\n\nTotal patients with smoking data: 872\n\n\n\n\n\n\n\n\n\n\n============================================================\nSMOKING EXPOSURE SURVIVAL ANALYSIS SUMMARY\n============================================================\n\nInsufficient data for statistical comparison between never smokers and current smokers\n\n============================================================\n\n\nThere is a heavy imbalance towards lifelong non-smoker in the tobacco smoking status column which might indicate underreporting or misclassification of smoking status among cervical cancer patients. This results suggests that smoking status may not be a reliable indicator of cervical cancer risk in this dataset. From survival time by smoking status, lifelong non-smokers and unknowen tend to have higher survival times compared to current smokers and former smokers. However, there is insufficient data to draw definitive conclusions about the impact of smoking status on survival time in cervical cancer patients."
  },
  {
    "objectID": "technical-details/supervised-learning/main.html#training-and-testing",
    "href": "technical-details/supervised-learning/main.html#training-and-testing",
    "title": "Supervised Learning",
    "section": "",
    "text": "The dataset was split into training and testing sets using an 80-20 split. Cross-validation was employed during model training to ensure robustness and generalizability of the models.\n\n\n\n\nLinear Regression Model Evaluation on Test Set:\nRMSE: 61585077470726.38\nMAE: 7691527358667.03\nR2 Score: -2406669127225213190144.0000\n\n\n\n\n\nWe do a parametric Curve Fitting with L1 regularization (Lasso) to predict patient survival time based on the preprocessed BRCA dataset. Design choicces include: - Model Choice: Lasso regression is chosen for its ability to perform both variable selection and regularization, which helps enhance the prediction accuracy and interpretability of the statistical model it produces. In addition, early stopping is implemented to prevent overfitting during training. - Hyperparameter Tuning: The regularization parameter (alpha) tuned using cross-validation to find the optimal balance between bias and variance. - Evaluation Metrics: Model performance was evaluated using Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and R-squared (R²) to provide a comprehensive assessment of prediction accuracy. - SGDRegressor is used for optimization due to its efficiency with large datasets and ability to handle L1 regularization effectively.\n\n\nTraining MAE Linear Regression with Lasso Regularization...\n============================================================\n\nTesting alpha = 0.001\nEpoch 500: Train MAE = 1217.1975, Val MAE = 1269.3982\nEpoch 500: Train MAE = 1217.1975, Val MAE = 1269.3982\nEpoch 1000: Train MAE = 1216.7116, Val MAE = 1268.9919\nEpoch 1000: Train MAE = 1216.7116, Val MAE = 1268.9919\nEpoch 1500: Train MAE = 1216.2261, Val MAE = 1268.5873\nEpoch 1500: Train MAE = 1216.2261, Val MAE = 1268.5873\nEpoch 2000: Train MAE = 1215.7407, Val MAE = 1268.1848\n\nTesting alpha = 0.01\nEpoch 2000: Train MAE = 1215.7407, Val MAE = 1268.1848\n\nTesting alpha = 0.01\nEpoch 500: Train MAE = 1217.2068, Val MAE = 1269.3909\nEpoch 500: Train MAE = 1217.2068, Val MAE = 1269.3909\nEpoch 1000: Train MAE = 1216.7332, Val MAE = 1268.9616\nEpoch 1000: Train MAE = 1216.7332, Val MAE = 1268.9616\nEpoch 1500: Train MAE = 1216.2613, Val MAE = 1268.5353\nEpoch 1500: Train MAE = 1216.2613, Val MAE = 1268.5353\nEpoch 2000: Train MAE = 1215.7901, Val MAE = 1268.1114\n\nTesting alpha = 0.1\nEpoch 2000: Train MAE = 1215.7901, Val MAE = 1268.1114\n\nTesting alpha = 0.1\nEpoch 500: Train MAE = 1217.2204, Val MAE = 1269.3513\nEpoch 500: Train MAE = 1217.2204, Val MAE = 1269.3513\nEpoch 1000: Train MAE = 1216.7601, Val MAE = 1268.8937\nEpoch 1000: Train MAE = 1216.7601, Val MAE = 1268.8937\nEpoch 1500: Train MAE = 1216.3023, Val MAE = 1268.4425\nEpoch 1500: Train MAE = 1216.3023, Val MAE = 1268.4425\nEpoch 2000: Train MAE = 1215.8448, Val MAE = 1267.9919\n\nTesting alpha = 1.0\nEpoch 2000: Train MAE = 1215.8448, Val MAE = 1267.9919\n\nTesting alpha = 1.0\nEpoch 500: Train MAE = 1217.2207, Val MAE = 1269.3516\nEpoch 500: Train MAE = 1217.2207, Val MAE = 1269.3516\nEpoch 1000: Train MAE = 1216.7604, Val MAE = 1268.8941\nEpoch 1000: Train MAE = 1216.7604, Val MAE = 1268.8941\nEpoch 1500: Train MAE = 1216.3026, Val MAE = 1268.4428\nEpoch 1500: Train MAE = 1216.3026, Val MAE = 1268.4428\nEpoch 2000: Train MAE = 1215.8451, Val MAE = 1267.9922\n\nBest alpha: 0.1\nBest validation MAE: 1267.9919\nEpoch 2000: Train MAE = 1215.8451, Val MAE = 1267.9922\n\nBest alpha: 0.1\nBest validation MAE: 1267.9919\n\n\n\n\n\n\n\n\n\n\n\n\nFinal MAE Linear Regression Model Evaluation on Test Set:\n=======================================================\nMAE: 1288.54 days\nRMSE: 1798.93 days\nR² Score: -1.0535\n\n\n\n\n\nRandom Forest Regressor is implemented to predict patient survival time based on the preprocessed BRCA dataset. Design choices include: - Model Choice: Random Forest is selected for its robustness, ability to handle high-dimensional data, and effectiveness in capturing complex interactions between features. - Hyperparameter Tuning: A grid search with cross-validation employed to optimize key hyperparameters such as the number of estimators, maximum depth of the trees, and minimum samples per leaf. - Evaluation Metrics: Model performance evaluated using Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and R-squared (R²) to provide a comprehensive assessment of prediction accuracy.\n\n\nTraining Random Forest Regressor with Hyperparameter Tuning...\n=================================================================\nPerforming hyperparameter tuning with 5-fold cross-validation...\nFitting 5 folds for each of 50 candidates, totalling 250 fits\n\nBest Random Forest Parameters:\n  random_state: 42\n  n_estimators: 300\n  min_samples_split: 5\n  min_samples_leaf: 1\n  max_features: 0.3\n  max_depth: None\n  bootstrap: True\n\nBest Cross-Validation MAE: 755.05\nOut-of-Bag Score (R²): 0.1786\n\nBest Random Forest Parameters:\n  random_state: 42\n  n_estimators: 300\n  min_samples_split: 5\n  min_samples_leaf: 1\n  max_features: 0.3\n  max_depth: None\n  bootstrap: True\n\nBest Cross-Validation MAE: 755.05\nOut-of-Bag Score (R²): 0.1786\n\n\n\n\nEvaluating Random Forest Model on Test Set...\n==================================================\nRandom Forest Model Evaluation on Test Set:\nMAE: 792.40 days\nRMSE: 1156.06 days\nR² Score: 0.1519\n\nFeature Importance Statistics:\nNumber of features with importance &gt; 0.01: 25\nCumulative importance of top 10 features: 0.6256\n\n\n\n\n\n\n\n\n\n\nRandom Forest Model Complexity:\nNumber of trees: 300\nMax depth: None\nTotal number of nodes: 147756\nAverage tree depth: 29.93"
  },
  {
    "objectID": "technical-details/supervised-learning/main.html#final-model-comparison-and-analysis",
    "href": "technical-details/supervised-learning/main.html#final-model-comparison-and-analysis",
    "title": "Supervised Learning",
    "section": "",
    "text": "======================================================================\n                    FINAL MODEL COMPARISON\n======================================================================\n\n                     Model          MAE         RMSE            R²\nStandard Linear Regression 7.691527e+12 6.158508e+13 -2.406669e+21\n  Parametric Curve Fitting 1.288540e+03 1.798930e+03 -1.053500e+00\n   Random Forest Regressor 7.924000e+02 1.156060e+03  1.519000e-01\n\n======================================================================\nBEST MODEL: Random Forest Regressor\n   Achieved lowest MAE of 792.4 days\n======================================================================"
  },
  {
    "objectID": "technical-details/supervised-learning/main.html#model-selection-1",
    "href": "technical-details/supervised-learning/main.html#model-selection-1",
    "title": "Supervised Learning",
    "section": "Model Selection",
    "text": "Model Selection\nThe following models were evaluated for predicting patient survival time based on the preprocessed CESC dataset: 1. Standard Linear Regression: Benchmark model for comparison 2. Random Forest Regressor: For capturing non-linear relationships and interactions between features. 3. Parametric Curve Fitting: With Lasso regularization to prevent overfitting and eliminate potentially redundant features."
  },
  {
    "objectID": "technical-details/supervised-learning/main.html#training-and-testing-1",
    "href": "technical-details/supervised-learning/main.html#training-and-testing-1",
    "title": "Supervised Learning",
    "section": "Training and Testing",
    "text": "Training and Testing\nThe dataset was split into training and testing sets using an 80-20 split. Cross-validation was employed during model training to ensure robustness and generalizability of the models.\n\nStandard Linear Regression\n\n\nLinear Regression Model Evaluation on Test Set:\nRMSE: 1268.35\nMAE: 960.32\nR2 Score: -0.8628\n\n\n\n\nParametric Curve Fitting\nWe do a parametric Curve Fitting with L1 regularization (Lasso) to predict patient survival time based on the preprocessed CESC dataset. Design choices include: - Model Choice: Lasso regression is chosen for its ability to perform both variable selection and regularization, which helps enhance the prediction accuracy and interpretability of the statistical model it produces. In addition, early stopping is implemented to prevent overfitting during training. - Hyperparameter Tuning: The regularization parameter (alpha) was tuned using cross-validation to find the optimal balance between bias and variance. - Evaluation Metrics: Model performance evaluated using Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and R-squared (R²) to provide a comprehensive assessment of prediction accuracy. - SGDRegressor is used for optimization due to its efficiency with large datasets and ability to handle L1 regularization effectively.\n\n\nTraining MAE Linear Regression with Lasso Regularization...\n============================================================\n\nTesting alpha = 0.001\nEpoch 500: Train MAE = 1129.6072, Val MAE = 1096.8568\nEpoch 500: Train MAE = 1129.6072, Val MAE = 1096.8568\nEpoch 1000: Train MAE = 1129.0612, Val MAE = 1096.5397\nEpoch 1000: Train MAE = 1129.0612, Val MAE = 1096.5397\nEpoch 1500: Train MAE = 1128.5152, Val MAE = 1096.2226\nEpoch 1500: Train MAE = 1128.5152, Val MAE = 1096.2226\nEpoch 2000: Train MAE = 1127.9692, Val MAE = 1095.9054\n\nTesting alpha = 0.01\nEpoch 500: Train MAE = 1129.6240, Val MAE = 1096.8178\nEpoch 500: Train MAE = 1129.6240, Val MAE = 1096.8178\nEpoch 1000: Train MAE = 1129.0916, Val MAE = 1096.4694\nEpoch 1000: Train MAE = 1129.0916, Val MAE = 1096.4694\nEpoch 1500: Train MAE = 1128.5597, Val MAE = 1096.1201\nEpoch 1500: Train MAE = 1128.5597, Val MAE = 1096.1201\nEpoch 2000: Train MAE = 1128.0280, Val MAE = 1095.7708\n\nTesting alpha = 0.1\nEpoch 2000: Train MAE = 1128.0280, Val MAE = 1095.7708\n\nTesting alpha = 0.1\nEpoch 500: Train MAE = 1129.6547, Val MAE = 1096.6700\nEpoch 500: Train MAE = 1129.6547, Val MAE = 1096.6700\nEpoch 1000: Train MAE = 1129.1546, Val MAE = 1096.1732\nEpoch 1000: Train MAE = 1129.1546, Val MAE = 1096.1732\nEpoch 1500: Train MAE = 1128.6545, Val MAE = 1095.6765\nEpoch 1500: Train MAE = 1128.6545, Val MAE = 1095.6765\nEpoch 2000: Train MAE = 1128.1544, Val MAE = 1095.1798\n\nTesting alpha = 1.0\nEpoch 2000: Train MAE = 1128.1544, Val MAE = 1095.1798\n\nTesting alpha = 1.0\nEpoch 500: Train MAE = 1129.6548, Val MAE = 1096.6667\nEpoch 500: Train MAE = 1129.6548, Val MAE = 1096.6667\nEpoch 1000: Train MAE = 1129.1548, Val MAE = 1096.1667\nEpoch 1000: Train MAE = 1129.1548, Val MAE = 1096.1667\nEpoch 1500: Train MAE = 1128.6548, Val MAE = 1095.6667\nEpoch 1500: Train MAE = 1128.6548, Val MAE = 1095.6667\nEpoch 2000: Train MAE = 1128.1548, Val MAE = 1095.1667\n\nBest alpha: 1.0\nBest validation MAE: 1095.1667\nEpoch 2000: Train MAE = 1128.1548, Val MAE = 1095.1667\n\nBest alpha: 1.0\nBest validation MAE: 1095.1667\n\n\n\n\n\nFinal MAE Linear Regression Model Evaluation on Test Set:\n=======================================================\nMAE: 887.97 days\nRMSE: 1285.33 days\nR² Score: -0.9130\n\n\nRandom Forest Regressor is implemented to predict patient survival time based on the preprocessed CESC dataset. Design choices include: - Model Choice: Random Forest is selected for its robustness, ability to handle high-dimensional data, and effectiveness in capturing complex interactions between features. - Hyperparameter Tuning: A randomized search with cross-validation employed to optimize key hyperparameters such as the number of estimators, maximum depth of the trees, and minimum samples per leaf. - Evaluation Metrics: Model performance evaluated using Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and R-squared (R²) to provide a comprehensive assessment of prediction accuracy.\n\n\nRandom Forest Regressor\n\n\nTraining Random Forest Regressor with Hyperparameter Tuning...\n=================================================================\nPerforming hyperparameter tuning with 5-fold cross-validation...\nFitting 5 folds for each of 50 candidates, totalling 250 fits\n\nBest Random Forest Parameters:\n  random_state: 42\n  n_estimators: 500\n  min_samples_split: 2\n  min_samples_leaf: 2\n  max_features: log2\n  max_depth: 10\n  bootstrap: True\n\nBest Cross-Validation MAE: 709.13\nOut-of-Bag Score (R²): 0.0970\n\nBest Random Forest Parameters:\n  random_state: 42\n  n_estimators: 500\n  min_samples_split: 2\n  min_samples_leaf: 2\n  max_features: log2\n  max_depth: 10\n  bootstrap: True\n\nBest Cross-Validation MAE: 709.13\nOut-of-Bag Score (R²): 0.0970\n\n\n\n\nEvaluating Random Forest Model on Test Set...\n==================================================\nRandom Forest Model Evaluation on Test Set:\nMAE: 730.73 days\nRMSE: 921.17 days\nR² Score: 0.0174\n\nFeature Importance Statistics:\nNumber of features with importance &gt; 0.01: 23\nCumulative importance of top 10 features: 0.6870\nRandom Forest Model Evaluation on Test Set:\nMAE: 730.73 days\nRMSE: 921.17 days\nR² Score: 0.0174\n\nFeature Importance Statistics:\nNumber of features with importance &gt; 0.01: 23\nCumulative importance of top 10 features: 0.6870\n\n\n\n\n\n\n\n\n\n\nRandom Forest Model Complexity:\nNumber of trees: 500\nMax depth: 10\nTotal number of nodes: 24956\nAverage tree depth: 9.30\n\n\n\n\n======================================================================\n                    FINAL MODEL COMPARISON\n======================================================================\n\n                     Model    MAE    RMSE      R²\nStandard Linear Regression 960.32 1268.35 -0.8628\n  Parametric Curve Fitting 887.97 1285.33 -0.9130\n   Random Forest Regressor 730.73  921.17  0.0174\n\n======================================================================\nBEST MODEL: Random Forest Regressor\n   Achieved lowest MAE of 730.73 days\n======================================================================"
  },
  {
    "objectID": "technical-details/supervised-learning/main.html#final-model-comparison-and-analysis-1",
    "href": "technical-details/supervised-learning/main.html#final-model-comparison-and-analysis-1",
    "title": "Supervised Learning",
    "section": "Final Model Comparison and Analysis",
    "text": "Final Model Comparison and Analysis\nRandom Forest Regressor performs best for predicting patient survival time in both BRCA and CESC datasets, demonstrating its effectiveness in handling complex relationships within clinical data. This model consistently outperforms Standard Linear Regression and Parametric Curve Fitting across all evaluation metrics (MAE, RMSE, R²). The ability of Random Forest to capture non-linear interactions and its robustness to overfitting make it a superior choice for this predictive task."
  },
  {
    "objectID": "technical-details/supervised-learning/main.html#results-and-insights",
    "href": "technical-details/supervised-learning/main.html#results-and-insights",
    "title": "Breast (BRCA) Cancer Survival Time (days) Prediction Using Supervised Learning Models",
    "section": "Results and Insights",
    "text": "Results and Insights\nModeling Findings\nThe survival modeling using Random Forest regressors for both breast cancer (BRCA) and cervical cancer (CESC) provides additional insight into the relative influence of demographic, clinical, and tumor-specific variables on survival time. Across both cancers, the models achieve a mean absolute error (MAE) of under 800 days, indicating that predictions deviate from the true survival time by approximately two years on average. While this may appear large in absolute terms, it is important to contextualize the MAE relative to the observed survival distributions: the BRCA cohort averages 1,324 days of survival, and the CESC cohort averages 1,036 days. Thus, an MAE of &lt;800 days reflects moderate predictive power, consistent with the inherent difficulty of modeling survival solely with clinical variables in heterogeneous cancer populations. The implication is that the models capture broad, directional signals—such as early vs. late-stage disease—but cannot precisely predict patient-level survival due to missing biological, genomic, or treatment response data, a limitation widely noted in survival modeling literature (Moore et al., 2019).\nFeature Importance in Breast Cancer Survival Modeling (BRCA)\nFor breast cancer, the Random Forest model identifies age at diagnosis as the most influential predictor of survival, aligning with exploratory findings and long-established evidence indicating that older patients experience reduced survival due to comorbidity burden and more aggressive tumor biology (Siegel et al., 2023). Treatment counts emerged as the second most important feature, suggesting that patients receiving a greater number of therapies tend to have either more aggressive disease requiring multimodal treatment or more opportunities for therapeutic benefit.\nTumor staging variables—including T stage, overall stage, N stage, and M stage—collectively comprise a substantial proportion of the model’s predictive power, underscoring the clinical reality that anatomical extent of disease remains central to prognosis. Spatial tumor descriptors, such as site of involvement (breast right upper outer), also contribute meaningfully, likely reflecting differential lymphatic drainage patterns and associated metastatic risk.\nTreatment-related variables—particularly radiation therapy and pharmaceutical therapy—rank among the top predictors. Their presence in the top ten suggests that treatment modality type and intensity may partially proxy for tumor aggressiveness or patient fitness for therapy. The top ten BRCA features collectively explain over 60% of the model’s cumulative importance, demonstrating that survival in this cohort is dominated by a relatively concentrated set of clinical factors.\nFeature Importance in Cervical Cancer Survival Modeling (CESC)\nIn the CESC model, FIGO stage is overwhelmingly the strongest predictor of survival, consistent with its central role in cervical cancer staging and treatment decision-making (Arbyn et al., 2020). Higher FIGO stages (e.g., IIB, IIIB, IVA) correlate with markedly poorer outcomes in the EDA, and this relationship is captured quantitatively by the model. Similar to BRCA, age at diagnosis and treatment counts also play major roles, though age behaves differently in CESC, reflecting the dataset-specific survival-age pattern discussed in the exploratory analysis.\nTumor burden and spread variables—T stage, N stage, and M stage—remain key predictors but are secondary to FIGO staging, which already encodes much of the disease extent. Demographic variables, particularly race (Black), enter the top ten, suggesting potential disparities in outcomes that warrant deeper investigation.\nHistopathological descriptors such as tumor grade, primary diagnosis (squamous cell carcinoma), and diagnoses morphology also contribute substantially, consistent with the strong correspondence between tumor differentiation, histologic subtype, and survival in cervical cancer. The top ten CESC features account for over 68% of total model importance, indicating that survival time in this cohort is explained by an even more concentrated set of predictors than in BRCA.\nExposure Variables and Tobacco Use\nDespite tobacco exposure being a known risk factor for developing cervical cancer, smoking-related variables did not appear in the top ten predictive features for CESC survival. This is likely due to the dataset’s distribution: as seen in the EDA, the majority of patients report being lifelong non-smokers, which diminishes the ability of the model to detect meaningful survival differences across exposure categories. Underreporting and missing exposure data may further obscure any true effect (Benard et al., 2019). As a result, the lack of predictive importance should not be interpreted as evidence that tobacco exposure is unrelated to cervical cancer survival, but rather as a limitation of the dataset’s completeness and variability."
  },
  {
    "objectID": "technical-details/supervised-learning/main.html#references",
    "href": "technical-details/supervised-learning/main.html#references",
    "title": "Breast (BRCA) Cancer Survival Time (days) Prediction Using Supervised Learning Models",
    "section": "References",
    "text": "References\n\nSiegel RL, Miller KD, Fuchs HE, Jemal A. Cancer Statistics, 2023. CA Cancer J Clin. 2023;73(1):17–48.\n\nArbyn M, Weiderpass E, Bruni L, et al. Estimates of incidence and mortality of cervical cancer in 2018: a worldwide analysis. Lancet Glob Health. 2020;8(2):e191–203.\n\nCollaborative Group on Hormonal Factors in Breast Cancer. Breast cancer and hormonal contraceptives: collaborative reanalysis of individual data on 53,297 women with breast cancer and 100,239 women without breast cancer. Lancet. 2002;360:1040–1054.\n\nMoore JX, Akinyemiju T, Lemeshow S. Issues in survival modeling: biases, missing data, and opportunities for advancing prognostic research. Stat Methods Med Res. 2019;28(3):939–953.\n\nBenard VB, Thomas CC, King J, et al. Vital signs: cervical cancer incidence, mortality, and screening — United States, 2007–2012. MMWR Morb Mortal Wkly Rep. 2019;68(15):355–360."
  },
  {
    "objectID": "technical-details/supervised-learning/main1.html",
    "href": "technical-details/supervised-learning/main1.html",
    "title": "Supervised Learning",
    "section": "",
    "text": "Note: You should remove these instruction once you have read and understood them. They should not be included in your final submission.\nRemember: Exactly what do you put on this page will be specific you your project and data. Some things might “make more sense” on one page rather than another, depending on your workflow. Organize your project in a logical way that makes the most sense to you.\n\n\nHere’s one suggested structure for organizing your technical pages. You can adjust this as needed:\nAudience:Remember that these are written for a technical audience. Assume they have completed the DSAN program, but would appreciate refreshers of the important concepts.\n\nIntroduction and Motivation: Briefly outline your plan. What are you doing on this page, and why? Provide context and explain the goals of your analysis.\nOverview of Methods: Give a concise explanation of the methods used. For example, if using K-Means clustering, describe what it is, how it works, the inputs and outputs, and key hyperparameters.\nCode: Include the code you used to implement your workflow.\nSummary and Interpretation of Results: Summarize your findings, interpret the results, and discuss their technical implications.\n\n\n\n\nThe following is a list of some of the things you should address on this page. This list is not exhaustive, and you should use your judgment to decide what is most relevant to your project.\nPlease do some form of “Feature selection” in your project and include a section on it. Discuss the process you went through to select the features that you used in your model, this should be done for both classification models and regression models. What did you include and why? What did you exclude? What was the reasoning behind your decisions? This section can be included here, or you can make a new page in the dropdown menu for it.\nPlease break this page into a “regression” section, “binary classification” section, and a “Multi-class classification” section. For each case you should try multiple methods, including those discussed in class, and compare and contrast their preformance and results.\n\n\n\n\nNormalization or Standardization: Apply techniques to scale the data appropriately.\nFeature Selection or Extraction: Identify and select the most relevant features for your analysis.\nEncoding Categorical Variables: Convert categorical variables into a suitable format for modeling.\n\n\n\n\n\nModel Rationale: Explain the reasons for selecting specific models or algorithms.\nOverview of Algorithms: Provide a brief overview of the algorithms used\n\n\n\n\n\nSplit Methods: Detail the splitting methods used (e.g., train-test split, cross-validation).\nDataset Proportions: Specify the proportions used for splitting the dataset.\n\n\n\n\n\nBinary Classification Metrics: Discuss metrics such as accuracy, precision, recall, F1 score, and ROC-AUC.\nMulticlass Classification Metrics: Include metrics such as confusion matrix and macro/micro F1 score.\nRegression Metrics: Explain metrics such as RMSE, MAE, and R-squared, parity plots, etc.\n\n\n\n\n\nModel Performance Summary: Provide a summary of the model’s performance.\nVisualizations: Include visualizations of results (e.g., ROC curves, feature importance plots).\n\n\n\n\n\nResult Interpretation: Interpret the results obtained from the analysis.\nModel Performance Comparison: Compare the performance of different models.\nInsights Gained: Share insights learned from the analysis."
  },
  {
    "objectID": "technical-details/supervised-learning/main1.html#suggested-page-structure",
    "href": "technical-details/supervised-learning/main1.html#suggested-page-structure",
    "title": "Supervised Learning",
    "section": "",
    "text": "Here’s one suggested structure for organizing your technical pages. You can adjust this as needed:\nAudience:Remember that these are written for a technical audience. Assume they have completed the DSAN program, but would appreciate refreshers of the important concepts.\n\nIntroduction and Motivation: Briefly outline your plan. What are you doing on this page, and why? Provide context and explain the goals of your analysis.\nOverview of Methods: Give a concise explanation of the methods used. For example, if using K-Means clustering, describe what it is, how it works, the inputs and outputs, and key hyperparameters.\nCode: Include the code you used to implement your workflow.\nSummary and Interpretation of Results: Summarize your findings, interpret the results, and discuss their technical implications."
  },
  {
    "objectID": "technical-details/supervised-learning/main1.html#what-to-address",
    "href": "technical-details/supervised-learning/main1.html#what-to-address",
    "title": "Supervised Learning",
    "section": "",
    "text": "The following is a list of some of the things you should address on this page. This list is not exhaustive, and you should use your judgment to decide what is most relevant to your project.\nPlease do some form of “Feature selection” in your project and include a section on it. Discuss the process you went through to select the features that you used in your model, this should be done for both classification models and regression models. What did you include and why? What did you exclude? What was the reasoning behind your decisions? This section can be included here, or you can make a new page in the dropdown menu for it.\nPlease break this page into a “regression” section, “binary classification” section, and a “Multi-class classification” section. For each case you should try multiple methods, including those discussed in class, and compare and contrast their preformance and results."
  },
  {
    "objectID": "technical-details/supervised-learning/main1.html#data-preprocessing",
    "href": "technical-details/supervised-learning/main1.html#data-preprocessing",
    "title": "Supervised Learning",
    "section": "",
    "text": "Normalization or Standardization: Apply techniques to scale the data appropriately.\nFeature Selection or Extraction: Identify and select the most relevant features for your analysis.\nEncoding Categorical Variables: Convert categorical variables into a suitable format for modeling."
  },
  {
    "objectID": "technical-details/supervised-learning/main1.html#model-selection",
    "href": "technical-details/supervised-learning/main1.html#model-selection",
    "title": "Supervised Learning",
    "section": "",
    "text": "Model Rationale: Explain the reasons for selecting specific models or algorithms.\nOverview of Algorithms: Provide a brief overview of the algorithms used"
  },
  {
    "objectID": "technical-details/supervised-learning/main1.html#training-and-testing-strategy",
    "href": "technical-details/supervised-learning/main1.html#training-and-testing-strategy",
    "title": "Supervised Learning",
    "section": "",
    "text": "Split Methods: Detail the splitting methods used (e.g., train-test split, cross-validation).\nDataset Proportions: Specify the proportions used for splitting the dataset."
  },
  {
    "objectID": "technical-details/supervised-learning/main1.html#model-evaluation-metrics",
    "href": "technical-details/supervised-learning/main1.html#model-evaluation-metrics",
    "title": "Supervised Learning",
    "section": "",
    "text": "Binary Classification Metrics: Discuss metrics such as accuracy, precision, recall, F1 score, and ROC-AUC.\nMulticlass Classification Metrics: Include metrics such as confusion matrix and macro/micro F1 score.\nRegression Metrics: Explain metrics such as RMSE, MAE, and R-squared, parity plots, etc."
  },
  {
    "objectID": "technical-details/supervised-learning/main1.html#results",
    "href": "technical-details/supervised-learning/main1.html#results",
    "title": "Supervised Learning",
    "section": "",
    "text": "Model Performance Summary: Provide a summary of the model’s performance.\nVisualizations: Include visualizations of results (e.g., ROC curves, feature importance plots)."
  },
  {
    "objectID": "technical-details/supervised-learning/main1.html#discussion",
    "href": "technical-details/supervised-learning/main1.html#discussion",
    "title": "Supervised Learning",
    "section": "",
    "text": "Result Interpretation: Interpret the results obtained from the analysis.\nModel Performance Comparison: Compare the performance of different models.\nInsights Gained: Share insights learned from the analysis."
  },
  {
    "objectID": "technical-details/supervised-learning/main.html#data-preprocessing-1",
    "href": "technical-details/supervised-learning/main.html#data-preprocessing-1",
    "title": "Supervised Learning",
    "section": "Data Preprocessing",
    "text": "Data Preprocessing\nSimilar to the brca data, we had preserved multiple rows from the same patient in the cesc data to track treatments recevied during exploratory data analysis.\n\n\n\n\n\n\nFirst two rows of the eda CESC clinical dataset.\n\n\n\nproject.project_id\ncases.case_id\ncases.disease_type\ncases.index_date\ncases.lost_to_followup\ncases.primary_site\ncases.submitter_id\ndemographic.days_to_death\ndemographic.ethnicity\ndemographic.gender\ndemographic.race\ndemographic.submitter_id\ndemographic.vital_status\ndiagnoses.age_at_diagnosis\ndiagnoses.ajcc_pathologic_m\ndiagnoses.ajcc_pathologic_n\ndiagnoses.ajcc_pathologic_t\ndiagnoses.classification_of_tumor\ndiagnoses.days_to_diagnosis\ndiagnoses.days_to_last_follow_up\ndiagnoses.figo_stage\ndiagnoses.figo_staging_edition_year\ndiagnoses.method_of_diagnosis\ndiagnoses.morphology\ndiagnoses.primary_diagnosis\ndiagnoses.prior_malignancy\ndiagnoses.prior_treatment\ndiagnoses.site_of_resection_or_biopsy\ndiagnoses.submitter_id\ndiagnoses.synchronous_malignancy\ndiagnoses.tissue_or_organ_of_origin\ndiagnoses.tumor_grade\ntreatments.submitter_id\ntreatments.treatment_or_therapy\ntreatments.treatment_type\nsurvival_time_days\ndiagnoses.behavior\nexposures.tobacco_smoking_status\n\n\n\n\n0\ntcga-cesc\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nsquamous cell neoplasms\ndiagnosis\nyes\ncervix uteri\ntcga-c5-a2lv\nNaN\nnot hispanic or latino\nfemale\nblack or african american\ntcga-c5-a2lv_demographic\nalive\n36.0\nmx\nn1\nt1b\nprimary\n0\n2234.0\nstage ib\n1995\nbiopsy\n8070/3\nsquamous cell carcinoma, nos\nFalse\nFalse\ncervix uteri\ntcga-c5-a2lv_diagnosis\nFalse\ncervix uteri\ng3\ntcga-c5-a2lv_treatment3\nyes\nhysterectomy, nos\n2234.0\nmalignant\ncurrent smoker\n\n\n1\ntcga-cesc\n00bca18c-b3d4-45a3-8f19-034cc40449a4\nsquamous cell neoplasms\ndiagnosis\nyes\ncervix uteri\ntcga-c5-a2lv\nNaN\nnot hispanic or latino\nfemale\nblack or african american\ntcga-c5-a2lv_demographic\nalive\n36.0\nmx\nn1\nt1b\nprimary\n0\n2234.0\nstage ib\n1995\nbiopsy\n8070/3\nsquamous cell carcinoma, nos\nFalse\nFalse\ncervix uteri\ntcga-c5-a2lv_diagnosis\nFalse\ncervix uteri\ng3\ntcga-c5-a2lv_treatment2\nno\nradiation therapy, nos\n2234.0\nmalignant\ncurrent smoker\n\n\n\n\n\n\n\nHowever, for supervised learning, this could lead to data leakage during model training and evaluation. To mitigate this, we implemented a preprocessing step to retain only one record per patient. We selected the most recent record for each patient based on the ‘days_to_last_followup’ attribute, and created a column treatment.count to captuure the effect of multiple treatments a patient received.\n\n\n\nAfter deduplication:\nDeduplicated dataset shape: (184, 39)\nUnique cases.submitter_id: 184\nRows removed: 688\n\nTreatment distribution in deduplicated data:\ntreatments.treatment_or_therapy\nyes        118\nno          49\nunknown     17\nName: count, dtype: int64\n\nFinal CESC dataset shape: (184, 39)\n\n\nOur next step involved feature selection to enhance model performance and interpretability. We focused on removing non-informative features that exhibited low variance across the dataset. Features with little to no variability do not contribute meaningful information for predicting survival time and can introduce noise into the model.\nRemove Non-informative Features: Exclude features with low variance e.g., behavior of the tumor is malignant for all samples. Dropped features: - project_id: represents the project and is constant for all samples. - case_id: unique identifier for each case, not useful for prediction. - submitter_id: unique identifier for each submitter, not useful for prediction. - primary_site: all samples are from the breast, so this feature has no variance. - index_date: date of indexing, not relevant for prediction. - lost_to_followup: not applicable for prediction, a tracker for patients when patient stopped participating in follow-up before the study recorded their death - days_to_death: not applicable for all samples, leading to missing values. - ethnicity: heavy imbalance to not hispanic or latino (over 80% of samples), leading to low variance. Race might capture the variance better. - gender: all samples are female, so this feature has no variance - classification_of_tumor: all samples are primary, so this feature has no variance. - days_to_diagnosis: 0 for all samples, so this feature has no variance. - diagnoses.figo_staging_edition_year: Used to determine stage, stage will be used instead. - days_to _last_follow_up: not applicable for all samples, leading to missing values. - diagnoses.prior_treatment: heavy imbalance to false , leading to low variance. Assuming number of treatments is more informative. - vital_status: does not make sense to predict survival time based on whether the patient is alive or dead at last follow-up. - diagnoses.tissue_or_organ_of_origin: all samples are from the cervix, so this feature has no variance. - site_of_resection_or_biopsy: all samples are from the cervix, so this feature has no variance. Specific location within the breast (sites_of_involvement) may provide more detailed information. - synchronous_malignancy: heavy imbalance to false (&gt; 97%), so this feature has no variance. - treatments.submitter_id: unique identifier for each submitter, not useful for prediction. - treatments_or_therapy: Heavy imbalance to true as most patients receive treatment, so this feature has low variance. Specific treatment types may provide more information. - diagnoses.diagnosis_is_primary_disease: all samples are primary, so this feature has no variance. - diagnoses.method_of_diagnosis: Not informative to how long a patient survives. The primary diagnosis might be more relevant.\n\n\nOriginal dataset shape: (184, 39)\nCleaned dataset shape: (184, 15)\nColumns removed: 24\n\n\nLastly, we prepared the data for modeling by applying appropriate transformations to different types of variables:\n\nNormalization: Numerical columns age_at_diagnosis and treatments.count normalized using Min-Max scaling.\nBoolean Variables: Converted boolean variables to integers (0 and 1) for model compatibility, vital status to 1 for alive\nOrdinal Categorical Variables: Used Ordinal Encoding for features with an inherent order (e.g., `tumor_stage).\nEncoding Categorical Variables: Categorical variables were encoded using One-Hot Encoding to convert them into a format suitable for machine learning algorithms.\n\n\n\n\nUnique value counts for diagnoses.ajcc_pathologic_t column:\ndiagnoses.figo_stage\nstage ib1     64\nstage ib2     24\nstage iib     23\nstage iiib    18\nstage ib      16\nstage iia2     7\nstage iia      6\nstage iia1     5\nstage ivb      5\nstage ii       4\nstage i        4\nstage iiia     3\nstage iva      2\nstage ia2      1\nstage iii      1\nstage ia1      1\nName: count, dtype: int64"
  },
  {
    "objectID": "report/report.html#model-results",
    "href": "report/report.html#model-results",
    "title": "Final Report",
    "section": "Model Results",
    "text": "Model Results\nWe evaluated three distinct machine learning approaches for predicting cancer patient survival times across both breast cancer (BRCA) and cervical cancer (CESC) datasets:\n\nBreast Cancer (BRCA) Results\n======================================================================\n                    FINAL MODEL COMPARISON\n======================================================================\n\n                     Model          MAE         RMSE            R²\nStandard Linear Regression 7.691527e+12 6.158508e+13 -2.406669e+21\n  Parametric Curve Fitting 1.288540e+03 1.798930e+03 -1.053500e+00\n   Random Forest Regressor 7.924000e+02 1.156060e+03  1.519000e-01\n\n======================================================================\nBEST MODEL: Random Forest Regressor\n   Achieved lowest MAE of 792.4 days\n======================================================================\nBest Hyperparameters for Random Forest (BRCA):\n\nn_estimators: 300\nmax_depth: None\nmin_samples_split: 5\nmin_samples_leaf: 1\nmax_features: 0.3\nbootstrap: True\nBest Cross-Validation MAE: 755.05\nOut-of-Bag Score (R²): 0.1786\n\n\n\nCervical Cancer (CESC) Results\n======================================================================\n                    FINAL MODEL COMPARISON\n======================================================================\n\n                     Model    MAE    RMSE      R²\nStandard Linear Regression 960.32 1268.35 -0.8628\n  Parametric Curve Fitting 887.97 1285.33 -0.9130\n   Random Forest Regressor 730.73  921.17  0.0174\n\n======================================================================\nBEST MODEL: Random Forest Regressor\n   Achieved lowest MAE of 730.73 days\n======================================================================\nBest Hyperparameters for Random Forest (CESC):\n\nn_estimators: 500\nmax_depth: 10\nmin_samples_split: 2\nmin_samples_leaf: 2\nmax_features: log2\nbootstrap: True\nBest Cross-Validation MAE: 709.13\nOut-of-Bag Score (R²): 0.0970\n\n\n\nModel Performance Analysis\nRandom Forest consistently emerged as the superior model for both cancer types, achieving the lowest Mean Absolute Error (MAE) in both cases. This success can be attributed to several key factors:\n\nNon-linear Relationship Capture: Cancer survival involves complex, non-linear interactions between clinical variables that Random Forest effectively models through its ensemble of decision trees.\nRobust Feature Handling: The algorithm naturally handles mixed data types (categorical staging variables, continuous age/treatment counts) without extensive preprocessing requirements.\nOverfitting Resistance: The ensemble approach and bootstrap sampling provide built-in regularization, preventing overfitting to training data patterns.\nFeature Importance: Random Forest provides interpretable feature importance scores, crucial for clinical applications where understanding driving factors is essential.\n\nThe Standard Linear Regression showed severe overfitting in the BRCA dataset (extremely high MAE and negative R²), while Parametric Curve Fitting with Lasso regularization performed moderately but still struggled with the complex, non-linear nature of cancer survival patterns."
  },
  {
    "objectID": "report/report.html#discussion",
    "href": "report/report.html#discussion",
    "title": "Final Report",
    "section": "Discussion",
    "text": "Discussion\n\n\n\n\n\nFeature Importance for BRCA Survival Time Prediction\n\n\n\n\n\n\nFeature Importance for CESC Survival Time Prediction\n\n\n\n\nOur Random Forest models revealed distinct but complementary patterns in feature importance across cancer types, with age at diagnosis consistently emerging as a top predictor for both BRCA and CESC cohorts, reflecting well-established clinical evidence linking advanced age to poorer outcomes due to comorbidity burden and aggressive tumor biology. In breast cancer, the model identified treatment counts and comprehensive tumor staging variables (T, N, M, overall stage) as critical predictors, with spatial descriptors and treatment modalities (radiation, pharmaceutical therapy) collectively explaining over 60% of predictive power, suggesting that survival is dominated by disease extent and treatment intensity. Cervical cancer analysis revealed FIGO staging as the overwhelmingly dominant predictor, consistent with its central role in clinical decision-making, while age, treatment counts, and demographic variables (including race) comprised secondary but important factors, with the top ten features accounting for over 68% of model importance—indicating more concentrated predictive factors than in breast cancer. Notably, despite tobacco exposure being a known cervical cancer risk factor, smoking-related variables did not appear among top predictors, likely due to dataset limitations including predominant non-smoker representation and potential underreporting, highlighting the critical role of data completeness in model performance and clinical interpretation.\nThese results reinforce why cervical cancer screening is recommended to start earlier at age 21 compared to breast cancer (after 30 for high risk individuals)1 2 . However, cervical cancer prevention efforts receive less public visibility than breast cancer campaigns and tying the campaigns together could help catch cervical cancer earlier in the population3 . This could improve survival time as the tumor stage is the dominant predictor for cervical cancer in our findings and cervical cancer has a lower survival rate of 66% compared to that of breast cancer (90%)4 ."
  },
  {
    "objectID": "report/report.html#future-improvements",
    "href": "report/report.html#future-improvements",
    "title": "Final Report",
    "section": "Future Improvements",
    "text": "Future Improvements\nSeveral technical enhancements could significantly improve our cancer survival prediction models:\n\nData Enhancement\n\nMulti-modal Integration: Incorporate genomic data, imaging features, and proteomics to create a more comprehensive patient profile\nTemporal Modeling: Include longitudinal treatment response data and biomarker changes over time\nExternal Validation: Test models on independent datasets from different institutions to assess generalizability\n\n\n\nAdvanced Modeling Techniques\n\nDeep Learning Approaches: Implement neural networks specifically designed for survival analysis (DeepSurv, DeepHit)\nEnsemble Methods: Combine multiple algorithms using stacking or voting approaches for improved robustness\nSurvival-Specific Models: Utilize Cox Proportional Hazards models or accelerated failure time models designed for time-to-event data\n\n\n\nFeature Engineering\n\nInteraction Terms: Systematically explore clinically meaningful feature interactions (e.g., stage × treatment combinations)\nDerived Biomarkers: Create composite scores from multiple clinical variables\nTime-Varying Covariates: Model how patient characteristics change during treatment\n\n\n\nModel Optimization\n\nHyperparameter Optimization: Implement Bayesian optimization or genetic algorithms for more efficient parameter tuning\nCross-Validation Strategy: Use stratified or time-series cross-validation appropriate for clinical data\nUncertainty Quantification: Implement confidence intervals and prediction uncertainty estimates for clinical decision support\n\n\n\nClinical Integration\n\nInterpretability Tools: Develop SHAP (SHapley Additive exPlanations) or LIME explanations for individual patient predictions\nRisk Stratification: Create clinically meaningful risk categories rather than continuous predictions\nReal-time Deployment: Build APIs for integration into electronic health record systems\n\n\n\nEvaluation Metrics\n\nClinical Relevance: Include clinically meaningful metrics like concordance index (C-index) for survival models\nSubgroup Analysis: Evaluate model performance across demographic and clinical subgroups to assess fairness\nCalibration Assessment: Ensure predicted survival probabilities match observed outcomes across risk levels"
  },
  {
    "objectID": "index.html#lanf",
    "href": "index.html#lanf",
    "title": "Landing page",
    "section": "",
    "text": "Audio instructions:\nIf you want, you can listen to the instructions:\n\n\n\n Source: Text-to-speech conversion done with Amazon Polly on AWS \nNote: These audio instructions should not be included in your final submission or repository, once you are done wiht them, please delete the files and remove them from the website."
  },
  {
    "objectID": "index.html#landing-page",
    "href": "index.html#landing-page",
    "title": "Landing page",
    "section": "Landing Page",
    "text": "Landing Page\nAudio instructions:\nIf you want, you can listen to the instructions:\n\n\n\n Source: Text-to-speech conversion done with Amazon Polly on AWS \nNote: These audio instructions should not be included in your final submission or repository, once you are done wiht them, please delete the files and remove them from the website."
  },
  {
    "objectID": "index.html#literature-review",
    "href": "index.html#literature-review",
    "title": "Landing page",
    "section": "Literature Review",
    "text": "Literature Review\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
  },
  {
    "objectID": "index.html#about-u",
    "href": "index.html#about-u",
    "title": "Landing page",
    "section": "About U",
    "text": "About U"
  },
  {
    "objectID": "index.html#about-us",
    "href": "index.html#about-us",
    "title": "Landing page",
    "section": "About Us",
    "text": "About Us\n\n::: column width=“50%” {width=70% alt = “Munashe Mhlanga portrait”}Munashe Mhlanga\nMS Data Science & Analytics, Georgetown UniversityMunashe focuses on applied data science for social impact, with research interests in digital transformation, accessibility, and ethical data use. LinkedIn\n\n::: column width=“50%” {width=70% alt = “Betsy portrait”}\nBetsy\nDepartment / Institution\nPlaceholder Text. ::: :::"
  },
  {
    "objectID": "index.html#about-the-project",
    "href": "index.html#about-the-project",
    "title": "Landing page",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
  },
  {
    "objectID": "index.html#about-the-authors",
    "href": "index.html#about-the-authors",
    "title": "Landing page",
    "section": "About the Authors",
    "text": "About the Authors\n\n::: column width=“50%” Munashe Mhlanga\nMS Data Science & Analytics, Georgetown UniversityMunashe focuses on applied data science for social impact, with research interests in digital transformation, accessibility, and ethical data use.\n\n::: column width=“50%” \nBetsy\nDepartment / Institution\nPlaceholder Text. ::: :::"
  },
  {
    "objectID": "index.html#additional-information",
    "href": "index.html#additional-information",
    "title": "Landing page",
    "section": "Additional Information",
    "text": "Additional Information"
  },
  {
    "objectID": "index.html#additional",
    "href": "index.html#additional",
    "title": "Landing page",
    "section": "Additional",
    "text": "Additional"
  },
  {
    "objectID": "index.html#additional-resources",
    "href": "index.html#additional-resources",
    "title": "Landing page",
    "section": "Additional Resources",
    "text": "Additional Resources\nPlease find additional resources on womens health below:\n\nPodcast: Women’s Health\nWomen’s Health Podcast\nA wide-ranging podcast covering women’s health topics including hormonal health, aging, disease prevention, and overall wellbeing.\nWomen’s Health Podcast\n\n\nYouTube Channel: Cleveland Clinic\nSpeaking of Women’s Health (Cleveland Clinic)\nExpert-led video discussions focused on women’s wellness, preventive care, and clinical health topics.\nSpeaking of Women’s Health – YouTube\n\n\nBlog / Reading Resource\nSpeaking of Women’s Health – Cleveland Clinic\nAn evidence-based blog and educational resource with articles on gynecology, cancer screening, menopause, and general women’s health.\nSpeaking of Women’s Health – Articles\n\n\nLearn More About Care\nGeorgetown Lombardi Comprehensive Cancer Center – Breast Cancer Care\nClinical information, diagnostic pathways, and patient-centered breast cancer care resources.\nGet Diagnosed or Learn More About Breast Cancer Care\n\n\nDonation\nPlease consider donating to CancerServe, a voluntary organization that focuses on education, community mobilisation, and assistance for disadvantaged patients in Zimbabwe."
  },
  {
    "objectID": "index.html#podcast-womens-health",
    "href": "index.html#podcast-womens-health",
    "title": "Landing page",
    "section": "🎧 Podcast: Women’s Health",
    "text": "🎧 Podcast: Women’s Health\nWomen’s Health Podcast\nA wide-ranging podcast covering women’s health topics including hormonal health, aging, disease prevention, and overall wellbeing.\n🔗 Women’s Health Podcast\n\n📺 YouTube Channel: Cleveland Clinic\nSpeaking of Women’s Health (Cleveland Clinic)\nExpert-led video discussions focused on women’s wellness, preventive care, and clinical health topics.\n🔗 Speaking of Women’s Health – YouTube\n\n\n📝 Blog / Reading Resource\nSpeaking of Women’s Health – Cleveland Clinic\nAn evidence-based blog and educational resource with articles on gynecology, cancer screening, menopause, and general women’s health.\n🔗 Speaking of Women’s Health – Articles\nPlease consider donating to CancerServe, a voluntary organization that focuses on education, community mobilisation, and assistance for disadvantaged patients."
  },
  {
    "objectID": "index.html#youtube-channel-cleveland-clinic",
    "href": "index.html#youtube-channel-cleveland-clinic",
    "title": "Landing page",
    "section": "📺 YouTube Channel: Cleveland Clinic",
    "text": "📺 YouTube Channel: Cleveland Clinic\nSpeaking of Women’s Health (Cleveland Clinic)\nExpert-led video discussions focused on women’s wellness, preventive care, and clinical health topics.\n🔗 Speaking of Women’s Health – YouTube"
  },
  {
    "objectID": "index.html#blog-reading-resource",
    "href": "index.html#blog-reading-resource",
    "title": "Landing page",
    "section": "📝 Blog / Reading Resource",
    "text": "📝 Blog / Reading Resource\nSpeaking of Women’s Health – Cleveland Clinic\nAn evidence-based blog and educational resource with articles on gynecology, cancer screening, menopause, and general women’s health.\n🔗 Speaking of Women’s Health – Articles\nPlease consider donating to CancerServe, a voluntary organization that focuses on education, community mobilisation, and assistance for disadvantaged patients."
  },
  {
    "objectID": "index.html#if-you-want-to-get-diagnosed-or-learn-more-about-care",
    "href": "index.html#if-you-want-to-get-diagnosed-or-learn-more-about-care",
    "title": "Landing page",
    "section": "🩺 If You Want to Get Diagnosed or Learn More About Care",
    "text": "🩺 If You Want to Get Diagnosed or Learn More About Care\nGeorgetown Lombardi Comprehensive Cancer Center – Breast Cancer Care\nClinical information, diagnostic pathways, and patient-centered breast cancer care resources.\n🔗 Get Diagnosed or Learn More About Breast Cancer Care"
  },
  {
    "objectID": "index.html#learn-more-about-care",
    "href": "index.html#learn-more-about-care",
    "title": "Landing page",
    "section": "🩺 Learn More About Care",
    "text": "🩺 Learn More About Care\nGeorgetown Lombardi Comprehensive Cancer Center – Breast Cancer Care\nClinical information, diagnostic pathways, and patient-centered breast cancer care resources.\n🔗 Get Diagnosed or Learn More About Breast Cancer Care"
  }
]